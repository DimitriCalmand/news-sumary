[
  {
    "title": "D-ID acquires Berlin-based video startup Simpleshow",
    "url": "https://techcrunch.com/2025/09/16/d-id-acquires-berlin-based-video-startup-simpleshow/",
    "content": "Video generation and editing platform D-ID said Tuesday that it has acquired Berlin-based B2B video creation platform Simpleshow. The companies didn’t disclose financial terms of the deal.\n--------------------\nSimpleshow’s product will operate under D-ID’s umbrella, and eventually the two platforms will merge, D-ID chief executive Gil Perry told TechCrunch.\n--------------------\nSimpleshow, founded in 2008, has raised over $20 million in funding, according to Crunchbase data.\n--------------------\nThe startup has offices in Berlin, Luxembourg, London, Miami, Singapore, Hong Kong, and Tokyo. As part of the merger, the company will have consolidated offices in Berlin, Tel Aviv, and the United States. D-ID didn’t mention Simpleshow’s team size, but said that the combined entity will have 140 employees.\n--------------------\n“Simpleshow initially approached us for a strategic partnership. We saw that there was synergy between management teams and products,” said Perry. “We felt that we needed to increase our speed in capturing a large [part of the enterprise avatar video] market. We thought acquiring Simpleshow would give us the necessary boost in that.”\n--------------------\nBoth companies are seeing a strong future of digital avatars for different kinds of videos, including training, marketing, and sales. D-ID already has a suite of AI-powered interactive avatars that it offers to its clients.\n--------------------\nSimpleshow’s CEO Karsten Boehrs said that when he joined the company over a decade ago, it was largely an agency producing videos for businesses and enterprises.\n--------------------\n“To achieve scale and serve more clients internationally, we decided to build a SaaS-based tech platform,” Boehrs told TechCrunch. “One of the first tools we launched was a text-to-video tool for our clients in 2017.”\n--------------------\nBoehrs added that in the last few years, with the rise of AI, it started conversations with companies like Sythesia for potential partnerships and eventually landed on D-ID to get acquired.\n--------------------\nAlongside its product, Simpleshow is also bringing more than 1,500 enterprise clients, including Adobe, Audio, Airbus, Microsoft, Bayer, HP, T-Mobile, McDonald’s, eBay, and Deutsche Bank. D-ID’s Perry mentioned that this will boost the company’s bottom line and bring it closer to profitability.\n--------------------\nGoing forward, D-ID wants to build interactive training videos, which will let users interrupt a video presented by an avatar and ask them a question or take a quiz.\n--------------------\nD-ID has strong competition for enterprise adoption of digital avatars in companies like Sythesia and Soul Machine. Companies such as Google and McKinsey are also developing solutions to let clients use digital avatars.\n--------------------\nD-ID has raised $60 million in funding to date. The company said it has secured funding to bankroll the acquisition, but it didn’t disclose the money.\n--------------------\n\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "YouTube announces new generative AI tools for Shorts creators",
    "url": "https://techcrunch.com/2025/09/16/youtube-announces-new-generative-ai-tools-for-shorts-creators/",
    "content": "At its Made on YouTube live event on Tuesday, the company unveiled new generative AI tools for Shorts creators. YouTube is bringing a custom version of Google’s text-to-video generative AI model, Veo 3, to Shorts, along with a new remixing tool, an “Edit with AI” feature, and more.\n--------------------\nThe custom version of Veo 3, called Veo 3 Fast, generates outputs with lower latency at 480p, making it easy to create video clips, YouTube says. And now, users can do so with sound for the first time.\n--------------------\nThis update is rolling out in the United States, the United Kingdom, Canada, Australia, and New Zealand. YouTube plans to expand its functionality to more regions in the future.\n--------------------\nYouTube is also bringing new Veo capabilities to Shorts, including the ability to apply motion from a video to an image. For example, you could animate a still image by making the person in it do a dance from a video. The company says this is possible through technology that captures and transfers movement from one subject to another.\n--------------------\nCreators can now also use Veo to apply different styles to their videos, such as pop art or origami. Plus, creators now have the ability to add objects like characters or props with text descriptions.\n--------------------\nThese new capabilities will roll out in the coming months.\n--------------------\nAs for the new remixing tool, creators can turn the dialogue from eligible videos into catchy soundtracks for other Shorts.\n--------------------\n“As the world’s largest creative playground, YouTube is where trends are born and where you can draw inspiration from. Imagine hearing a line of dialogue that sparks an idea—a funny phrase, a memorable quote, or a one-of-a-kind sound—and you want to remix it into a new sound,” YouTube’s Director of Product, Shorts and Generative AI Creation, Dina Berrada wrote in a blog post. “With our new Speech to Song remixing tool, you’ll be able to do just that.”\n--------------------\nYouTube notes that the feature uses Google’s AI music model Lyria 2 to create the soundtrack. Creators will be able to add their own vibe to the song, like “chill,” “danceable,” or “fun.”\n--------------------\nThe company plans to test this feature soon, it says, and will roll it out to more creators in the United States in the coming weeks.\n--------------------\nWith the new Edit with AI feature, creators can turn their raw footage into first drafts. It transforms raw camera roll footage into a first draft by finding and arranging the best moments, adding music, and transitions. It can even add a voiceover that can react to what’s happening in the video, in either English or Hindi. The idea behind the feature is to give creators a starting point for their Shorts, YouTube says.\n--------------------\nYouTube is experimenting with Edit with AI on Shorts and in the YouTube Create app, and will expand the feature in the coming weeks in select markets.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "YouTube to use AI to help podcasters promote themselves with clips and Shorts",
    "url": "https://techcrunch.com/2025/09/16/youtube-to-use-ai-to-help-podcasters-promote-themselves-with-clips-and-shorts/",
    "content": "On Tuesday, YouTube introduced new tools for podcasters at its Made on YouTube live event in New York, including new ways to turn video podcasts into clips and YouTube Shorts, and a new feature that helps create videos for audio-only podcasters. Both will be powered by AI and will roll out in the months ahead.\n--------------------\nUsing AI technology, video podcast creators in the U.S. will be able to create clips more easily with AI suggestions, the company says. This will be available in the “coming months,” while a feature that will transform those clips into YouTube Shorts will arrive early next year.\n--------------------\nThe addition could give YouTube more fodder to compete with rival short-form video apps, like TikTok and Instagram (Reels), while also directing users to podcasters they might find interesting on YouTube’s larger platform, driving subscriptions and engagement.\n--------------------\nMeanwhile, another new feature also available early next year will help audio podcasters turn their content into video. Using AI, these creators will be able to generate a customizable video for their podcast, the company says. However, the feature will only be available to “select podcasters” when it launches, with a larger expansion planned for later in 2026.\n--------------------\nYouTube has been more focused on building out tools for podcasters over the past several years, making pods a more prominent feature on YouTube’s home page and its YouTube Music service alike. Meanwhile, Spotify, at the same time, has been inching into its market with added support for video podcasts and other engagement features for podcasters, like comments, polls, and Q&As, as well as monetization tools.\n--------------------\nIn February, the company announced YouTube had surpassed 1 billion monthly podcaster viewers. Today, YouTube announced that users, as of July 2025, now consume over 100 million hours of podcasts daily, with more than 30% of those hours starting as a livestream or premiere.\n--------------------\n\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "YouTube rolls out Studio updates, ‘likeness’ detection, lip synced dubs, creator collabs and more",
    "url": "https://techcrunch.com/2025/09/16/youtube-rolls-out-studio-updates-likeness-detection-lip-synced-dubs-creator-collabs-and-more/",
    "content": "YouTube on Tuesday announced a suite of new features coming to YouTube Studio, the platform over 30 million creators use to manage their channels and track their analytics and revenue every month. At its Made on YouTube event, the company unveiled new and updated tools like an AI-powered chatbot for support, an inspiration tab, title A/B testing features, auto dubbing, likeness detection tools, and more.\n--------------------\nMany of these features build on tools previously announced or tested with smaller groups, but are now rolling out more broadly.\n--------------------\nOf these, the most interesting addition is the likeness detection feature, which was first announced in 2024 and expanded earlier this year to a handful of top creators, like Mr. Beast. Now, the company says it’s bringing the technology to an open beta that will be available to all YouTube Partner Program creators — content creators who meet certain subscriber and view thresholds to monetize their channels. These creators will be able to detect, manage, and authorize the removal of any unauthorized videos using their facial likeness. This will help them protect their image and reputation, and ensure their audience isn’t misled, notes YouTube.\n--------------------\nAnother new tool, Ask Studio, provides an AI-powered chatbot assistant that can guide users and answer questions about their account, like how their latest video is performing or what their audience is saying about their editing style, for example. The tool is meant to offer creators actionable insights that will help them grow their channel, according to YouTube.\n--------------------\n(The feature is different from another “Ask” AI tool for viewers that YouTube tested in late 2023, which allowed users to ask questions about a video they were viewing.)\n--------------------\nOne feature getting an update is the Inspiration tab in YouTube Studio. Launched publicly at last year’s event, the tab helps creators leverage AI to spark ideas and come up with video concepts. Now, it’s being updated with new ways to generate ideas, including a list of suggested topics tailored to each creator’s channel and a set of nine responses to every AI prompt, to help creators build out their content plan. The company notes that the topics can be combined, or users can add their own, as they brainstorm. The feature will also explain why it’s making specific suggestions based on audience insights and behavior.\n--------------------\nYouTube Studio will also introduce a way to test and compare up to three different video titles and thumbnails, as an update to its A/B testing feature launched to select creators in 2023 and expanded the following year. Creators have used this testing feature more than 15 million times so far, according to the company (a metric that seems a bit small, given that 20 million videos are uploaded to the site daily).\n--------------------\nPlus, creators will be able to collaborate with up to five others on one video that is shown to the audiences of all the participating creators. While the feature is aimed at boosting engagement and helping creators reach new viewers, the revenue earned from the video will be attributed to the channel that posts the video, YouTube says.\n--------------------\nThe company says it will also begin testing lip-syncing technology to make its auto dubbing features more realistic. Today, YouTube supports dubbing content into 20 different languages, and in the coming months, it will improve the translated videos to make them appear more natural by matching lip movements to the dubbed audio.\n--------------------\nYouTube notes that, on average, viewers spent over 75% of their time viewing the autodubbed video compared to the original, based on a comparison that ran from December 2024 to August 2025.\n--------------------\n\n--------------------\n\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Salesforce launches ‘Missonforce,’ a national security-focused business unit",
    "url": "https://techcrunch.com/2025/09/16/salesforce-launches-missonforce-a-national-security-focused-business-unit/",
    "content": "Salesforce is increasing its focus on national security.\n--------------------\nThe customer relationship management giant announced the creation of a new business unit called Missionforce on Tuesday. It will be focused on incorporating AI into defense workflows in three main areas: personnel, logistics, and decision making, according to a company press release.\n--------------------\nMissionforce will be helmed by Kendall Collins, who joined Salesforce in 2023 and is currently the chief business officer and chief of staff to Salesforce CEO Marc Benioff.\n--------------------\n“With Missionforce, we’ll now bring the best of AI, cloud, and platform technology from the private sector to modernize critical areas including personnel, logistics, and analytics,” Collins said in the press release. “The goal is simple: to help our warfighters and the organizations that support them operate smarter, faster, and more efficiently. There’s never been a more important time to serve those who serve.”\n--------------------\nSalesforce has held contracts with the U.S. government for years across federal agencies and multiple branches of the U.S. military including the U.S. Army, Navy and Air Force. The company doesn’t publicly disclose how many government contracts it has nor how much revenue it makes from them.\n--------------------\nThis news is the latest in a wave of tech companies building and offering services specifically for the U.S. government.\n--------------------\nOpenAI launched a version of its ChatGPT designed for U.S. government agencies in January. In August, the company announced it struck a deal with the government to give federal agencies access to its enterprise ChatGPT tier for just $1 a year.\n--------------------\nOther companies quickly followed suit.\n--------------------\nA week later, Anthropic announced it was giving the U.S. government access to its government and enterprise tiers of its Claude chatbot for $1.\n--------------------\nGoogle announced “Gemini for Government” in late August which offers their AI services to federal agencies for 47 cents for the first year.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "This $30M startup built a dog crate-sized robot factory that learns by watching humans",
    "url": "https://techcrunch.com/2025/09/16/this-30m-startup-built-a-dog-crate-sized-robot-factory-that-learns-by-watching-humans/",
    "content": "While many robotics companies are building human-sized robots, or working to automate entire factories, MicroFactory is instead trying to think big by building small.\n--------------------\nSan Francisco-based MicroFactory built a general-purpose, tabletop manufacturing kit that’s about the size of my Siberian Husky’s dog crate. This compact factory includes two robotic arms and can be trained by human demonstration, as well as through AI.\n--------------------\n“General purpose robots are good, but it’s not necessary [to] be humanoid,” said Igor Kulakov, the co-founder and CEO of MicroFactory, in an interview with TechCrunch. “We decided to design robots from scratch that will still be general purpose but not in human shape, and this way, it can be done much simpler, much easier, in hardware and on the AI side.”\n--------------------\nRather than selling individual robotic arms, MicroFactory’s system comes as an enclosed but transparent workstation, allowing users to watch the manufacturing process in real time. The compact factory-in-a-box is designed for precision tasks like circuit board assembly, component soldering, and cable routing. Users can train the robots by physically guiding the arms through complex motions — a hands-on approach that Kulakov says works faster than traditional AI programming for intricate manufacturing sequences.\n--------------------\n“Usually it takes couple hours, but in this way, the robot much better understands what it should do,” Kulakov said. “When you hire people, we still need to spend time, like a week or something, to instruct these people to then supervise their work. A manufacturing company, they already have this time and resources to spend, and it will be much easier to train a model and to make it work in this way.”\n--------------------\nKulakov’s experience with traditional manufacturing helped spark the idea behind MicroFactory.\n--------------------\nHe and his co-founder, Viktor Petrenko, used to run bitLighter, a manufacturing business that made portable lighting equipment for photographers. Kulakov said it was difficult to train new employees on how to complete the manufacturing process correctly. When advancements in AI made it seem possible to automate this type of work, they decided to jump on the opportunity.\n--------------------\nKulakov and Petrenko launched MicroFactory in 2024. It took them about five months to build their prototype. Now the company has hundreds of preorders from customers looking to use the machines for various applications, including assembling electronics and even processing snails to be shipped to France for escargot.\n--------------------\nMicroFactory just raised a $1.5 million pre-seed funding round that included investors like executives from the AI company Hugging Face and investor-entrepreneur Naval Ravikant. The round values the young startup at a $30 million post-money valuation.\n--------------------\nKulakov said the company plans to use the funding to build and ship out its units. The company is currently converting its prototype into a commercial product that it hopes to begin shipping in about two months.\n--------------------\nThe company also plans to make some hires and continue improving its technology, including the AI models running under the hood.\n--------------------\n“Our growth is related to building hardware, so we set the goal to increase it 10x each year,” Kulakov said. “In the first year, we want to produce 1,000 robots, [about] three per day, and we have the capability to do this. Then, [we want to] make more and more productions.”\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Google launches new protocol for agent-driven purchases",
    "url": "https://techcrunch.com/2025/09/16/google-launches-new-protocol-for-agent-driven-purchases/",
    "content": "On Tuesday, Google announced a new open protocol for purchases initiated by AI agents — automated software programs that can shop and make decisions on behalf of users —  with backing from more than 60 merchants and financial institutions. Called the Agent Payments Protocol (AP2), the system is meant to be interoperable between AI platforms, payment systems and vendors, providing a traceable paper trail for each transaction.\n--------------------\nIn a post announcing the protocol, Google executives emphasized their commitment to openness. “We are committed to evolving this protocol in an open, collaborative process, including through standards bodies, and  invite the entire payments and technology community to build this future with us,” wrote Stavan Parikh and Rao Surapaneni, who are VPs at Google and Google Cloud, respectively.\n--------------------\nThe full specification for AP2 was posted to GitHub in conjunction with the announcement.\n--------------------\nThe protocol is built for a future in which AI agents routinely shop for products on customers’ behalf, and engage in complex real-time interactions with retailers’ AI agents. One example in Google’s post imagines a chatbot user asking their agent to shop for a bike trip, which triggers a spontaneous time-sensitive bundle offer from a bike shop’s agent.\n--------------------\nIn another example, a user asks for travel and lodging for a weekend vacation, giving only the dates, location and budget. “The agent can then interact with both airline and hotel agents, as well as online travel agencies and booking platforms,” the post explains, “and once it finds a combination that fits the budget, it can execute both cryptographically-signed bookings simultaneously.”\n--------------------\nEnabling that kind of transaction is complex, from both a technological and social standpoint. AP2 requires agents to register two separate approvals before a purchase can be made: first the “intent mandate” (essentially telling the AI, “I’m looking for a polka dot neck tie”), which enables the agent to search for a specific item and negotiate with sellers; then the “cart mandate,” which gives final approval for a purchase once a specific item has been found.\n--------------------\nThe protocol also contains a provision for fully automated purchases, in which the agent is permitted to automatically generate a cart mandate once an item is found. Those circumstances require a more detailed intent mandate, specifying price limits, timing, and other rules of engagement. In either case, the goal is to maintain an auditable trail that can be re-examined in cases of fraud.\n--------------------\nIn collaboration with cryptocurrency outfits Coinbase, Metamask and the Ethereum foundation, Google also produced an extension that would integrate the cryptocurrency-oriented x402 protocol, allowing for AI-driven purchasing from crypto wallets.\n--------------------\nA number of other tech companies are working on their own agentic purchasing systems — most notably Perplexity, which allows for a Buy With Pro service in its agentic browser. The payment provider Stripe also produces software tools for agentic purchasing on its platform, though they are not as comprehensive as AP2.\n--------------------\nLike any protocol, the impact of AP2 will depend on its support from other players in the ecosystem — most notably, developers building agentic purchasing systems. But AP2 has already won the support of major financial providers like Mastercard, American Express and PayPal, giving the protocol a significant immediate footprint.\n--------------------\n\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Y Combinator-backed Rulebase wants to be the AI coworker for fintech",
    "url": "https://techcrunch.com/2025/09/16/y-combinator-backed-rulebase-wants-to-be-the-ai-coworker-for-fintech/",
    "content": "Y Combinator-alum Rulebase is betting that the next wave of automation in financial services won’t be about flashy AI interfaces, but the unglamorous back-office tasks like compliance.\n--------------------\nThe startup, founded by Gideon Ebose and Chidi Williams, two Nigerian engineers who met in London, just raised a $2.1 million pre-seed round led by Bowery Capital, with participation from Y Combinator, Commerce Ventures, Transpose Platform VC, alongside several angels.\n--------------------\nFinancial services firms spend enormous amounts of effort on support tickets, resolving disputes, ensuring quality assurance, and regulatory compliance. Rulebase’s software, which it calls an agent coworker, replaces much of the manual grunt work in these tasks. Its AI agent can evaluate customer interactions, flag regulatory risks, and trigger the right follow-ups across tools like Zendesk, Jira, and Slack without losing the human-in-the-loop oversight that financial firms demand.\n--------------------\n“Our ‘Coworker’ tool integrates across platforms and collaborates with human agents and back-office teams to fully manage the dispute lifecycle while saving time, reducing errors, and maintaining compliance,” said CTO Williams. Currently, the year-old startup is already deployed at customers like U.S. business banking platform Rho and an unnamed Fortune 50 financial institution.\n--------------------\nRulebase wasn’t the founders’ first swing. Ebose, a former product lead at Microsoft and Williams, a former backend engineer at Goldman Sachs, built several products together like an AI customer feedback tool before eventually settling on Rulebase. The idea came about after seeing how inefficient back-office operations were in small and large financial institutions, especially when it came to regulatory workflows.\n--------------------\nThe startup currently focuses on workflows triggered by customer service interactions, with its first wedge around quality assurance. QA analysts in traditional financial institutions typically manually review 3–5% of support interactions to ensure reps follow compliance protocols.\n--------------------\nRulebase now evaluates 100% of such interactions, cutting costs by up to 70%, the founders say. In the case of Rho, for instance, Rulebase has helped cut escalations by up to 30%.\n--------------------\n“We automate workflows that start with a customer interaction, areas we’re already great at handling end-to-end,” CEO Ebose said in an interview with TechCrunch. “While much of that is QA, compliance, and disputes tied to customer calls and messages, long-term our goal is to take on as many manual back-office tasks as possible by pulling these fragmented steps and tabs into one coordinated workflow.”\n--------------------\nThe new funding will help it double down on engineering and eventually add new features to AI Coworker like fraud investigation, audit preparation, and regulatory reporting.\n--------------------\nRulebase is focused on financial services for now because automation demands precision. “You need to understand MasterCard’s rules, CFPB timelines. That depth of domain knowledge is our moat,” Ebose said.\n--------------------\nThey company is targeting business banks, neobanks, and card issuers across Africa, Europe, and the U.S. But the roadmap could eventually include adjacent verticals like insurance, where similar workflows exist.\n--------------------\nRevenue is growing fast, with “double-digit” month-over-month growth since joining Y Combinator’s Fall 2024 batch, the founders say. Rulebase’s business model is usage-based, charging per interaction reviewed or workflow automated.\n--------------------\nAs one of the few African founders to get into YC building AI tools, Ebose and Williams’ advice to founders trying to get accepted into the global accelerator is to think globally from day one.\n--------------------\n“We’re in a moment where small teams can deliver more value, more quickly, than ever before, so limiting yourself to ‘X for Y’ or a narrow vertical feels like a missed opportunity,” Williams remarked. “With AI, it feels obvious that you have to go after something massive. Anything less than the most ambitious version of your idea likely won’t cut it,” said Williams, who before Rulebase built Buzz, an early open-source speech-to-text tool with over 300,000 downloads and over 12,000 GitHub stars.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "The 9 most sought-after startups from YC Demo Day",
    "url": "https://techcrunch.com/2025/09/15/the-9-most-sought-after-startups-from-yc-demo-day/",
    "content": "Y Combinator hosted its Summer 2025 Demo Day last week, showcasing the latest batch of over 160 startups.\n--------------------\nAs with recent batches, the majority of startups presented AI-centric solutions. However, a clear evolution was evident. Instead of  “AI-powered” products, many companies are now building AI agents or the infrastructure and tools needed to develop them. For instance, this batch had a flurry of voice AI solutions and new businesses focused on helping others monetize the “AI economy” with ads and marketing tools.\n--------------------\nWe spoke with a handful of YC-focused  investors to learn which startups they found most interesting and which generated the highest investment demand.\n--------------------\nBelow are the most frequently mentioned ones:\n--------------------\nWhat it does: Stripe for AI startups\n--------------------\nWhy it’s a fave: Many AI startups use complex pricing models that often blend a flat subscription fee per seat with usage-based charges, credits, and various add-on costs. Managing complex AI pricing on Stripe is a time-consuming, manual process. That’s why Autumn developed an open-source infrastructure that simplifies Stripe integration for AI startups. The company says its technology is already used by hundreds of AI apps and 40 YC startups. Given Stripe’s dominance in payments and the explosive growth of the AI market, could a specialized billing solution for AI be the next major fintech success story?\n--------------------\n\n--------------------\nWhat it does: Builds Vercel for AI agents\n--------------------\nWhy it’s a fave: Just as Vercel helps developers deploy and host startups, Dedalus Labs claims its platform automates the infrastructure for building AI agents, cutting hours of coding down to a few clicks. The company handles complex tasks like autoscaling and load balancing, which it says makes agent deployment fast and simple.\n--------------------\nWhat it does: crowdsource rankings of vibe coded designs\n--------------------\nWhy it’s a fave: The ability of AI to rapidly generate a huge number of designs creates a new problem: figuring out which ones are actually good. Design Arena solves this by crowdsourcing rankings of AI-generated visuals, creating a feedback loop that forces AI models to improve. Large AI labs see value in training their models to generate better designs, as some of them are already Design Arena’s customers.\n--------------------\nWhat it does: Tech-enabled distributor for retailers in Southeast Asia\n--------------------\nWhy it’s a fave: Getasap Asia was founded by Raghav Arora three years ago when he was just 14 years old. Since then, the startup that uses tech to deliver supplies to corner stores, restaurants and large supermarkets in Southeast Asia in under eight hours, has earned millions in revenue. Getasap Asia closed a round from General Catalyst, according to its website, and we are hearing that the startup’s valuation was among the highest in the whole batch.\n--------------------\nWhat it does: AI engineer that fixes bugs in production\n--------------------\nWhy it’s a fave: Founded by a 20-year-old Pablo Hansen who last year earned a master’s degree in AI, Keystone is on a mission to reduce software breaks. The company’s AI finds and fixes bugs for clients like Lovable and has already turned down a seven-figure acquisition offer, Hansen said.\n--------------------\nWhat it does: AI matchmaker for female friends\n--------------------\nWhy it’s a fave: While there isn’t a shortage of dating apps, RealRoots is tackling a different kind of loneliness. The company’s AI matchmaker, Lisa, interviews women and then organizes social experiences to connect them with compatible friends. While the AI part might be performative –  conversations with Lisa probably wouldn’t give RealRoots more insights about participants than written answers would – RealRoots may be on to something. Last month alone, the company generated $782,000 from 9,000 paying clients, its founders said.\n--------------------\nWhat it does: Automates insurance claims with AI\n--------------------\nWhy it’s a fave: Solva’s AI automates the most routine tasks for insurance adjusters, from filling out complex claims to preventing improper payouts. Just ten weeks after launching, Solva has already amassed $245,000 in annual recurring revenue (ARR), a figure that has investors excited.\n--------------------\nWhat it does: counter-drone mini-missiles\n--------------------\nWhy it’s a fave: With China reportedly amassing swarms of inexpensive drones, the U.S. military faces an urgent need for cost-effective counter-drone solutions. Perseus is developing just that: small missiles designed to shoot down drones at a fraction of the cost of existing systems. Multiple branches of the U.S. military have already invited the startup to demonstrate its solution, which could lead to hefty contracts.\n--------------------\nWhat it does: AI foreign language tutor\n--------------------\nWhy it’s a fave: Apps like Duolingo have made language learning accessible and fun, but they often lack a key component of fluency: consistent conversation. Pingo solves this problem by allowing users to speak with its AI, which acts as a native speaker. The company’s unique approach is proving incredibly popular, with founders claiming it’s growing 70% monthly and earning $250,000 in monthly revenue.\n--------------------\n\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Inside the shift at Disrupt: Building community and scaling in the AI era",
    "url": "https://techcrunch.com/2025/09/15/on-stage-at-techcrunch-disrupt-2025-how-ai-is-forcing-late-stage-startups-to-rewire-gtm-or-be-left-behind/",
    "content": "At TechCrunch Disrupt 2025, taking place October 27–29 in San Francisco, industry leaders will explore how founders can build lasting companies while navigating rapid shifts in AI, markets, and consumer behavior. Catch this dynamic panel on the Going Public Stage, where three seasoned leaders will explore how AI is transforming go-to-market (GTM) strategies from the inside out.\n--------------------\nBuy your tickets now to join this conversation — and more than 200 others — at the premier gathering for startups and investors. Register now for TechCrunch Disrupt 2025 and save up to $668, available through September 26. Prices increase September 27.\n--------------------\n\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "OpenAI upgrades Codex with a new version of GPT-5",
    "url": "https://techcrunch.com/2025/09/15/openai-upgrades-codex-with-a-new-version-of-gpt-5/",
    "content": "OpenAI announced Monday that it’s releasing a new version of GPT-5 to its AI coding agent, Codex. The company says its new model, called GPT-5-Codex, spends its “thinking” time more dynamically than previous models and could spend anywhere from a few seconds to seven hours on a coding task. As a result, it performs better on agentic coding benchmarks.\n--------------------\nThe new model is now rolling out in Codex products — which can be accessed via a terminal, IDE, GitHub, or ChatGPT — to all ChatGPT Plus, Pro, Business, Edu, and Enterprise users. OpenAI says it plans to make the model available to API customers in the future.\n--------------------\nThe update is part of OpenAI’s effort to make Codex more competitive with other AI coding products, such as Claude Code, Anysphere’s Cursor, or Microsoft’s GitHub Copilot. The market for AI coding tools has become much more crowded in the last year as a result of intense user demand. Cursor surpassed $500 million in ARR earlier in 2025, and Windsurf, a similar code editor, was the subject of a chaotic acquisition attempt that saw its team split between Google and Cognition.\n--------------------\nOpenAI says that GPT-5-Codex outperforms GPT-5 on SWE-bench Verified, a benchmark measuring agentic coding abilities, as well as a benchmark measuring performance on code refactoring tasks from large, established repositories.\n--------------------\nThe company also says it trained GPT-5-Codex for conducting code reviews and asked experience software engineers to evaluate the model’s review comments. The engineers reportedly found GPT-5-Codex to submit fewer incorrect comments, while adding more “high-impact comments.”\n--------------------\nIn a briefing, OpenAI’s Codex product lead Alexander Embiricos said that much of the increased performance was thanks to GPT-5-Codex’s dynamic “thinking abilities.” Users may be familiar with GPT-5’s router in ChatGPT, which directs queries to different models based on the complexity of a task. Embiricos said GPT-5-Codex works similarly but has no router under the hood and can adjust for how long to work on a task in real time.\n--------------------\nEmbiricos says this is an advantage compared to a router, which decides how much computational power and time to use on a problem at the outset. Instead, GPT-5-Codex can decide five minutes into a problem that it needs to spend another hour. Embiricos said he’s seen the model take upward of seven hours in some cases.\n--------------------\n\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "China says Nvidia violated antitrust regulations",
    "url": "https://techcrunch.com/2025/09/15/china-says-nvidia-violated-antitrust-regulations/",
    "content": "Trade tensions between China and the U.S. regarding semiconductors just got even more strained.\n--------------------\nOn Monday, China’s State Administration for Market Regulation ruled that semiconductor giant Nvidia was in violation of the country’s antitrust regulations, as first reported by Bloomberg. The ruling was in reference to Nvidia’s 2020 acquisition of Mellanox Technologies, a computer networking supplier, for $7 billion.\n--------------------\nAn Nvidia spokesperson supplied the following statement: “We comply with the law in all respects. We will continue to cooperate with all relevant government agencies as they evaluate the impact of export controls on competition in the commercial markets.”\n--------------------\nChina didn’t announce any consequences tied to its findings and will continue to investigate. Still, the ruling is likely to cast a pall over ongoing tariff negotiations between the U.S. and China, currently taking place in Madrid. While these trade discussions aren’t specifically about semiconductors, the question of Chinese access to Nvidia chips is a major point of contention between the two regimes.\n--------------------\nThe outgoing Biden administration announced its AI Diffusion Rule back in January that was meant to restrict U.S.-made AI chips to many countries, with further restrictions specifically for China and other adversaries.\n--------------------\nWhile the U.S. Department of Commerce formally repealed Biden’s AI rule in May, the future of AI chip exports to China remains in flux. The Trump administration slapped licensing agreements on chips heading to China in April. A few months later, in July, these companies were given the green light to start selling these chips again.\n--------------------\nJust a few weeks after that the country struck a deal requiring companies selling chips to China to give the U.S. a 15% cut of the revenue made on those sales. China has discouraged firms from buying Nvidia chips and, as of a recent earnings call, none of the company’s chips have made it through the new export process.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Time’s running out to volunteer at TechCrunch Disrupt 2025",
    "url": "https://techcrunch.com/2025/09/15/times-running-out-to-volunteer-at-techcrunch-disrupt-2025/",
    "content": "Every year, TechCrunch Disrupt runs on innovation — and the support of our incredible volunteers. If you’ve ever dreamed of a front-row seat to the startup world, this is your chance. But heads-up: volunteer applications close September 30, and the clock is ticking.\n--------------------\nWhether you’re a future founder, marketer, engineer, or event producer, volunteering at Disrupt offers a behind-the-scenes look at what it takes to run one of the most iconic startup conferences on the planet. You’ll gain experience, build your network, and score a free pass to the full event — just for pitching in.\n--------------------\nTechCrunch Disrupt 2025 takes place October 27–29 at Moscone West in San Francisco, and we’re looking for motivated, curious, and energetic volunteers to help make it all happen.\n--------------------\nSpots are filling quickly — sign up to volunteer now before it’s too late.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "By popular demand: 10 extra exhibit tables open at TechCrunch Disrupt 2025",
    "url": "https://techcrunch.com/2025/09/15/by-popular-demand-10-extra-exhibit-tables-open-at-techcrunch-disrupt-2025/",
    "content": "Back by overwhelming demand, we’ve added 10 more exhibit tables to TechCrunch Disrupt 2025 — this will be the final release before they sell out. This is your last chance to showcase your company in front of 10,000+ founders, VCs, and tech innovators from October 27-29 at San Francisco’s Moscone West.\n--------------------\nDisrupt isn’t just a tech conference — it’s a launchpad. Startups of all stages come here to meet their first investors, land their biggest partnerships, and spark ideas that take them to the next level. In 2025, that launchpad could be your exhibit table. Books yours here.\n--------------------\nVisibility where it counts: No table = no chance to showcase your product to thousands of investors, partners, and press walking through the heart of one of the largest tech conferences of the year.\n--------------------\nAccess to key decision-makers: Without passes, your team misses direct engagement with high-level founders, investors, and enterprise leaders.\n--------------------\nBrand amplification: Without placement, you miss exposure across TechCrunch channels before, during, and after the event.\n--------------------\nSmart investment: For just $10,000, you unlock unmatched reach, networking, and lead-generation tools. Skipping this means leaving serious value on the table.\n--------------------\nThese 10 tables won’t last — act now to own the spotlight, leads, and momentum. Book your exhibit table now.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Harvard Law to AI: MarqVision lands $48M to combat brand abuse",
    "url": "https://techcrunch.com/2025/09/15/harvard-law-to-ai-marqvision-lands-48m-to-combat-brand-abuse/",
    "content": "When Mark Lee was a law student at Harvard, a trademark class exposed him to the staggering scale of counterfeiting, an illicit industry worth more than $3 trillion annually and set him on an unexpected path to entrepreneurship.\n--------------------\n“I was always broadly interested in technology and startups, but I never really thought I’d be an entrepreneur. I assumed I was set to become a lawyer; most of my family members are lawyers, and practicing law felt like a natural path,” Lee said in an exclusive interview with TechCrunch. But when he got to Harvard Law, the education wasn’t quite what he expected, Lee said, adding that he began to question whether a career as a corporate lawyer was the right fit.\n--------------------\n“So I started exploring different ideas. One day, I took a trademark class and learned that counterfeiting is the world’s largest criminal enterprise, $3 trillion in counterfeit products traded every year, about 8% of global commerce. What struck me was that during COVID, as everything was moving online, this already massive market was growing 20% a year, fueled by marketplaces and social media,” Lee continued. “I saw it as a universal problem — and one that could be solved with the technology I was passionate about at the time: computer vision.”\n--------------------\nThat insight became the seed for MarqVision, the company he later co-founded in 2021. The name itself reflects its origins: “Marq” from trademark, and “Vision” from computer vision. The mission was straightforward but ambitious: harness AI-powered computer vision to fight counterfeiting and trademark infringement on a global scale.\n--------------------\nFast-forward to 2025 and the LA-headquartered AI startup has closed a $48 million Series B round, bringing its total capital raised to about $90 million.\n--------------------\nRoughly half of the fresh capital will go toward expanding its AI and engineering teams to accelerate automation and integrate generative AI across its product suite. Another $10 million is earmarked for making the platform enterprise-ready as the company moves upmarket to target larger brands, while an additional $10 million will fund regional expansion. Already active in the U.S., Korea, China, and Europe, MarqVision is now entering Japan, highlighting the borderless nature of IP law and the company’s push to scale globally.\n--------------------\nThe financing was led by Peak XV Partners — formerly Sequoia Capital India & SEA — with participation from Salesforce Ventures, HSG (formerly Sequoia China), Coral Capital, and Michael Seibel, partner emeritus at Y Combinator. Returning backers, including YC, Altos Ventures, and Atinum Investment, also joined the round.\n--------------------\n“Increasingly, top-tier investors are looking for technology companies that leverage AI not just to enhance productivity, but to fundamentally transform service delivery,” Lee explained. “AI is expanding the total addressable market for software from efficiency tools into the execution of the work itself — unlocking a market opportunity of over $10 trillion. While many early-stage companies are experimenting with AI to disrupt labor-intensive service industries, very few have reached the early-growth stage with the scale and traction.”\n--------------------\nMarqVision serves more than 350 customers worldwide across industries ranging from fashion and luxury to gaming, pharmaceuticals, entertainment, automotive, and consumer electronics. The startup reached $1 million in annual recurring revenue within eight months, $10 million in three years, and recently crossed $20 million after four years, doubling annually along the way.\n--------------------\n“Our goal is $100 million ARR by mid-2027,” Lee said. “Growth could have been faster, but we prioritized two things: delivering the best customer experience and building a scalable AI-driven foundation. As a managed service, we can monetize many offerings, but everything ties back to one core promise — helping global brands control their digital presence and grow revenue.”\n--------------------\nOnce considered an unappealing category in technology, “services” is being redefined by AI, which brings software-like scalability and efficiency. This shift has fueled investor interest, with Peak XV, HSG, and Salesforce Ventures backing the company’s vision. The rise of large language models has reframed its positioning from a “software company with humans in the loop” to a leader in the emerging AI-led services space, drawing strong competition in its latest funding round.\n--------------------\nMarqVision started out fighting counterfeits, using AI to spot and remove fake products online. As the technology advanced, the startup shifted its focus toward helping brands directly recover lost revenue. Today, many clients report a roughly 5% boost in sales, making the platform valuable not just to legal teams but also to go-to-market organizations tracking revenue impact, according to Lee.\n--------------------\nWhen Lee first pitched MarqVision, he envisioned a $5 billion software company, selling $50,000 tools to 10,000 IP teams worldwide. But YC partner Michael Seibel urged him to think bigger — beyond software — by reimagining how IP and brand professionals work. MarqVision has since expanded into end-to-end managed services, an opportunity Lee now believes is 100x larger than his original plan.\n--------------------\nBrand protection typically involves detecting and removing infringements like counterfeits and impersonations, while brand control goes further, giving companies the ability to manage their presence across e-commerce, social media, websites, and chat platforms, Lee noted. Looking ahead, the roadmap includes brand intelligence, offering insights into supply chains, pricing strategies, and reseller networks.\n--------------------\n“Our vision is to be the backbone of every global brand that owns IP — becoming the AI-led services platform for IP, content, and brand professionals worldwide,” Lee said.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "OpenAI board chair Bret Taylor says we’re in an AI bubble (but that’s OK)",
    "url": "https://techcrunch.com/2025/09/14/openai-board-chair-bret-taylor-says-were-in-an-ai-bubble-but-thats-ok/",
    "content": "Posted:\n--------------------\nBret Taylor, board chair at OpenAI and CEO of AI agent startup Sierra, was asked in a recent interview with The Verge whether he agreed with OpenAI CEO Sam Altman’s declaration that “someone is going to lose a phenomenal amount of money in AI.”\n--------------------\nTaylor echoed Altman’s sentiments, suggesting that we are indeed in an AI bubble — but like Altman, he didn’t sound too worried about it.\n--------------------\n“I think it is both true that AI will transform the economy, and I think it will, like the internet, create huge amounts of economic value in the future,” Taylor said. “I think we’re also in a bubble, and a lot of people will lose a lot of money. I think both are absolutely true at the same time, and there’s a lot of historical precedent for both of those things being true at the same time.”\n--------------------\nSpecifically, Taylor compared today’s AI landscape to the dot-com bubble of the late ‘90s. While many companies failed when the bubble burst, he argued that “all the people in 1999 were kind of right.”\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Vibe coding has turned senior devs into ‘AI babysitters,’ but they say it’s worth it",
    "url": "https://techcrunch.com/2025/09/14/vibe-coding-has-turned-senior-devs-into-ai-babysitters-but-they-say-its-worth-it/",
    "content": "Carla Rover once spent 30 minutes sobbing after having to restart a project she vibe coded.\n--------------------\nRover has been in the industry for 15 years, mainly working as a web developer. She’s now building a startup, alongside her son, that creates custom machine learning models for marketplaces.\n--------------------\nShe called vibe coding a beautiful, endless cocktail napkin on which one can perpetually sketch ideas. But dealing with AI-generated code that one hopes to use in production can be “worse than babysitting,” she said, as these AI models can mess up work in ways that are hard to predict.\n--------------------\nShe had turned to AI coding in a need for speed with her startup, as is the promise of AI tools.\n--------------------\n“Because I needed to be quick and impressive, I took a shortcut and did not scan those files after the automated review,” she said. “When I did do it manually, I found so much wrong. When I used a third-party tool, I found more. And I learned my lesson.”\n--------------------\nShe and her son wound up restarting their whole project — hence the tears. “I handed it off like the copilot was an employee,” she said. “It isn’t.”\n--------------------\nRover is like many experienced programmers turning to AI for coding help. But such programmers are also finding themselves acting like AI babysitters — rewriting and fact-checking the code the AI spits out.\n--------------------\nA recent report by content delivery platform company Fastly found that at least 95% of the nearly 800 developers it surveyed said they spend extra time fixing AI-generated code, with the load of such verification falling most heavily on the shoulders of senior developers.\n--------------------\nThese experienced coders have discovered issues with AI-generated code ranging from hallucinating package names to deleting important information and security risks. Left unchecked, AI code can leave a product far more buggy than what humans would produce.\n--------------------\nWorking with AI-generated code has become such a problem that it’s given rise to a new corporate coding job known as “vibe code cleanup specialist.”\n--------------------\nTechCrunch spoke to experienced coders about their time using AI-generated code about what they see as the future of vibe coding. Thoughts varied, but one thing remained certain: The technology still has a long way to go.\n--------------------\n“Using a coding co-pilot is kind of like giving a coffee pot to a smart six-year-old and saying, ‘Please take this into the dining room and pour coffee for the family,’” Rover said.\n--------------------\nCan they do it? Possibly. Could they fail? Definitely. And most likely, if they do fail, they aren’t going to tell you. “It doesn’t make the kid less clever,” she continued. “It just means you can’t delegate [a task] like that completely.”\n--------------------\nFeridoon Malekzadeh also compared vibe coding to a child.\n--------------------\nHe’s worked in the industry for more than 20 years, holding various roles in product development, software, and design. He’s building his own startup and heavily using vibe-coding platform Lovable, he said. For fun, he also vibe codes apps like one that generates Gen Alpha slang for Boomers.\n--------------------\nHe likes that he’s able to work alone on projects, saving time and money, but agrees that vibe coding is not like hiring an intern or a junior coder. Instead, vibe coding is akin to “hiring your stubborn, insolent teenager to help you do something,” he told TechCrunch.\n--------------------\n“You have to ask them 15 times to do something,” he said. “In the end, they do some of what you asked, some stuff you didn’t ask for, and they break a bunch of things along the way.”\n--------------------\nMalekzadeh estimates he spends around 50% of his time writing requirements, 10% to 20% of his time on vibe coding, and 30% to 40% of his time on vibe fixing — remedying the bugs and “unnecessary script” created by AI-written code.\n--------------------\nHe also doesn’t think vibe coding is the best at systems thinking — the process of seeing how a complex problem could impact an overall result. AI-generated code, he said, tries to solve more surface-level problems.\n--------------------\n“If you’re creating a feature that should be broadly available in your product, a good engineer would create that once and make it available everywhere that it’s needed,” Malekzadeh said. “Vibe coding will create something five different times, five different ways, if it’s needed in five different places. It leads to a lot of confusion, not only for the user, but for the model.”\n--------------------\nMeanwhile, Rover finds that AI “runs into a wall” when data conflicts with what it was hard-coded to do. “It can offer misleading advice, leave out key elements that are vital, or insert itself into a thought pathway you’re developing,” she said.\n--------------------\nShe also found that rather than admit to making errors, it will manufacture results.\n--------------------\nShe shared another example with TechCrunch, where she questioned the results an AI model initially gave her. The model started to give a detailed explanation pretending it used the data she uploaded. Only when she called it out did the AI model confess.\n--------------------\n“It freaked me out because it sounded like a toxic co-worker,” she said.\n--------------------\nOn top of this, there are the security concerns.\n--------------------\nAustin Spires is the senior director of developer enablement at Fastly and has been coding since the early 2000s.\n--------------------\nHe’s found through his own experience — along with chatting with customers — that vibe code likes to build what is quick rather than what is “right.” This may introduce vulnerabilities to the code of the kind that very new programmers tend to make, he said.\n--------------------\n“What often happens is the engineer needs to review the code, correct the agent, and tell the agent that they made a mistake,” Spires told TechCrunch. “This pattern is why we’ve seen the trope of ‘you’re absolutely right’ appear over social media.”\n--------------------\nHe’s referring to how AI models, like Anthropic Claude, tend to respond “you’re absolutely right” when called out on their mistakes.\n--------------------\nMike Arrowsmith, the chief trust officer at the IT management software company NinjaOne, has been in software engineering and security for around 20 years. He said that vibe coding is creating a new generation of IT and security blind spots to which young startups in particular are susceptible.\n--------------------\n“Vibe coding often bypasses the rigorous review processes that are foundational to traditional coding and crucial to catching vulnerabilities,” he told TechCrunch.\n--------------------\nNinjaOne, he said, counters this by encouraging “safe vibe coding,” where approved AI tools have access controls, along with mandatory peer review and, of course, security scanning.\n--------------------\nWhile nearly everyone we spoke to agrees that AI-generated code and vibe-coding platforms are useful in many situations — like mocking up ideas — they all agree that human review is essential before building a business on it.\n--------------------\n“That cocktail napkin is not a business model,” Rover said. “You have to balance the ease with insight.”\n--------------------\nBut for all the lamenting on its errors, vibe coding has changed the present and the future of the job.\n--------------------\nRover said vibe coding helped her tremendously in crafting a better user interface. Malekzadeh simply said that, despite the time he spends fixing code, he still gets more done with AI coders than without them.\n--------------------\n“‘Every technology carries its own negativity, which is invented at the same time as technical progress,” Malekzadeh said, quoting the French theorist Paul Virilio, who spoke about inventing the shipwreck along with the ship.\n--------------------\nThe Fastly survey found that senior developers were twice as likely to put AI-generated code into production compared to junior developers, saying that the technology helped them work faster.\n--------------------\nVibe coding is also part of Spires’ coding routine. He uses AI coding agents on several platforms for both front-end and back-end personal projects. He called the technology a mixed experience but said it’s good in helping with prototyping, building out boilerplate, or scaffolding out a test; it removes menial tasks so that engineers can focus on building, shipping, and scaling products.\n--------------------\nIt seems the extra hours spent combing through the vibe weeds will simply become a tolerated tax on using the innovation.\n--------------------\nElvis Kimara, a young engineer, is learning that now. He just graduated with a master’s in AI and is building an AI-powered marketplace.\n--------------------\nLike many coders, he said vibe coding has made his job harder and has often found vibe coding a joyless experience.\n--------------------\n“There’s no more dopamine from solving a problem by myself. The AI just figures it out,” he said. At one of his last jobs, he said senior developers didn’t look to help young coders as much — some not understanding new vibe-coding models, while others delegated mentorship tasks to said AI models.\n--------------------\nBut, he said, “the pros far outweigh the cons,” and he’s prepared to pay the innovation tax.\n--------------------\n“We won’t just be writing code; we’ll be guiding AI systems, taking accountability when things break, and acting more like consultants to machines,” Kimara said of the new normal for which he’s preparing.\n--------------------\n“Even as I grow into a senior role, I’ll keep using it,” he continued. “It’s been a real accelerator for me. I make sure I review every line of AI-generated code so I learn even faster from it.”\n--------------------\nThis post was updated to reflect the proper title of Mike Arrowsmith.\n--------------------\n\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Users turn to chatbots for spiritual guidance",
    "url": "https://techcrunch.com/2025/09/14/users-turn-to-chatbots-for-spiritual-guidance/",
    "content": "Posted:\n--------------------\nAI-powered chatbots play a growing role in spiritual life, according to a New York Times story that examines the popularity of religious chatbots and apps.\n--------------------\nThe Times notes that an app called Bible Chat has been downloaded more than 30 million times, while another app, Hallow, reached the No. 1 spot in Apple’s App Store last year.\n--------------------\nFor the most part, these apps are supposed to point people to religious doctrine and Scripture to answer their questions, although at least one website purports to allow users to chat with God. Rabbi Jonathan Romain suggested chatbots could be a “way into faith” for “a whole generation of people who have never been to a church or synagogue.”\n--------------------\nHowever, these chatbots are built on top of AI models that are designed to validate users’ opinions, to the point that they can reinforce delusional or conspiratorial thinking. Heidi Campbell, a Texas A&M professor who studies the intersection of digital culture and religion, warned that chatbots “tell us what we want to hear.”\n--------------------\n“It’s not using spiritual discernment, it is using data and patterns,” Campbell said.\n--------------------\n\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Karen Hao on the Empire of AI, AGI evangelists, and the cost of belief",
    "url": "https://techcrunch.com/2025/09/14/karen-hao-on-the-empire-of-ai-agi-evangelists-and-the-cost-of-belief/",
    "content": "At the center of every empire is an ideology, a belief system that propels the system forward and justifies expansion — even if the cost of that expansion directly defies the ideology’s stated mission.\n--------------------\nFor European colonial powers, it was Christianity and the promise of saving souls while extracting resources. For today’s AI empire, it’s artificial general intelligence to “benefit all humanity.” And OpenAI is its chief evangelist, spreading zeal across the industry in a way that has reframed how AI is built.\n--------------------\n“I was interviewing people whose voices were shaking from the fervor of their beliefs in AGI,” Karen Hao, journalist and bestselling author of “Empire of AI,” told TechCrunch on a recent episode of Equity.\n--------------------\nIn her book, Hao likens the AI industry in general, and OpenAI in particular, to an empire.\n--------------------\n“The only way to really understand the scope and scale of OpenAI’s behavior … is actually to recognize that they’ve already grown more powerful than pretty much any nation-state in the world, and they’ve consolidated an extraordinary amount of not just economic power, but also political power,” Hao said. “They’re terraforming the Earth. They’re rewiring our geopolitics, all of our lives. And so you can only describe it as an empire.”\n--------------------\nOpenAI has described AGI as “a highly autonomous system that outperforms humans at most economically valuable work,” one that will somehow “elevate humanity by increasing abundance, turbocharging the economy, and aiding in the discovery of new scientific knowledge that changes the limits of possibility.”\n--------------------\nThese nebulous promises have fueled the industry’s exponential growth — its massive resource demands, oceans of scraped data, strained energy grids, and willingness to release untested systems into the world. All in service of a future that many experts say may never arrive.\n--------------------\nHao says this path wasn’t inevitable and that scaling isn’t the only way to get more advances in AI.\n--------------------\n“You can also develop new techniques in algorithms,” she said. “You can improve the existing algorithms to reduce the amount of data and compute that they need to use.”\n--------------------\nBut that tactic would have meant sacrificing speed.\n--------------------\n“When you define the quest to build beneficial AGI as one where the victor takes all — which is what OpenAI did — then the most important thing is speed over anything else,” Hao said. “Speed over efficiency, speed over safety, speed over exploratory research.”\n--------------------\nFor OpenAI, she said, the best way to guarantee speed was to take existing techniques and “just do the intellectually cheap thing, which is to pump more data, more supercomputers, into those existing techniques.”\n--------------------\nOpenAI set the stage, and rather than fall behind, other tech companies decided to fall in line.\n--------------------\n“And because the AI industry has successfully captured most of the top AI researchers in the world, and those researchers no longer exist in academia, then you have an entire discipline now being shaped by the agenda of these companies, rather than by real scientific exploration,” Hao said.\n--------------------\nThe spend has been, and will be, astronomical. Last week, OpenAI said it expects to burn through $115 billion in cash by 2029. Meta said in July that it would spend up to $72 billion on building AI infrastructure this year. Google expects to hit up to $85 billion in capital expenditures for 2025, most of which will be spent on expanding AI and cloud infrastructure.\n--------------------\nMeanwhile, the goal posts keep moving, and the loftiest “benefits to humanity” haven’t yet materialized, even as the harms mount. Harms like job loss, concentration of wealth, and AI chatbots that fuel delusions and psychosis. In her book, Hao also documents workers in developing countries like Kenya and Venezuela who were exposed to disturbing content, including child sexual abuse material, and were paid very low wages — around $1 to $2 an hour — in roles like content moderation and data labeling.\n--------------------\nHao said it’s a false trade-off to pit AI progress against present harms, especially when other forms of AI offer real benefits.\n--------------------\nShe pointed to Google DeepMind’s Nobel Prize-winning AlphaFold, which is trained on amino acid sequence data and complex protein folding structures and can now accurately predict the 3D structure of proteins from their amino acids — profoundly useful for drug discovery and understanding disease.\n--------------------\n“Those are the types of AI systems that we need,” Hao said. “AlphaFold does not create mental health crises in people. AlphaFold does not lead to colossal environmental harms … because it’s trained on substantially less infrastructure. It does not create content moderation harms because [the datasets don’t have] all of the toxic crap that you hoovered up when you were scraping the internet.”\n--------------------\nAlongside the quasi-religious commitment to AGI has been a narrative about the importance of racing to beat China in the AI race so that Silicon Valley can have a liberalizing effect on the world.\n--------------------\n“Literally, the opposite has happened,” Hao said. “The gap has continued to close between the U.S. and China, and Silicon Valley has had an illiberalizing effect on the world … and the only actor that has come out of it unscathed, you could argue, is Silicon Valley itself.”\n--------------------\nOf course, many will argue that OpenAI and other AI companies have benefited humanity by releasing ChatGPT and other large language models, which promise huge gains in productivity by automating tasks like coding, writing, research, customer support, and other knowledge-work tasks.\n--------------------\nBut the way OpenAI is structured — part non-profit, part for-profit — complicates how it defines and measures its impact on humanity. And that’s further complicated by the news this week that OpenAI reached an agreement with Microsoft that brings it closer to eventually going public.\n--------------------\nTwo former OpenAI safety researchers told TechCrunch that they fear the AI lab has begun to confuse its for-profit and non-profit missions — that because people enjoy using ChatGPT and other products built on LLMs, this ticks the box of benefiting humanity.\n--------------------\nHao echoed these concerns, describing the dangers of being so consumed by the mission that reality is ignored.\n--------------------\n“Even as the evidence accumulates that what they’re building is actually harming significant amounts of people, the mission continues to paper all of that over,” Hao said. “There’s something really dangerous and dark about that, of [being] so wrapped up in a belief system you constructed that you lose touch with reality.”\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Rolling Stone owner Penske Media sues Google over AI summaries",
    "url": "https://techcrunch.com/2025/09/14/rolling-stone-owner-penske-media-sues-google-over-ai-summaries/",
    "content": "Google faces a new lawsuit accusing the company of illegally using news publishers’ content to create AI summaries that damage their business.\n--------------------\nThe lawsuit comes from Penske Media Corporation (PMC), which owns industry publications such as Rolling Stone, Billboard, Variety, Hollywood Reporter, Deadline, Vibe, and Artforum. While Penske’s suit is the first to target Google and its parent company Alphabet over showing AI-generated summaries in search, both publishers and authors have sued other AI companies over related copyright concerns. Google also is also facing an antitrust complaint over AI Overviews in Europe.\n--------------------\n“As a leading global publisher, we have a duty to protect PMC’s best-in-class journalists and award-winning journalism as a source of truth,” said Penske Media CEO Jay Penske in a statement. “Furthermore, we have a responsibility to proactively fight for the future of digital media and preserve its integrity — all of which is threatened by Google’s current actions.”\n--------------------\nSince launching its AI Overviews last year, Google has been criticized for threatening the business models of the same publishers it relies on to provide the content needed to create accurate AI summaries and answers.\n--------------------\nThe new lawsuit goes further by accusing Google of continuing to “wield its monopoly to coerce PMC into permitting Google to republish PMC’s content in AI Overviews” and to use that content to train its AI models.\n--------------------\nGoogle spokesperson José Castañeda said in a statement that AI Overviews make Google search “more helpful” and create “new opportunities for content to be discovered.”\n--------------------\n“Every day, Google sends billions of clicks to sites across the web, and AI Overviews send traffic to a greater diversity of sites,” Castañeda said. “We will defend against these meritless claims.”\n--------------------\nThe lawsuit argues that while Penske Media allows Google to crawl its websites in an “exchange of access for traffic” that is “the fundamental bargain that supports the production of content for the open commercial Web,” Google has recently “begun to tie its participation in this bargain to another transaction to which PMC and other publishers do not willingly consent.”\n--------------------\n“As a condition of indexing publisher content for search, Google now requires publishers to also supply that content for other uses that cannibalize or preempt search referrals,” the lawsuit claims, adding that the only way for Penske to opt out would be to remove itself from Google search entirely, which would be “devastating.”\n--------------------\nThe lawsuit also claims that Penske has seen “significant declines in clicks from Google searches since Google started rolling out AI Overviews.” That means less ad revenue for the publisher, and it also threatens subscription and affiliate revenue, the company says: “These revenue streams rely on people actually visiting PMC sites.”\n--------------------\nAnd while Google has pushed back against complaints that AI Overviews reduce traffic to publishers, the lawsuit says, “Google has offered no credible competing information regarding search referral traffic.”\n--------------------\nPenske’s suit comes after Google seemingly dodged an antitrust bullet — while a federal judge had ruled the company acted illegally to maintain a monopoly in online search, the judge did not to order the company to break up its businesses (e.g., by selling Chrome), due in part to an increasing competition in AI.\n--------------------\nThis post has been updated with a statement from Jay Penske.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "‘Selling coffee beans to Starbucks’ — how the AI boom could leave AI’s biggest companies behind",
    "url": "https://techcrunch.com/2025/09/14/selling-coffee-beans-to-starbucks-how-the-ai-boom-could-leave-ais-biggest-companies-behind/",
    "content": "How much do foundation models matter?\n--------------------\nIt might seem like a silly question, but it’s come up a lot in my conversations with AI startups, which are increasingly comfortable with businesses that used to be dismissed as “GPT wrappers,” or companies that build interfaces on top of existing AI models like ChatGPT.\n--------------------\nThese days, startup teams are focused on customizing AI models for specific tasks and interface work, and see the foundation model as a commodity that can be swapped in and out as necessary. That approach was on display especially at last week’s BoxWorks conference, which seemed devoted entirely to the user-facing software built on top of AI models.\n--------------------\nPart of what is driving this is that the scaling benefits of pre-training — that initial process of teaching AI models using massive datasets, which is the sole domain of foundation models — has slowed down. That doesn’t mean AI has stopped making progress, but the early benefits of hyperscaled foundational models have hit diminishing returns, and attention has turned to post-training and reinforcement learning as sources of future progress.\n--------------------\nIf you want to make a better AI coding tool, you’re better off working on fine-tuning and interface design rather than spending another few billion dollars’ worth in server time on pre-training. As the success of Anthropic’s Claude Code shows, foundation model companies are quite good at these other fields too — but it’s not as durable an advantage as it used to be.\n--------------------\nIn short, the competitive landscape of AI is changing in ways that undermine the advantages of the biggest AI labs. Instead of a race for an all-powerful AGI that could match or exceed human abilities across all cognitive tasks, the immediate future looks like a flurry of discrete businesses: software development, enterprise data management, image generation, and so on.\n--------------------\nAside from a first-mover advantage, it’s not clear that building a foundation model gives you any advantage in those businesses. Worse, the abundance of open source alternatives means that foundation models may not have any price leverage if they lose the competition at the application layer. This would turn companies like OpenAI and Anthropic into back-end suppliers in a low-margin commodity business — as one founder put it to me, “like selling coffee beans to Starbucks.”\n--------------------\nIt’s hard to overstate what a dramatic shift this would be for the business of AI. Throughout the contemporary boom, the success of AI has been inextricable from the success of the companies building foundation models — specifically, OpenAI, Anthropic, and Google. Being bullish on AI meant believing that AI’s transformative impact would make these into generationally important companies. We could argue about which company would come out on top, but it was clear that some foundation model company was going to end up with the keys to the kingdom.\n--------------------\nAt the time, there were lots of reasons to think this was true. For years, foundation model development was the only AI business there was — and the fast pace of progress made their lead seem insurmountable. And Silicon Valley has always had a deep-rooted love of platform advantage. The assumption was that, however AI models ended up making money, the lion’s share of the benefit would flow back to the foundation model companies, which had done the work that was hardest to replicate.\n--------------------\nThe past year has made that story more complicated. There are lots of successful third-party AI services, but they tend to use foundation models interchangeably. For startups, it no longer matters whether their product sits on top of GPT-5, Claude, or Gemini, and they expect to be able to switch models in mid-release without end users noticing the difference. Foundation models continue to make real progress, but it no longer seems plausible for any one company to maintain a large enough advantage to dominate the industry.\n--------------------\nWe already have plenty of indication that there is not much of a first-mover advantage. As venture capitalist Martin Casado of a16z pointed out on a recent podcast, OpenAI was the first lab to put out a coding model, as well as generative models for image and video — only to lose all three categories to competitors. “As far as we can tell, there is no inherent moat in the technology stack for AI,” Casado concluded.\n--------------------\nOf course, we shouldn’t count foundation model companies out just yet. There are still lots of durable advantages on their side, including brand recognition, infrastructure, and unthinkably vast cash reserves. OpenAI’s consumer business may prove harder to replicate than its coding business, and other advantages may emerge as the sector matures. Given the fast pace of AI development, the current interest in post-training could easily reverse course in the next six months. Most uncertain of all, the race toward general intelligence could pay off with new breakthroughs in pharmaceuticals or materials science, radically shifting our ideas about what makes AI models valuable.\n--------------------\nBut in the meantime, the strategy of building ever-bigger foundation models looks a lot less appealing than it did last year — and Meta’s billion-dollar spending spree is starting to look awfully risky.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "California lawmakers pass AI safety bill SB 53 — but Newsom could still veto",
    "url": "https://techcrunch.com/2025/09/13/california-lawmakers-pass-ai-safety-bill-sb-53-but-newsom-could-still-veto/",
    "content": "California’s state senate gave final approval early on Saturday morning to a major AI safety bill setting new transparency requirements on large companies.\n--------------------\nAs described by its author, state senator Scott Wiener, SB 53 “requires large AI labs to be transparent about their safety protocols, creates whistleblower protections for [employees] at AI labs & creates a public cloud to expand compute access (CalCompute).”\n--------------------\nThe bill now goes to California governor Gavin Newsom to sign or veto. He has not commented publicly on SB 53, but last year, he vetoed a more expansive safety bill also authored by Wiener, while signing narrower legislation targeting issues like deepfakes.\n--------------------\nAt the time, Newsom acknowledged the importance of “protecting the public from real threats posed by this technology,” but criticized Wiener’s previous bill for applying “stringent standards” to large models regardless of whether they were “deployed in high-risk environments, [involved] critical decision-making or the use of sensitive data.”\n--------------------\nWiener said the new bill was influenced by recommendations from a policy panel of AI experts that Newsom convened after his veto.\n--------------------\nPolitico also reports that SB 53 was recently amended so that companies developing “frontier” AI models while bringing in less than $500 million in annual revenue will only need to disclose high-level safety details, while companies making more than that will need to provide more detailed reports.\n--------------------\nA number of Silicon Valley companies, VC firms, and lobbying groups have criticized the bill, as well as broader efforts by states to regulate AI. In a recent letter to Newsom, OpenAI did not mention SB 53 specifically but argued that to avoid “duplication and inconsistencies,” companies should be considered compliant with statewide safety rules as long as they meet federal or European standards.\n--------------------\nAnd Andreessen Horowitz’s head of AI policy and chief legal officer recently claimed that ”many of today’s state AI bills — like proposals in California and New York — risk” crossing a line by violating constitutional limits on how states can regulate interstate commerce.\n--------------------\nAndreessen Horowitz’s co-founders had previously pointed to tech regulation as one of the factors leading them to back Donald Trump’s bid for a second term. The Trump administration and its allies subsequently called for a 10-year ban on state AI regulation.\n--------------------\nAnthropic, meanwhile, has come out in favor of SB 53.\n--------------------\n“We have long said we would prefer a federal standard,” said Anthropic co-founder Jack Clark in a post. “But in the absence of that this creates a solid blueprint for AI governance that cannot be ignored.”\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "xAI reportedly lays off 500 workers from data-annotation team",
    "url": "https://techcrunch.com/2025/09/13/xai-reportedly-lays-off-500-workers-from-data-annotation-team/",
    "content": "Posted:\n--------------------\nElon Musk’s AI startup xAI laid off 500 team members on Friday night, according to internal messages viewed by Business Insider.\n--------------------\nThese emails reportedly announce an immediate “strategic pivot,” with the company deciding to “accelerate the expansion and prioritization of our specialist AI tutors, while scaling back our focus on general AI tutor roles.”\n--------------------\n“As part of this shift in focus, we no longer need most generalist AI tutor positions and your employment with xAI will conclude,” xAI reportedly wrote.\n--------------------\nAccording to Business Insider, these cuts represent about one-third of xAI’s 1,500-person data-annotation team — the team that works to label and prepare data used to train xAI’s chatbot Grok.\n--------------------\nWhen contacted for confirmation, xAI pointed to a statement on X (the Musk-owned social network that xAI acquired earlier this year) declaring that the company “will immediately surge our Specialist AI tutor team by 10x.”\n--------------------\n“We are hiring across domains like STEM, finance, medicine, safety, and many more,” the company said.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Why the Oracle-OpenAI deal caught Wall Street by surprise",
    "url": "https://techcrunch.com/2025/09/12/why-the-oracle-openai-deal-caught-wall-street-by-surprise/",
    "content": "This week, OpenAI and Oracle shocked the markets with a surprise $300 billion, five-year agreement, part of a surge of new business that sent the cloud provider’s stock skyrocketing. But maybe the markets shouldn’t have been taken by surprise. The deal is a reminder that, despite Oracle’s legacy status, the company still plays a major role in AI infrastructure.\n--------------------\nOn the OpenAI side, the agreement was more revealing than the lack of details suggest. For one, the startup’s willingness to pay so much for compute provides a measurement of the startup’s appetite — even if it’s unclear where the electricity to power said compute is coming from or how it will pay for it.\n--------------------\nChirag Dekate, a vice president at research firm Gartner, told TechCrunch it’s clear why both sides were interested in this deal. It makes sense for OpenAI to work with several infrastructure providers, he noted. It also diversifies the company’s infrastructure — spreading out risk among several cloud providers — and gives OpenAI a scaling advantage compared to competitors.\n--------------------\n“OpenAI seems to be putting together one of the most comprehensive global AI supercomputing foundations for extreme scale, inference scaling where appropriate,” Dekate said. “This is quite unique. This is probably exemplary of what a model ecosystem should look like.”\n--------------------\nSome industry watchers expressed surprise that Oracle was involved, citing the company’s diminished role in the AI boom compared to cloud rivals like Google, Microsoft Azure, and AWS. But Dekate argues that observers shouldn’t be so surprised: Oracle has worked with hyperscalers before and provides the infrastructure for TikTok’s sizable U.S. business.\n--------------------\n“Over the decades, they actually built core infrastructure capabilities that enabled them to deliver extreme scale and performance as a core part of their cloud infrastructure,” Dekate said.\n--------------------\nBut even as the stock market celebrates the deal, key details are missing and questions around power and payment remain.\n--------------------\nOpenAI has made a string of infrastructure investment announcements over the past year, each one with an eye-popping price tag. OpenAI has committed to spend around $60 billion a year for compute from Oracle and $10 billion to develop custom AI chips with Broadcom.\n--------------------\nMeanwhile, OpenAI said in June it hit $10 billion in annual recurring revenue, up from around $5.5 billion last year. That figure includes revenue from the company’s consumer products, ChatGPT business products, and its API. And while its CEO Sam Altman has painted a rosy picture of its future prospects in terms of subscribers, products, and revenue, the company is burning through billions of dollars in cash each year.\n--------------------\nPower is another question, or more specifically where the companies plan to source the energy needed to run this level of compute.\n--------------------\nIndustry observers have been predicting a near-term boost for natural gas, though solar and batteries are arguably better positioned to deliver power sooner and at lower cost in many markets. Tech companies are also betting big on nuclear.\n--------------------\nDespite market moving headlines, the energy impact of OpenAI’s anticipated growth isn’t entirely unexpected. Data centers are anticipated to consume 14% of all electricity in the U.S. by 2040, according to a report the Rhodium Group published yesterday.\n--------------------\nCompute has always been a constraint for AI companies, so much so that investors have bought thousands of Nvidia chips to ensure their startups have access to the power they need. Andreessen Horowitz has reportedly purchased over 20,000 GPUs, while Nat Friedman and Daniel Gross rented access to a 4,000 GPU cluster (though maybe Meta owns that now).\n--------------------\nBut compute is worthless without power. To ensure their data centers remain juiced, large tech companies have been snapping up solar farms, buying nuclear power plants, and inking deals with geothermal startups.\n--------------------\nSo far, OpenAI has been relatively quiet on that front. CEO Sam Altman has placed several prominent bets in the energy sector, including Oklo, Helion, and Exowatt, but the company itself hasn’t thrown money into the space like Google, Meta, or Amazon.\n--------------------\nWith a 4.5 gigawatt compute deal, that may soon change.\n--------------------\nThe company may play an indirect role, paying Oracle to handle the physical infrastructure — something it has extensive experience with — just as Altman invested in startups aligned with OpenAI’s future power needs. That will leave the company “asset light,” something that will undoubtedly please its investors and help keep its valuation in line with other software-centric AI startups and not with legacy tech firms, which are burdened with pricey infrastructure.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Google is a ‘bad actor’ says People CEO, accusing the company of stealing content",
    "url": "https://techcrunch.com/2025/09/12/google-is-a-bad-actor-says-people-ceo-accusing-the-company-of-stealing-content/",
    "content": "The CEO of the largest digital and print publisher in the U.S. has accused Google of being a bad actor for crawling its websites to support the search giant’s AI products.\n--------------------\nNeil Vogel, CEO of People, Inc. (formerly Dotdash Meredith), a publisher that operates over 40 brands, including People, Food & Wine, Travel + Leisure, Better Homes & Gardens, Real Simple, Southern Living, Allrecipes, and others, said that Google is not playing fair because it uses the same bot to crawl websites to index them for the Google search engine as it does to support its AI features.\n--------------------\n“Google has one crawler, which means they use the same crawler for their search, where they still send us traffic, as they do for their AI products, where they steal our content,” said Vogel, speaking at the Fortune Brainstorm Tech conference this week.\n--------------------\nHe noted that three years ago, Google Search accounted for about 65% of the company’s traffic and that has since dropped to the “high 20s.” (Vogel shared an even more startling statistic with AdExchanger last month, saying that as of several years ago, Google’s traffic accounted for as much as 90% of People Inc.’s traffic from the open web.)\n--------------------\n“I’m not complaining. We’ve grown our audience. We’ve grown our revenue,” Vogel told conference attendees. “We’re doing great. What is not right about this is: You cannot take our content to compete with us.”\n--------------------\nVogel believes publishers need more leverage in the AI era, which is why he feels it’s necessary to block AI crawlers — automated programs that scan websites to train AI systems — as that can force them into content deals. His company, for example, has a deal with OpenAI, which Vogel described as a “good actor.”\n--------------------\nPeople Inc. has been leveraging web infrastructure company Cloudflare’s latest solution to block AI crawlers that don’t pay, prompting AI players to approach the publisher with potential content deals. While Vogel wouldn’t directly name the companies involved, he said they were “large LLM providers.” No deals have been signed yet, but Vogel said the company is “much further along” than before it adopted the crawler-blocking solution.\n--------------------\nHowever, Vogel pointed out, Google’s crawler can’t be blocked because doing so would also prevent the publisher’s websites from being indexed in Google Search, cutting off that “20%-ish” of traffic that Google still delivers.\n--------------------\n“They know this, and they’re not splitting their crawler. So they are an intentional bad actor here,” Vogel declared.\n--------------------\nJanice Min, the editor-in-chief and CEO at newsletter provider Ankler Media, agreed, calling Big Tech companies like Google and Meta longtime “content kleptomaniacs.”\n--------------------\n“I don’t see the benefit to us in partnering with any AI company right now,” she said, adding that her company blocks AI crawlers.\n--------------------\nMeanwhile, Cloudflare CEO Matthew Prince, whose company makes the AI-blocking solution (and who was also on the panel), said he believed that things would still change in the future when it comes to how the AI companies behave. He suspected those changes could be prompted by new regulations.\n--------------------\nThe Cloudflare exec also questioned whether fighting the AI companies using legal solutions around things like copyright law, created for the pre-AI era, was the right answer.\n--------------------\n“I think that it’s a fool’s errand to go down that path, because, in copyright law, typically, the more derivative something is, the more it’s protected under fair use … What these AI companies are doing is they’re actually creating derivatives,” Prince said. “And so if you look at the best case law that’s come out so far, it’s actually said that the use by Anthropic and others — the reason Anthropic settled recently with all the book publishers for $1.5 billion — was for them to be able to preserve the positive copyright ruling that they got.”\n--------------------\nPrince also proclaimed that “everything that’s wrong with the world today is, at some level, Google’s fault,” because the search giant had taught publishers to value traffic over original content creation, triggering publishers like BuzzFeed to write for clicks. Still, he admitted that Google was in a tough spot right now from a competitive standpoint.\n--------------------\n“Internally, they’re having massive fights about what they do, and my prediction is that, by this time next year, Google will be paying content creators for crawling their content and taking it and putting it in AI models,” he said.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Micro1, a competitor to Scale AI, raises funds at $500M valuation",
    "url": "https://techcrunch.com/2025/09/12/micro1-a-competitor-to-scale-ai-raises-funds-at-500m-valuation/",
    "content": "Micro1, a three-year-old startup that helps AI companies find and manage human contractors for data labeling and training, has raised a $35 million Series A funding round that values the company at $500 million. The round was led by 01 Advisors, a venture capital firm co-founded by Dick Costolo and Adam Bain, the former CEO and COO of Twitter.\n--------------------\nThe startup is one of many companies looking to fill the gap in the data market created by recent changes involving Scale AI. After Meta invested $14 billion in Scale AI and hired its CEO, AI labs, including OpenAI and Google, said they planned to cut ties with the startup, presumably over concerns that their research could end up in Meta’s hands. (Scale AI denies that it shares confidential information with Meta as part of its partnership.)\n--------------------\nHowever, AI labs still need these data services, and startups like Micro1 aim to pick up the slack.\n--------------------\nMicro1 CEO Ali Ansari — who is just 24 years old — tells TechCrunch that his company has been working with leading AI labs, including Microsoft, as well as several Fortune 100 companies. Ansari said Micro1 is now generating $50 million in annual recurring revenue (ARR), up from $7 million at the start of 2025.\n--------------------\nThat’s still a far cry from larger competitors like Mercor, which is generating more than $450 million in ARR, and Surge, which reportedly brought in $1.2 billion in 2024. However, Micro1’s growth and adoption among AI labs seems to be growing at a healthy rate.\n--------------------\nAs part of the new funding, Micro1 is also adding Bain to its board of directors, alongside Joshua Browder, founder and CEO of the AI legal assistant DoNotPay.\n--------------------\n“Really the only way models are now learning is through net new human data. Micro1 is at the core of providing that data to all frontier labs, while moving at speeds I’ve never seen before,” Bain said in a statement to TechCrunch.\n--------------------\nReuters previously reported details of Micro1’s fundraising efforts.\n--------------------\nAll these companies — Micro1, Surge, Mercor, and Scale AI — supply AI labs with access to a large base of human contractors who can label and generate data for AI training. It’s become a crucial service that companies like OpenAI, Anthropic, Meta, and Google need to build cutting-edge AI models.\n--------------------\nScale AI was first to dominate this space, with the initial insight that it could pay relatively little for low-skilled contractors around the world to help label data for AI model training. However, Ansari says that the demands of AI labs have shifted in recent years and that companies now need high-quality data labeling from domain experts — such as senior software engineers, doctors, and professional writers — to improve their AI models. The hard part became recruiting these types of folks.\n--------------------\nThis led Micro1 to build its AI recruiter, Zara, which interviews and vets candidates who apply to work as one of the company’s contractors, or as Ansari calls them, experts. Micro1 says Zara has recruited thousands of experts — including professors from Stanford and Harvard — and that the company plans to add hundreds more every week.\n--------------------\nThe market for AI training data appears to be changing yet again. Now, many AI labs are interested in working with startups to develop “environments” — virtual workspaces that can be used to train AI agents on simulated tasks. Ansari says Micro1 is building new offerings in the environments space to meet this demand.\n--------------------\nLuckily for startups like Micro1, AI labs seem to be working with multiple training data providers. The nature of the business is such that it’s difficult for any one company to handle all of one AI lab’s data needs. That means there’s plenty of business to go around, at least for now.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Last day to amplify your brand: Host your Side Event at TechCrunch Disrupt 2025",
    "url": "https://techcrunch.com/2025/09/12/last-day-to-amplify-your-brand-host-your-side-event-at-disrupt-2025/",
    "content": "The countdown is on: The application to host a Side Event at TechCrunch Disrupt 2025 closes tonight at 11:59 p.m. PT.\n--------------------\nIf you’ve been considering a way to amplify your brand during the week’s tech epicenter, now is the time to lock it in.\n--------------------\nYour Side Event could be the dinner everyone’s still talking about, the panel that sparks a deal, or the happy hour that launches a new collaboration.\n--------------------\nWith 10,000+ Disrupt attendees in San Francisco — plus the global spotlight of TechCrunch promotion — your event won’t just happen. It will resonate.\n--------------------\nApplications are free, but the deadline is final. Submit your proposal before it’s too late.\n--------------------\nApply now and make your event the one everyone remembers during Disrupt 2025.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "We are entering a golden age of robotics startups — and not just because of AI",
    "url": "https://techcrunch.com/2025/09/12/we-are-entering-a-golden-age-of-robotics-startups-and-not-just-because-of-ai/",
    "content": "When Seth Winterroth left his job at GE Ventures to help launch Eclipse in 2015, robotics was on his mind. Or more specifically, the number of early-stage robotics startups that were struggling to launch due to lack of interest.\n--------------------\n“These are teams that had just finished their postdocs at Waterloo, or CMU, or MIT and were starting robotics companies, and the refrain that I continually heard from the startups was, ‘Hey, we’re having a really hard time raising institutional venture capital,’” Winterroth told TechCrunch. “At the time in Silicon Valley, most venture capital was going into the very mature application layer or the application layer of some very mature computing platforms.”\n--------------------\nA lot has changed since then.\n--------------------\nNow, after investing in robotics startups for 10 years, Winterroth, a partner at Eclipse, said the time to invest in robotics has never been better. The robotics startup market has matured and the hardware and software powering these bots has gotten significantly better — and cheaper.\n--------------------\nVenture investing in the category is gaining momentum as well. Investors poured $6 billion into robotics startups in the first seven months of 2025 according to Crunchbase data. The data company predicts that this year’s funding totals will eclipse 2024, making it one of the only non-AI categories to experience a boost in funding.\n--------------------\nWhile one could argue that robotics is seeing a surge in investor interest because of AI — and it’s not wrong to acknowledge AI’s role in the advancement of robotic tech — investors who have focused on the category longer than the last few years said the industry didn’t get to this point just because of advancements in AI over the past few years.\n--------------------\nThe real catalyst for the industry to start gaining momentum actually happened back in 2012, Winterroth said, when Kiva Systems, a small startup based out of Massachusetts, got acquired by Amazon.\n--------------------\n“I like to say Kiva Systems’ acquisition was the acquisition that launched 1,000 robotic startups,” Winterroth said. “Between 2011 and 2015, 2016, that really was the case. You just saw a number of different new companies get started. Some like 6 River Systems, or Clearpath Robotics, were successful, but most were not. But that talent learns and that learning compounds, and it’s brought into the next set of ventures.”\n--------------------\nThis first wave helped attract engineers to the sector and helped companies figure out product-market-fit, he said.\n--------------------\nKira Noodleman, a partner at Bee Partners, echoed this. Noodleman told TechCrunch the last decade of trial and error helped startups figure out what the market is actually looking for when it comes to robotics and automation.\n--------------------\nSome companies, like Rapid Robotics, which Noodleman backed, shut down trying to figure out what the market wanted. Those failures have helped the next batch of startup founders, who now have a much better idea of what potential customers want from this sector.\n--------------------\nNoodleman had a similar experience with her own investing thesis, she said, which changed as the market matured.\n--------------------\n“Lights out manufacturing assumes there are zero humans in the loop; that is just not happening. We proved that already back in the 2010s,” Noodleman said. “Let me take a simple task, machine tending, all it is is someone’s hand putting something in and out of a machine. The point here is you can imagine how many low-hanging fruit, repetitive tasks there are, like machine tending.”\n--------------------\nFady Saad, a general partner at early-stage robotics-focused Cybernetix Ventures, also launched his firm prior to the AI boom after he noticed he was spending a lot of time connecting early-stage robotics companies to sources of funding during his time as a co-founder at MassRobotics.\n--------------------\nFalling hardware costs have also driven investor interest in the sector, Saad said, noting that it’s cheaper to build robots today than five years ago. This allows companies to have a more viable path to scale and makes them more attractive to potential venture backers.\n--------------------\n“The cost of building robotics has been going dramatically down,” Saad said. “Advances in sensor technology, compute, and batteries, all of that, it was the perfect timing to start full-stack robotics solutions.”\n--------------------\nAdvancements in AI aren’t hurting the industry either. While AI is being touted by many as the main reason why robotics are starting to see an increase in interest — alongside an Elon Musk-driven fascination with humanoid robots — it isn’t the only factor.\n--------------------\nSaad added that while AI and large language models can be helpful for training robots, these LLMs are primarily trained on online information, whereas robots interact with the real world.\n--------------------\nThere are companies building models based on that real-life data; Nvidia just released a new set of world models for robot training in August. But Saad predicted it will take a bit longer to capture and train robots, especially those that will exist alongside people, on world data.\n--------------------\nMomentum in the industry may be starting to swell, but that doesn’t mean every startup has figured out the best approach yet. Nor are some categories within robotics as mature as others.\n--------------------\nSome of the first few markets to adopt robotics and automation, including manufacturing, warehousing, and construction, continue to be attractive for robotics startup backers.\n--------------------\nFor Winterroth, Saad, and Noodleman, healthcare and surgical-related robots remain a compelling area to invest in too. Noodleman adds eldercare to that category as well.\n--------------------\n“In-home assistance is interesting, coming from me having looked at industrial robotics for 10 years,” Noodleman said. “Manufacturing and mining, burning labor shortages, aging populations, no humans are available at any price, even imperfect robotics are better than nothing.”\n--------------------\nSaad added that vertically focused robotics companies tend to have access to more real-world and physical data, too, than horizontal players.\n--------------------\nOne area that these VCs are not as excited about are humanoids or consumer — and especially not consumer-focused humanoids.\n--------------------\nSaad isn’t convinced that people will want to have a robot in their house anytime soon. He added that even non-humanoid consumer-focused robotics companies have struggled to get consumers excited.\n--------------------\n“The only successful consumer robot company, iRobot, failed to come up with a second act,” Saad said. “Pool cleaning robot, lawn mower, mopping and floor-cleaning robot, none of these worked out for whatever reason.”\n--------------------\nWhile the industry is still years away from commercial success of more intricate robotic models, like humanoids, VCs are pouring more capital into the sector. Despite the fact that this interest is driving up the costs of deals, the surge in interest is a net positive for the industry, Winterroth and Saad said, as the potential customer base for robotics startups continues to grow.\n--------------------\n“There are enough examples of successful commercial organizations, successful robotics companies, that have become a valuable commercial organization,” Winterroth said. “Ten, 15 years ago, it was questionable whether or not there was going to be a large and thriving marketplace for these types of solutions. Now there’s a lot of customer awareness.”\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "A California bill that would regulate AI companion chatbots is close to becoming law",
    "url": "https://techcrunch.com/2025/09/11/a-california-bill-that-would-regulate-ai-companion-chatbots-is-close-to-becoming-law/",
    "content": "California has taken a big step toward regulating AI. SB 243 — a bill that would regulate AI companion chatbots in order to protect minors and vulnerable users — passed both the State Assembly and Senate with bipartisan support and now heads to Governor Gavin Newsom’s desk.\n--------------------\nNewsom has until October 12 to either veto the bill or sign it into law. If he signs, it would take effect January 1, 2026, making California the first state to require AI chatbot operators to implement safety protocols for AI companions and hold companies legally accountable if their chatbots fail to meet those standards.\n--------------------\nThe bill specifically aims to prevent companion chatbots — which the legislation defines as AI systems that provide adaptive, human-like responses and are capable of meeting a user’s social needs — from engaging in conversations around suicidal ideation, self-harm, or sexually explicit content.\n--------------------\nThe bill would require platforms to provide recurring alerts to users — every three hours for minors — reminding them that they are speaking to an AI chatbot, not a real person, and that they should take a break. It also establishes annual reporting and transparency requirements for AI companies that offer companion chatbots, including major players OpenAI, Character.AI, and Replika, which would go into effect July 1, 2027.\n--------------------\nThe California bill would also allow individuals who believe they have been injured by violations to file lawsuits against AI companies seeking injunctive relief, damages (up to $1,000 per violation), and attorney’s fees.\n--------------------\nSB 243 was introduced in January by state senators Steve Padilla and Josh Becker. It gained momentum in the California legislature following the death of teenager Adam Raine, who committed suicide after prolonged chats with OpenAI’s ChatGPT that involved discussing and planning his death and self-harm. The legislation also responds to leaked internal documents that reportedly showed Meta’s chatbots were allowed to engage in “romantic” and “sensual” chats with children.\n--------------------\nIn recent weeks, U.S. lawmakers and regulators have responded with intensified scrutiny of AI platforms’ safeguards to protect minors. The Federal Trade Commission is preparing to investigate how AI chatbots impact children’s mental health. Texas attorney general Ken Paxton has launched investigations into Meta and Character.AI, accusing them of misleading children with mental health claims. Meanwhile, both Sen. Josh Hawley (R-MO) and Sen. Ed Markey (D-MA) have launched separate probes into Meta.\n--------------------\n“I think the harm is potentially great, which means we have to move quickly,” Padilla told TechCrunch. “We can put reasonable safeguards in place to make sure that particularly minors know they’re not talking to a real human being, that these platforms link people to the proper resources when people say things like they’re thinking about hurting themselves or they’re in distress, [and] to make sure there’s not inappropriate exposure to inappropriate material.”\n--------------------\nPadilla also stressed the importance of AI companies sharing data about the number of times they refer users to crisis services each year, “so we have a better understanding of the frequency of this problem, rather than only becoming aware of it when someone’s harmed or worse.”\n--------------------\nSB 243 previously had stronger requirements, but many were whittled down through amendments. For example, the bill originally would have required operators to prevent AI chatbots from using “variable reward” tactics or other features that encourage excessive engagement. These tactics, used by AI companion companies like Replika and Character, offer users special messages, memories, storylines, or the ability to unlock rare responses or new personalities, creating what critics call a potentially addictive reward loop.\n--------------------\nThe current bill also removes provisions that would have required operators to track and report how often chatbots initiated discussions of suicidal ideation or actions with users.\n--------------------\n“I think it strikes the right balance of getting to the harms without enforcing something that’s either impossible for companies to comply with, either because it’s technically not feasible or just a lot of paperwork for nothing,” Becker told TechCrunch.\n--------------------\nSB 243 is moving toward becoming law at a time when Silicon Valley companies are pouring millions of dollars into pro-AI political action committees (PACs) to back candidates in the upcoming midterm elections who favor a light-touch approach to AI regulation.\n--------------------\nThe bill also comes as California weighs another AI safety bill, SB 53, which would mandate comprehensive transparency reporting requirements. OpenAI has written an open letter to Governor Newsom, asking him to abandon that bill in favor of less stringent federal and international frameworks. Major tech companies like Meta, Google, and Amazon have also opposed SB 53. In contrast, only Anthropic has said it supports SB 53.\n--------------------\n“I reject the premise that this is a zero-sum situation, that innovation and regulation are mutually exclusive,” Padilla said. “Don’t tell me that we can’t walk and chew gum. We can support innovation and development that we think is healthy and has benefits — and there are benefits to this technology, clearly — and at the same time, we can provide reasonable safeguards for the most vulnerable people.”\n--------------------\n“We are closely monitoring the legislative and regulatory landscape, and we welcome working with regulators and lawmakers as they begin to consider legislation for this emerging space,” a Character.AI spokesperson told TechCrunch, noting that the startup already includes prominent disclaimers throughout the user chat experience explaining that it should be treated as fiction.\n--------------------\nA spokesperson for Meta declined to comment.\n--------------------\nTechCrunch has reached out to OpenAI, Anthropic, and Replika for comment.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "OpenAI secures Microsoft’s blessing to transition its for-profit arm",
    "url": "https://techcrunch.com/2025/09/11/openai-secures-microsofts-blessing-to-transition-its-for-profit-arm/",
    "content": "OpenAI announced Thursday it reached a nonbinding agreement with Microsoft, its largest investor, on a revised partnership that would allow the startup to convert its for-profit arm into a public benefit corporation (PBC).\n--------------------\nThe transition, should it be cleared by state regulators, could allow OpenAI to raise additional capital from investors and, eventually, become a public company.\n--------------------\nIn a blog post, OpenAI board chairman Bret Taylor said under the nonbinding agreement with Microsoft, OpenAI’s nonprofit would continue to exist and retain control over the startup’s operations. OpenAI’s nonprofit would obtain a stake in the company’s PBC, worth upward of $100 billion, Taylor said. Further terms of the deal were not disclosed.\n--------------------\n“Microsoft and OpenAI have signed a nonbinding memorandum of understanding (MOU) for the next phase of our partnership,” the companies said in a joint statement. MOUs are not legally binding but aim to document each party’s expectations and intent.\n--------------------\n“We are actively working to finalize contractual terms in a definitive agreement,” the joint statement added.\n--------------------\nThe development seems to mark an end to months of negotiations between OpenAI and Microsoft over the ChatGPT maker’s transition plans. Unlike most startups, OpenAI is controlled by a nonprofit board. The unusual structure allowed for OpenAI board members to fire CEO Sam Altman in 2023. Altman was reinstated days later, and many of the board members resigned. However, the same governance structure remains in place today.\n--------------------\nUnder their current deal, Microsoft is supposed to get preferred access to OpenAI’s technology and be the startup’s primary provider of cloud services. However, ChatGPT is a much larger business than when Microsoft first invested in the startup back in 2019, and OpenAI has reportedly sought to loosen the cloud provider’s control as part of these negotiations.\n--------------------\nIn the last year, OpenAI has struck a series of deals that would allow it to be less dependent on Microsoft. OpenAI recently signed a contract to spend $300 billion with cloud provider Oracle over a five-year period starting in 2027, according to the Wall Street Journal. OpenAI has also partnered with the Japanese conglomerate SoftBank on its Stargate data center project.\n--------------------\nTaylor says OpenAI and Microsoft will “continue to work with the California and Delaware attorneys general” on the transition plan, implying the deal still needs a stamp of approval from regulators before it can take effect.\n--------------------\nRepresentatives for California and Delaware attorneys general did not immediately respond to TechCrunch’s request for comment.\n--------------------\nTensions between OpenAI and Microsoft over these negotiations reportedly reached a boiling point in recent months. The Wall Street Journal reported Microsoft wanted control of technology owned by Windsurf, the AI coding startup that OpenAI had planned to acquire earlier this year, while OpenAI fought to keep the startup’s IP independent. However, the deal fell through, and Windsurf’s founders were hired by Google, and the rest of its staff was acquired by another startup, Cognition.\n--------------------\nIn Elon Musk’s lawsuit against OpenAI — which at its core accuses Sam Altman, Greg Brockman, and the company of abandoning its nonprofit mission — the startup’s for-profit transition is also a major flash point. Lawyers representing Musk in the lawsuit have tried to surface information related to Microsoft and OpenAI’s negotiations over the transition.\n--------------------\nMusk also submitted an unsolicited $97 billion takeover bid for OpenAI earlier this year, which the startup’s board promptly rejected. However, legal experts noted at the time that Musk’s bid may have raised the price of OpenAI’s nonprofit stake.\n--------------------\nNotably, the nonprofit’s stake in OpenAI PBC, under this agreement, is larger than what Musk offered.\n--------------------\nIn recent months, nonprofits such as Encode and The Midas Project have taken issue with OpenAI’s for-profit transition, arguing that it threatens the startup’s mission to develop AGI that benefits humanity. OpenAI has responded by sending subpoenas to some of these groups, claiming the nonprofits are funded by its competitors — namely, Musk and Meta CEO Mark Zuckerberg. Encode and The Midas Project deny the claims.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Apple’s iOS 26 with the new Liquid Glass design is now available to everyone",
    "url": "https://techcrunch.com/2025/09/15/apples-ios-26-with-the-new-liquid-glass-design-is-now-available-to-everyone/",
    "content": "Apple’s iOS 26 software update for iPhones is available Monday to people who have an iPhone 11, iPhone SE 2, and later. The marquee feature of iOS 26 is Apple’s Liquid Glass design, which includes elements on-screen that resembled a “glassy” look. Other features include a call screening assistant, a new gaming and preview app, in-app translation across the system, and updates to Genmoji and Image Playground apps.\n--------------------\nThe operating system update also went through a big numerical change as Apple jumped from iOS 18 to iOS 26 for two key reasons. First, it wanted to bring all operating systems — iOS, iPadOS, macOS, watchOS, tvOS, and VisionOS — in sync. And it also wanted to reflect the year number in which the majority of the people will use this update.\n--------------------\nLiquid Glass design has been the most significant visual overhaul for iOS in years. Apple’s intention with this redesign was to take inspiration from the Vision Pro interface and apply it to all of its operating systems. The elements are meant to look like they are made of translucent glass. This resulted in challenges in terms of readability and how elements in the background look.\n--------------------\nSince June, Apple has made several changes to how “glassy” the interface looks through beta releases. While the company is releasing the stable version of iOS 26 today, we might expect visual tweaks for improved readability and usability in the coming months. This visual change might take a bit of time for users to adjust, and they might not like certain elements right away.\n--------------------\nThe Phone app has a new unified look where your favorites are up top in a card format with recents and voicemails on the same screen. You can tap the filter button on the top right and look at these sections individually as well. (If you don’t like the new interface, Apple also gives you an option to switch to the classic look.)\n--------------------\nIn addition, iOS 26 brings a call-screening feature to iPhones, which is a personal favorite. When an unknown number calls you, the system asks for their name and the purpose of the call. Once they give this information, the system invokes the ringer and notifies you of the call. You can look at the conversation and interject at any time. Transcription of voicemail doesn’t work well for all languages, but call screening has reduced the number of calls I’ve had to pick up.\n--------------------\nThere’s also a holding assist for when a restaurant or a helpline places you on hold; you can use call assist to notify when an agent starts talking again.\n--------------------\nThe Messages app is getting to feature party with other chat apps like WhatsApp and Telegram with backgrounds, new conversation flow, polls, text selection, photo previews, and typing indicators in groups. Apple has been working on SMS filtering for a few years now. The company said it updated its spam filtering with this release. Plus, it places messages from unknown senders in a new folder. One thing I didn’t like about this update is that it takes me a couple of taps to go to the transactions tab.\n--------------------\nThe games app overhaul means that you can look at the games you are playing (or have played), arcade games, challenges, and achievements in one place, along with suggestions for new titles. The app also shows you what your friends are playing.\n--------------------\nApple finally added Mac’s Preview app to iOS 26, which means you can edit, annotate, and sign PDFs more easily.\n--------------------\nMeanwhile, Apple Music now has automixing for dynamic song switching, along with lyrics translation and pronunciation. What’s more, you can pin your favorite songs and playlists.\n--------------------\nWith iOS 26, Apple Maps lets you define preferred routes while commuting. In case your choice of route has more traffic or any incidents, Maps sends you a notification along with suggesting alternative routes. The app also lets you easily view visited places through a new places library.\n--------------------\nThe Camera app in iOS 26 adopts the Liquid Glass design with only Video and Photo options visible by default. You can scroll to the left or right to switch between different modes. Apple has placed some controls like Flash and Night mode on the top right, and you can switch them on/off with one touch. For more options like filters, styles, exposure controls, and timer, you can swipe up from the bottom of the screen.\n--------------------\nIf you didn’t like the previous Photos app design, the tabs are back in this version.\n--------------------\nUnlike last year’s grand launch of Apple Intelligence, this year’s operating system is light on AI features, especially given delays in launching and rolling out features. The company is making AI-powered translation easily available in apps like Messages, FaceTime, and Phone. Currently, this feature supports English (U.K., U.S.), French (France), German, Portuguese (Brazil), and Spanish (Spain).\n--------------------\nThrough iOS 26, the company is also launching live translation on AirPods, including the newly launched AirPods Pro 3, AirPods Pro 2, and AirPods 4.\n--------------------\nAlso, iOS 26 updates visual intelligence to understand the content on the screen. You have to press Power + the volume down button to bring up this menu. Apple Intelligence can then suggest events to add to your calendar. You can also ask questions about the content on the screen, using Google Visual Search or ChatGPT. Apple is also releasing its own “Circle to search” called Highlight.\n--------------------\nThe most confusing part about this update is that the buttons used to bring up on-screen visual intelligence are the same as the screenshot button. Because of this, it takes an extra step to save a screenshot, and I have forgotten to save some important screenshots.\n--------------------\nApple is updating Genmoji with iOS 26 to let you merge two emojis with a text prompt and make something new. You can now add expression to people in both Genmoji and Image Playground. Update to Image Playground now allows you to modify attributes like hair and facial hair, along with new styles from ChatGPT.\n--------------------\nWe have a list of tons of small but useful iOS features here. You can update to iOS 26 by going to Settings > General > Software Update and downloading the latest version.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Spotify will now let free users pick and play tracks",
    "url": "https://techcrunch.com/2025/09/15/spotify-will-now-let-free-users-pick-and-play-tracks/",
    "content": "Following its long-awaited launch of lossless streaming for paid subscribers, Spotify is upgrading its service for free users, too. On Monday, the company announced that free users globally will now be able to search and play any song they want or play a song shared by a friend or an artist they follow on social media.\n--------------------\nThe company calls the new features “Pick & Play,” “Search & Play,” and “Share & Play,” respectively. With the former, free users can hit play in the Spotify app to pick and play any song they want, or can even search for a particular song and play it.\n--------------------\nThe “Share & Play” feature could encourage free users to open Spotify when they come across music on social media. For instance, Instagram lets users share a Spotify track to Stories with sound and allows users to share music on Instagram Notes.\n--------------------\nPreviously, free users could shuffle songs with limited skips on mobile devices.\n--------------------\nSpotify says the new features will roll out globally to free users, but there will still be some restrictions that Premium users won’t face.\n--------------------\nWhen reached for clarification, the company told TechCrunch that users on the free mobile experience will have an allocation of “on-demand time,” and when they reach that daily limit, they’ll then be restricted to a limited number of skips per hour. Spotify did not share what that time limit is, but noted that Premium users will not have these restrictions.\n--------------------\nIn recent months, Spotify’s ad business has been struggling, with CEO Daniel Ek telling investors the company has been “moving too slowly” on this front. The streamer wants ad revenue to make up 20% of its overall revenue, but has grown it only to 11% as of June. By adding new free features, Spotify could boost engagement among its free user base, who would then be exposed to more ads.\n--------------------\nSpotify says that other features, like its support for lossless, AI Playlists, and Mix, will remain Premium-only offerings, while others like the newly launched Messages and personalized playlist daylist, available to global users, will span both the free and paid experiences, as they had before.\n--------------------\nThe company’s free users today make up the bulk of its user base. Out of Spotify’s 696 million monthly active users in the most recent quarter, 433 million were free, ad-supported customers. In addition, there were 276 million Premium (paying) subscribers in the quarter.\n--------------------\nUpdated after publication with more information about the restrictions impacting free users.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Vibe coding has turned senior devs into ‘AI babysitters,’ but they say it’s worth it",
    "url": "https://techcrunch.com/2025/09/14/vibe-coding-has-turned-senior-devs-into-ai-babysitters-but-they-say-its-worth-it/",
    "content": "Carla Rover once spent 30 minutes sobbing after having to restart a project she vibe coded.\n--------------------\nRover has been in the industry for 15 years, mainly working as a web developer. She’s now building a startup, alongside her son, that creates custom machine learning models for marketplaces.\n--------------------\nShe called vibe coding a beautiful, endless cocktail napkin on which one can perpetually sketch ideas. But dealing with AI-generated code that one hopes to use in production can be “worse than babysitting,” she said, as these AI models can mess up work in ways that are hard to predict.\n--------------------\nShe had turned to AI coding in a need for speed with her startup, as is the promise of AI tools.\n--------------------\n“Because I needed to be quick and impressive, I took a shortcut and did not scan those files after the automated review,” she said. “When I did do it manually, I found so much wrong. When I used a third-party tool, I found more. And I learned my lesson.”\n--------------------\nShe and her son wound up restarting their whole project — hence the tears. “I handed it off like the copilot was an employee,” she said. “It isn’t.”\n--------------------\nRover is like many experienced programmers turning to AI for coding help. But such programmers are also finding themselves acting like AI babysitters — rewriting and fact-checking the code the AI spits out.\n--------------------\nA recent report by content delivery platform company Fastly found that at least 95% of the nearly 800 developers it surveyed said they spend extra time fixing AI-generated code, with the load of such verification falling most heavily on the shoulders of senior developers.\n--------------------\nThese experienced coders have discovered issues with AI-generated code ranging from hallucinating package names to deleting important information and security risks. Left unchecked, AI code can leave a product far more buggy than what humans would produce.\n--------------------\nWorking with AI-generated code has become such a problem that it’s given rise to a new corporate coding job known as “vibe code cleanup specialist.”\n--------------------\nTechCrunch spoke to experienced coders about their time using AI-generated code about what they see as the future of vibe coding. Thoughts varied, but one thing remained certain: The technology still has a long way to go.\n--------------------\n“Using a coding co-pilot is kind of like giving a coffee pot to a smart six-year-old and saying, ‘Please take this into the dining room and pour coffee for the family,’” Rover said.\n--------------------\nCan they do it? Possibly. Could they fail? Definitely. And most likely, if they do fail, they aren’t going to tell you. “It doesn’t make the kid less clever,” she continued. “It just means you can’t delegate [a task] like that completely.”\n--------------------\nFeridoon Malekzadeh also compared vibe coding to a child.\n--------------------\nHe’s worked in the industry for more than 20 years, holding various roles in product development, software, and design. He’s building his own startup and heavily using vibe-coding platform Lovable, he said. For fun, he also vibe codes apps like one that generates Gen Alpha slang for Boomers.\n--------------------\nHe likes that he’s able to work alone on projects, saving time and money, but agrees that vibe coding is not like hiring an intern or a junior coder. Instead, vibe coding is akin to “hiring your stubborn, insolent teenager to help you do something,” he told TechCrunch.\n--------------------\n“You have to ask them 15 times to do something,” he said. “In the end, they do some of what you asked, some stuff you didn’t ask for, and they break a bunch of things along the way.”\n--------------------\nMalekzadeh estimates he spends around 50% of his time writing requirements, 10% to 20% of his time on vibe coding, and 30% to 40% of his time on vibe fixing — remedying the bugs and “unnecessary script” created by AI-written code.\n--------------------\nHe also doesn’t think vibe coding is the best at systems thinking — the process of seeing how a complex problem could impact an overall result. AI-generated code, he said, tries to solve more surface-level problems.\n--------------------\n“If you’re creating a feature that should be broadly available in your product, a good engineer would create that once and make it available everywhere that it’s needed,” Malekzadeh said. “Vibe coding will create something five different times, five different ways, if it’s needed in five different places. It leads to a lot of confusion, not only for the user, but for the model.”\n--------------------\nMeanwhile, Rover finds that AI “runs into a wall” when data conflicts with what it was hard-coded to do. “It can offer misleading advice, leave out key elements that are vital, or insert itself into a thought pathway you’re developing,” she said.\n--------------------\nShe also found that rather than admit to making errors, it will manufacture results.\n--------------------\nShe shared another example with TechCrunch, where she questioned the results an AI model initially gave her. The model started to give a detailed explanation pretending it used the data she uploaded. Only when she called it out did the AI model confess.\n--------------------\n“It freaked me out because it sounded like a toxic co-worker,” she said.\n--------------------\nOn top of this, there are the security concerns.\n--------------------\nAustin Spires is the senior director of developer enablement at Fastly and has been coding since the early 2000s.\n--------------------\nHe’s found through his own experience — along with chatting with customers — that vibe code likes to build what is quick rather than what is “right.” This may introduce vulnerabilities to the code of the kind that very new programmers tend to make, he said.\n--------------------\n“What often happens is the engineer needs to review the code, correct the agent, and tell the agent that they made a mistake,” Spires told TechCrunch. “This pattern is why we’ve seen the trope of ‘you’re absolutely right’ appear over social media.”\n--------------------\nHe’s referring to how AI models, like Anthropic Claude, tend to respond “you’re absolutely right” when called out on their mistakes.\n--------------------\nMike Arrowsmith, the chief trust officer at the IT management software company NinjaOne, has been in software engineering and security for around 20 years. He said that vibe coding is creating a new generation of IT and security blind spots to which young startups in particular are susceptible.\n--------------------\n“Vibe coding often bypasses the rigorous review processes that are foundational to traditional coding and crucial to catching vulnerabilities,” he told TechCrunch.\n--------------------\nNinjaOne, he said, counters this by encouraging “safe vibe coding,” where approved AI tools have access controls, along with mandatory peer review and, of course, security scanning.\n--------------------\nWhile nearly everyone we spoke to agrees that AI-generated code and vibe-coding platforms are useful in many situations — like mocking up ideas — they all agree that human review is essential before building a business on it.\n--------------------\n“That cocktail napkin is not a business model,” Rover said. “You have to balance the ease with insight.”\n--------------------\nBut for all the lamenting on its errors, vibe coding has changed the present and the future of the job.\n--------------------\nRover said vibe coding helped her tremendously in crafting a better user interface. Malekzadeh simply said that, despite the time he spends fixing code, he still gets more done with AI coders than without them.\n--------------------\n“‘Every technology carries its own negativity, which is invented at the same time as technical progress,” Malekzadeh said, quoting the French theorist Paul Virilio, who spoke about inventing the shipwreck along with the ship.\n--------------------\nThe Fastly survey found that senior developers were twice as likely to put AI-generated code into production compared to junior developers, saying that the technology helped them work faster.\n--------------------\nVibe coding is also part of Spires’ coding routine. He uses AI coding agents on several platforms for both front-end and back-end personal projects. He called the technology a mixed experience but said it’s good in helping with prototyping, building out boilerplate, or scaffolding out a test; it removes menial tasks so that engineers can focus on building, shipping, and scaling products.\n--------------------\nIt seems the extra hours spent combing through the vibe weeds will simply become a tolerated tax on using the innovation.\n--------------------\nElvis Kimara, a young engineer, is learning that now. He just graduated with a master’s in AI and is building an AI-powered marketplace.\n--------------------\nLike many coders, he said vibe coding has made his job harder and has often found vibe coding a joyless experience.\n--------------------\n“There’s no more dopamine from solving a problem by myself. The AI just figures it out,” he said. At one of his last jobs, he said senior developers didn’t look to help young coders as much — some not understanding new vibe-coding models, while others delegated mentorship tasks to said AI models.\n--------------------\nBut, he said, “the pros far outweigh the cons,” and he’s prepared to pay the innovation tax.\n--------------------\n“We won’t just be writing code; we’ll be guiding AI systems, taking accountability when things break, and acting more like consultants to machines,” Kimara said of the new normal for which he’s preparing.\n--------------------\n“Even as I grow into a senior role, I’ll keep using it,” he continued. “It’s been a real accelerator for me. I make sure I review every line of AI-generated code so I learn even faster from it.”\n--------------------\nThis post was updated to reflect the proper title of Mike Arrowsmith.\n--------------------\n\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Why the Oracle-OpenAI deal caught Wall Street by surprise",
    "url": "https://techcrunch.com/2025/09/12/why-the-oracle-openai-deal-caught-wall-street-by-surprise/",
    "content": "This week, OpenAI and Oracle shocked the markets with a surprise $300 billion, five-year agreement, part of a surge of new business that sent the cloud provider’s stock skyrocketing. But maybe the markets shouldn’t have been taken by surprise. The deal is a reminder that, despite Oracle’s legacy status, the company still plays a major role in AI infrastructure.\n--------------------\nOn the OpenAI side, the agreement was more revealing than the lack of details suggest. For one, the startup’s willingness to pay so much for compute provides a measurement of the startup’s appetite — even if it’s unclear where the electricity to power said compute is coming from or how it will pay for it.\n--------------------\nChirag Dekate, a vice president at research firm Gartner, told TechCrunch it’s clear why both sides were interested in this deal. It makes sense for OpenAI to work with several infrastructure providers, he noted. It also diversifies the company’s infrastructure — spreading out risk among several cloud providers — and gives OpenAI a scaling advantage compared to competitors.\n--------------------\n“OpenAI seems to be putting together one of the most comprehensive global AI supercomputing foundations for extreme scale, inference scaling where appropriate,” Dekate said. “This is quite unique. This is probably exemplary of what a model ecosystem should look like.”\n--------------------\nSome industry watchers expressed surprise that Oracle was involved, citing the company’s diminished role in the AI boom compared to cloud rivals like Google, Microsoft Azure, and AWS. But Dekate argues that observers shouldn’t be so surprised: Oracle has worked with hyperscalers before and provides the infrastructure for TikTok’s sizable U.S. business.\n--------------------\n“Over the decades, they actually built core infrastructure capabilities that enabled them to deliver extreme scale and performance as a core part of their cloud infrastructure,” Dekate said.\n--------------------\nBut even as the stock market celebrates the deal, key details are missing and questions around power and payment remain.\n--------------------\nOpenAI has made a string of infrastructure investment announcements over the past year, each one with an eye-popping price tag. OpenAI has committed to spend around $60 billion a year for compute from Oracle and $10 billion to develop custom AI chips with Broadcom.\n--------------------\nMeanwhile, OpenAI said in June it hit $10 billion in annual recurring revenue, up from around $5.5 billion last year. That figure includes revenue from the company’s consumer products, ChatGPT business products, and its API. And while its CEO Sam Altman has painted a rosy picture of its future prospects in terms of subscribers, products, and revenue, the company is burning through billions of dollars in cash each year.\n--------------------\nPower is another question, or more specifically where the companies plan to source the energy needed to run this level of compute.\n--------------------\nIndustry observers have been predicting a near-term boost for natural gas, though solar and batteries are arguably better positioned to deliver power sooner and at lower cost in many markets. Tech companies are also betting big on nuclear.\n--------------------\nDespite market moving headlines, the energy impact of OpenAI’s anticipated growth isn’t entirely unexpected. Data centers are anticipated to consume 14% of all electricity in the U.S. by 2040, according to a report the Rhodium Group published yesterday.\n--------------------\nCompute has always been a constraint for AI companies, so much so that investors have bought thousands of Nvidia chips to ensure their startups have access to the power they need. Andreessen Horowitz has reportedly purchased over 20,000 GPUs, while Nat Friedman and Daniel Gross rented access to a 4,000 GPU cluster (though maybe Meta owns that now).\n--------------------\nBut compute is worthless without power. To ensure their data centers remain juiced, large tech companies have been snapping up solar farms, buying nuclear power plants, and inking deals with geothermal startups.\n--------------------\nSo far, OpenAI has been relatively quiet on that front. CEO Sam Altman has placed several prominent bets in the energy sector, including Oklo, Helion, and Exowatt, but the company itself hasn’t thrown money into the space like Google, Meta, or Amazon.\n--------------------\nWith a 4.5 gigawatt compute deal, that may soon change.\n--------------------\nThe company may play an indirect role, paying Oracle to handle the physical infrastructure — something it has extensive experience with — just as Altman invested in startups aligned with OpenAI’s future power needs. That will leave the company “asset light,” something that will undoubtedly please its investors and help keep its valuation in line with other software-centric AI startups and not with legacy tech firms, which are burdened with pricey infrastructure.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Elon Musk’s Boring Company suspends work on Vegas airport tunnel after ‘crushing injury’",
    "url": "https://techcrunch.com/2025/09/11/elon-musks-boring-company-suspends-work-on-vegas-airport-tunnel-after-crushing-injury/",
    "content": "Posted:\n--------------------\nElon Musk’s Boring Company has reportedly stopped work on a tunnel it’s been digging to the Las Vegas airport after a worker sustained a “crushing injury” late Wednesday night, according to Fortune.  Nevada’s Occupational Safety and Health Administration (OSHA) has opened an investigation.\n--------------------\nThe Clark County Fire Department received a call at 10:12 p.m. local time on Wednesday and dispatched an 18-person rescue crew to the site. It’s unclear exactly what happened to the worker, but the individual was lifted out of the job site by the local fire department, which used an on-site crane. The fire department told Fortune the worker is “reported to be stable.”\n--------------------\nThe Boring Company has spent the last few years digging tunnels that connect the Las Vegas Convention Center with a small number of nearby hotel casinos. The underground transportation system has provided over 3 million rides across the 3.5 miles of tunnels currently in service. The company has much larger ambitions of connecting nearly all of Las Vegas by underground tunnels, including the airport.\n--------------------\nBut dozens of workers have been injured during construction of these tunnels, and even the company’s former safety manager for the Las Vegas project has publicly voiced concerns about the dangers faced at these sites.\n--------------------\n\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Google is shutting down Tables, its Airtable rival",
    "url": "https://techcrunch.com/2025/09/11/google-is-shutting-down-tables-its-airtable-rival/",
    "content": "Google Tables, a work-tracking tool and competitor to the popular spreadsheet-database hybrid Airtable, is shutting down.\n--------------------\nIn an email sent to Tables users this week, Google said the app will not be supported after December 16, 2025, and advised that users export or migrate their data to either Google Sheets or AppSheet instead, depending on their needs.\n--------------------\nLaunched in 2020, Tables focused on making project tracking more efficient with automation. It was one of the many projects to emerge from Google’s in-house app incubator, Area 120, which at the time was devoted to cranking out a number of experimental projects. Some of these projects later graduated to become a part of Google’s core offerings across Cloud, Search, Shopping, and more.\n--------------------\nTables was one of those early successes: Google said in 2021 that the service was moving from a beta test to become an official Google Cloud product. At the time, the company said it saw Tables as a potential solution for a variety of use cases, including project management, IT operations, customer service tracking, CRM, recruiting, product development and more.\n--------------------\nThe app was created by Google employee Tim Gleason, who had spent over a decade at the company. Gleason later moved on to become a tech lead manager for NotebookLM before announcing that he would retire beginning September 2024.\n--------------------\nArea 120, meanwhile, was the victim of a Google re-org in 2022, when the company canceled half its projects and informed staff that a reduction in force would cut the in-house R&D division to half its size. The division that remained would focus on AI projects, Google said.\n--------------------\nThe following year, Area 120 was wound down amid broader layoffs, and a small handful of projects would move on to core Google product areas. (One of those was Aloud, which was building tools that let creators quickly dub their videos. YouTube announced an auto-dubbing feature in 2023 that became more broadly available this year.)\n--------------------\nTables had survived these changes, as it was a part of Google Workspace’s team under Google Cloud. Unfortunately for Tables users, the service now has its own end-of-life date, too.\n--------------------\nIn the email, Google advises Tables admins to export their data either directly to Google Sheets, then continue to manage their workflow in Sheets using tables and conditional notifications, or take advantage of a new migration tool to import their data to Google’s no-code platform, AppSheet. The latter solution preserves formatting like column types and relationships, and the workflow can then be managed with automations, fine-grained permissions, and Workspace integrations, Google says.\n--------------------\nThe company earlier this month announced the coming closure on Table’s website and directed users to an FAQ, which noted that the team behind Tables had created a new data experience to power automated apps and workflows directly inside AppSheet. This alternative, launched in June 2023, lets users build data models for custom apps and workflows directly within AppSheet, the company said.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  },
  {
    "title": "Spotify is finally launching support for lossless music streaming",
    "url": "https://techcrunch.com/2025/09/10/spotify-is-finally-launching-support-for-lossless-music-streaming/",
    "content": "Spotify is finally launching high-quality, lossless music streaming support for premium account holders after years of waiting.\n--------------------\nThe company first talked about a hi-fi tier in 2021 — which would offer CD-quality audio — but the plan faced multiple delays, partially due to licensing issues. Last year, CEO Daniel Ek said that the company was in the “early days” of launching lossless streaming support.\n--------------------\nOver the past few years, reports and code hints in the app suggested that the company was planning to introduce a more expensive tier for lossless music as well.\n--------------------\nNow the company is finally releasing support for up to 24-bit/44.1 kHz FLAC quality streaming — a format that preserves the original audio quality without compression — for paid users.\n--------------------\nThe company said lossless streaming will be rolling out to users in over 50 countries through October. It added that subscribers in Australia, Austria, Czechia, Denmark, Germany, Japan, New Zealand, the Netherlands, Portugal, Sweden, the U.S., and the U.K. are already getting access.\n--------------------\nUsers will get a notification on their app when they get access to lossless streaming. You can enable the feature from Settings and Privacy > Media Quality > and selecting “Lossless” quality for streaming on Wi-Fi, cellular data, and downloads.\n--------------------\nThe company said that the feature is available across devices, but you have to manually enable it for each device. That means the setting doesn’t apply to all the devices you use with your Spotify account automatically.\n--------------------\nAs files with lossless streaming are larger, you will be able to keep track of how much data you have used for streaming. While you can stream lossless quality tracks over Wi-Fi, this is not possible for Bluetooth-connected devices due to bandwidth limitations.\n--------------------\nYou can use Spotify Connect to connect to devices from companies like Bose, Yamaha, and Bluesound to stream the music over Wi-Fi. Notably, Apple has also previously complained about Bluetooth’s bandwidth restrictions for streaming high-quality music.\n--------------------\nSpotify is late to deliver on its promises of making lossless music available to users. Rivals like Apple Music rolled it out in 2021, and Amazon Music made its lossless streaming free after launching a paid HD tier in 2019. Spotify said that this launch covers “nearly every track” in its 100-million-song library, so there might be some tracks without lossless support.\n--------------------\nTopics\n--------------------\n© 2025 TechCrunch Media LLC.\n--------------------\n"
  }
]