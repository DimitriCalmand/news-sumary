[
  {
    "title": "6 days left: Last chance for Regular Bird savings for TechCrunch Disrupt 2025 passes",
    "url": "https://techcrunch.com/2025/09/21/6-days-left-last-chance-for-regular-bird-pricing/",
    "content": "### RÃ©sumÃ©\nTechCrunch Disrupt 2025, qui se tiendra Ã  San Francisco du 27 au 29 octobre, est un Ã©vÃ©nement incontournable pour les innovateurs. Les inscriptions Ã  tarif rÃ©duit sont disponibles jusqu'au 26 septembre Ã  23h59 PT, permettant d'Ã©conomiser jusqu'Ã  668$.\n\n### ğŸ“¢ **TechCrunch Disrupt 2025 : Ne manquez pas l'Ã©vÃ©nement de l'annÃ©e !**\n\nğŸ“… **Dates et lieu**\nTechCrunch Disrupt 2025 se dÃ©roulera Ã  **San Francisco**, plus prÃ©cisÃ©ment au **Moscone West**, du **27 au 29 octobre**.\n\nğŸŸï¸ **Ã‰conomisez jusqu'Ã  668$**\nNe manquez pas l'occasion de **sauvegarder jusqu'Ã  668$** sur votre billet en vous inscrivant avant le **26 septembre Ã  23h59 PT**. Les prix augmenteront dans **6 jours** !\n\nğŸ’¡ **Un Ã©vÃ©nement incontournable**\nTechCrunch Disrupt 2025 est le lieu oÃ¹ les **idÃ©es les plus audacieuses** se concrÃ©tisent et oÃ¹ les **frontlines de l'innovation** brillent. CÃ©lÃ©brez le **20e anniversaire** de cet Ã©vÃ©nement emblÃ©matique !\n\nğŸ“¢ **Ne manquez pas cette opportunitÃ©**\nNe laissez pas passer cette chance de participer Ã  l'un des Ã©vÃ©nements les plus prestigieux de l'industrie technologique. **Inscrivez-vous dÃ¨s maintenant** pour profiter des tarifs avantageux !\n\nÂ© 2025 TechCrunch Media LLC.\n\n",
    "has_been_pretreat": true,
    "rating": null,
    "time_spent": 57,
    "comments": "",
    "tags": [],
    "id": 0
  },
  {
    "title": "Updates to Studio, YouTube Live, new gen AI tools, and everything else announced at Made on YouTube",
    "url": "https://techcrunch.com/2025/09/20/updates-to-studio-youtube-live-new-gen-ai-tools-and-everything-else-announced-at-made-on-youtube/",
    "content": "### RÃ©sumÃ©\nLors de l'Ã©vÃ©nement annuel Made on YouTube, la plateforme a prÃ©sentÃ© de nombreuses nouvelles fonctionnalitÃ©s et outils destinÃ©s aux crÃ©ateurs, notamment des mises Ã  jour pour YouTube Live, de nouvelles faÃ§ons de monÃ©tiser, et des outils d'IA pour les podcasteurs.\n\n## ğŸ¥ **NouveautÃ©s pour les crÃ©ateurs**\n\n### ğŸ› ï¸ **Mises Ã  jour de Studio**\nYouTube a dÃ©voilÃ© de nouvelles fonctionnalitÃ©s pour **Studio**, l'outil utilisÃ© par les crÃ©ateurs pour gÃ©rer leurs chaÃ®nes et suivre leurs statistiques. Parmi les nouveautÃ©s :\n- Un **onglet d'inspiration**\n- Des **tests A/B pour les titres**\n- Le **doublage automatique**\n- La **dÃ©tection de ressemblance** (en version bÃªta ouverte), permettant de dÃ©tecter et gÃ©rer les vidÃ©os non autorisÃ©es utilisant l'image d'une personne.\n- Un **Ask Studio** alimentÃ© par l'IA pour guider les utilisateurs et rÃ©pondre Ã  leurs questions.\n- La possibilitÃ© de **collaborer Ã  plusieurs** sur une mÃªme vidÃ©o.\n\n### ğŸ® **Mises Ã  jour de YouTube Live**\nYouTube Live propose dÃ©sormais :\n- Des **minijeux** pour divertir les spectateurs.\n- La **diffusion simultanÃ©e** en formats horizontal et vertical.\n- Des **moments forts** gÃ©nÃ©rÃ©s par l'IA, transformant les meilleurs moments d'un live en **Shorts partageables**.\n- Un nouveau format publicitaire **\"side-by-side\"**, qui s'affiche Ã  cÃ´tÃ© du contenu principal sans interrompre le flux.\n\n### ğŸ¬ **NouveautÃ©s pour Shorts**\nYouTube intÃ¨gre une version personnalisÃ©e de **Veo 3**, le modÃ¨le d'IA text-to-video de Google, dans Shorts. Les crÃ©ateurs peuvent :\n- Appliquer du mouvement Ã  une image.\n- Ajouter diffÃ©rents styles Ã  leurs vidÃ©os.\n- InsÃ©rer des objets avec une simple commande textuelle.\n- Transformer le dialogue de vidÃ©os Ã©ligibles en **bandes-son** pour d'autres Shorts grÃ¢ce Ã  **Lyria 2**, le modÃ¨le de musique gÃ©nÃ©rative de Google.\n- Utiliser un nouvel outil de **remix** et une fonction **\"Ã‰diter avec l'IA\"**.\n\n### ğŸ§ **Mises Ã  jour pour YouTube Music**\nYouTube Music propose de nouvelles fonctionnalitÃ©s pour renforcer l'engagement entre les crÃ©ateurs et leurs fans :\n- Un **compte Ã  rebours** pour les nouvelles sorties.\n- Des **vidÃ©os \"merci\"** pour les fans.\n- Un programme pilote pour les auditeurs amÃ©ricains, leur permettant d'accÃ©der Ã  des **drops de marchandises exclusives** d'artistes.\n\n### ğŸ™ï¸ **NouveautÃ©s pour les podcasts vidÃ©o**\nLes crÃ©ateurs de podcasts vidÃ©o aux Ã‰tats-Unis pourront :\n- CrÃ©er des **clips plus facilement** grÃ¢ce Ã  des suggestions d'IA.\n- Transformer des **podcasts audio en podcasts vidÃ©o** grÃ¢ce Ã  une nouvelle fonctionnalitÃ© qui sera disponible l'annÃ©e prochaine.\n\n### ğŸ’° **Nouveaux moyens de monÃ©tisation**\nYouTube offre de nouvelles faÃ§ons pour les crÃ©ateurs de **monÃ©tiser** leur contenu :\n- Des **accords de marque** et le programme **YouTube Shopping**, permettant de gagner de l'argent en mettant en avant et en Ã©tiquetant des produits.\n- La possibilitÃ© de **remplacer les parrainages de marque** dans les vidÃ©os longues.\n- Des **liens de marque** pour les Shorts, avec des suggestions de crÃ©ateurs pertinents pour les marques dans le hub des partenariats crÃ©ateurs.\n\n",
    "has_been_pretreat": true,
    "rating": null,
    "time_spent": 10,
    "comments": "",
    "tags": [],
    "id": 1
  },
  {
    "title": "Lincoln Centerâ€™s Collider Fellows explore how tech could transform the performing arts",
    "url": "https://techcrunch.com/2025/09/20/lincoln-centers-collider-fellows-explore-how-tech-could-transform-the-performing-arts/",
    "content": "### RÃ©sumÃ©\nLe Lincoln Center for the Performing Arts lance sa deuxiÃ¨me promotion de Collider Fellows, un programme accueillant des artistes multidisciplinaires explorant l'impact des technologies Ã©mergentes sur les arts vivants. Les six nouveaux fellows travaillent avec des technologies comme la rÃ©alitÃ© virtuelle, l'intelligence artificielle et le systÃ¨me 4DSound. Le programme offre un espace de travail, une bourse financiÃ¨re et un soutien pour une durÃ©e de neuf mois, sans obligation de projet final.\n\n---\n\n### ğŸ­ **Lincoln Center lance sa deuxiÃ¨me promotion de Collider Fellows**\n\nÃ€ une Ã©poque marquÃ©e par l'anxiÃ©tÃ© face Ã  l'impact de la technologie sur les arts et la culture, le **Lincoln Center for the Performing Arts** se concentre sur les **nouvelles opportunitÃ©s** avec son programme **Collider Fellowship**. Ce programme accueille des artistes multidisciplinaires pour explorer comment les technologies Ã©mergentes peuvent transformer les **performances live** et les arts vivants.\n\nAujourd'hui, le cÃ©lÃ¨bre centre des arts de New York annonce sa **deuxiÃ¨me promotion de Collider Fellows** â€” un groupe de six artistes travaillant dans des domaines allant de la **rÃ©alitÃ© virtuelle** Ã  l'**intelligence artificielle**, en passant par le **systÃ¨me immersif 4DSound**.\n\n#### ğŸ’¡ **Une vision optimiste de la technologie dans les arts**\nJordana Leigh, vice-prÃ©sidente de la programmation au Lincoln Center, a dÃ©clarÃ© : *\"J'aime qu'ils soient tous des personnes vraiment rÃ©flÃ©chies qui ne pensent pas seulement Ã  l'Å“uvre elle-mÃªme, mais Ã  la maniÃ¨re dont elle s'inscrit dans une conversation plus large sur les arts et la technologie.\"*\n\nLeigh, une *\"optimiste Ã©ternelle\"* quant aux bÃ©nÃ©fices de la technologie pour les arts, a ajoutÃ© que l'**IA** peut Ãªtre un **\"outil supplÃ©mentaire dans la boÃ®te Ã  outils des artistes\"**, comme un **mÃ©langeur de son** ou un **pinceau pour la peinture**. Elle a Ã©galement soulignÃ© que pour certains artistes, *\"la technologie rattrape leur vision, plutÃ´t que leur vision ne rattrape pas la technologie.\"*\n\n#### ğŸŒŸ **Un exemple inspirant : Dream Machine**\nPour illustrer ce potentiel, Leigh a citÃ© une rÃ©cente commission arts et tech du Lincoln Center, **Dream Machine** de Nona Hendryx. En utilisant une combinaison d'**IA**, de **VR** et de **rÃ©alitÃ© augmentÃ©e**, cette Å“uvre immerge les visiteurs, en particulier les visiteurs **BIPOC**, dans des environnements **Afrofuturistes**. Selon Leigh, Dream Machine montre comment l'art peut aider *\"les personnes qui ne se voient pas dans la technologie Ã  commencer Ã  s'y voir â€” en particulier les personnes noires et brunes, surtout les femmes noires et brunes.\"*\n\n*\"Je pense que plus il y a de personnes qui participent Ã  la conversation, plus nous avons de chances que ce soit une bonne conversation,\"* a-t-elle ajoutÃ©.\n\n#### ğŸ“ **Le programme Collider Fellowship**\nLes nouveaux **Collider Fellows**, sÃ©lectionnÃ©s par un processus de nomination, continueront Ã  explorer ce potentiel. Pendant les **neuf prochains mois**, ils bÃ©nÃ©ficieront d'un **espace de travail** au Lincoln Center et Ã  Onassis ONX, ainsi que d'une **bourse financiÃ¨re** et d'un **soutien** de la part du personnel du Lincoln Center.\n\nLeigh a prÃ©cisÃ© que le **Collider Fellowship** fait partie d'une **plus large gamme de programmes** par lesquels le centre des arts vivants cherche Ã  soutenir les artistes de maniÃ¨re *\"non transactionnelle\"*. Notamment, la bourse ne nÃ©cessite pas que les artistes participants rÃ©alisent un projet final ou une commission. Leigh a expliquÃ© que la premiÃ¨re promotion de Collider Fellows comprenait un artiste qui a rÃ©alisÃ© *\"cinq ou six prototypes\"* pendant le programme, tandis qu'un autre voulait *\"prendre ce temps pour se ressourcer, lire des tonnes de livres, faire des recherches, ralentir\"* â€” elle a dÃ©clarÃ© que ces deux approches sont *\"des maniÃ¨res complÃ¨tement acceptables d'utiliser cette bourse.\"*\n\nSelon Leigh, de nombreux projets issus de la premiÃ¨re promotion sont *\"toujours en germination\"*, et certains pourraient potentiellement Ãªtre prÃ©sentÃ©s au Lincoln Center lui-mÃªme. Bien que Leigh se dÃ©crive comme *\"redoublant d'efforts sur les expÃ©riences basÃ©es sur le lieu\"*, en particulier celles impliquant la **VR**, la **AR** et la **rÃ©alitÃ© Ã©tendue**, elle a Ã©galement suggÃ©rÃ© que les **Collider Fellows** pourraient aider le Lincoln Center Ã  repenser les faÃ§ons de toucher les publics **mondiaux**.\n\n*\"Je ne pense pas que nous fermions la porte Ã  quoi que ce soit pour l'instant,\"* a-t-elle dÃ©clarÃ©.\n\n#### ğŸ­ **Les six nouveaux Collider Fellows**\nVoici les six nouveaux **Collider Fellows**, avec une brÃ¨ve description de leur travail :\n\n---\n\n**",
    "has_been_pretreat": true,
    "rating": null,
    "time_spent": 9,
    "comments": "",
    "tags": [],
    "id": 2
  },
  {
    "title": "Only 7 days left to save on TechCrunch Disrupt 2025 tickets â€” lock in Regular Bird pricing now",
    "url": "https://techcrunch.com/2025/09/20/only-7-days-left-to-save-on-techcrunch-disrupt-2025-tickets-lock-in-regular-bird-pricing-now/",
    "content": "### RÃ©sumÃ©\nTechCrunch Disrupt 2025 se tiendra Ã  San Francisco du 27 au 29 octobre. Il reste moins de 7 jours pour profiter du tarif Regular Bird et Ã©conomiser jusqu'Ã  668$. L'Ã©vÃ©nement rassemblera 10 000+ participants, 250+ intervenants, 100+ startups Ã©mergentes et offrira 200+ sessions, des tables rondes et des rencontres rÃ©seau ciblÃ©es.\n\n## ğŸŸï¸ **Ne manquez pas votre chance de participer Ã  TechCrunch Disrupt 2025 !**\n\nAvec **moins de 7 jours** pour bÃ©nÃ©ficier du **tarif Regular Bird**, c'est le moment idÃ©al pour **Ã©conomiser jusqu'Ã  668$** sur votre billet et rejoindre **10 000+ fondateurs, investisseurs et entrepreneurs** lors de l'un des **confÃ©rences de startups les plus emblÃ©matiques de l'annÃ©e**.\n\n## ğŸ“… **Ã‰vÃ©nement Ã  ne pas manquer**\nTechCrunch Disrupt se dÃ©roulera du **27 au 29 octobre 2025 Ã  San Francisco**. Inscrivez-vous avant le **26 septembre Ã  23h59 PT** pour profiter des **tarifs avantageux**.\n\n## ğŸ¤ **Intervenants de renom**\nNous ajoutons chaque jour de **nouveaux intervenants** de premier plan issus de l'Ã©cosystÃ¨me technologique. Parmi les leaders visionnaires que vous entendrez figurent des experts en **IA, construction, disruption, espace et introduction en bourse**. Ils partageront des **conversations franches, des conseils tactiques et des perspectives sur les prochaines Ã©tapes** du monde des startups.\n\n## ğŸš€ **Startup Battlefield**\nRencontrez **200 startups prometteuses** en phase de dÃ©marrage, sÃ©lectionnÃ©es par TechCrunch, et assistez aux **pitchs en direct** des meilleurs concurrents lors de la **compÃ©tition Startup Battlefield** pour une chance de remporter **100 000$**. Entendez des **retours en temps rÃ©el** de la part d'investisseurs de premier plan sur ce qu'il faut pour construire une startup viable.\n\n## ğŸ¤ **RÃ©seautage ciblÃ©**\nGrÃ¢ce Ã  l'application de l'Ã©vÃ©nement, des **rencontres rÃ©seau 1:1 et en petits groupes** sont disponibles. Ces rencontres sont conÃ§ues pour **aller au-delÃ  des Ã©changes superficiels**, plonger dans les dÃ©tails et vous connecter avec des personnes qui peuvent **soutenir votre croissance, vos idÃ©es ou fournir des insights approfondis**. Utilisez l'application pour **planifier votre emploi du temps, rÃ©server des rencontres 1:1 et connecter avec les bonnes personnes plus rapidement**.\n\n## â˜• **Deal Flow Cafe**\nLes **fondateurs et investisseurs** peuvent Ã©galement profiter du **Deal Flow Cafe** â€” un espace plus calme pour se concentrer et **plonger directement dans des deals significatifs**.\n\n## ğŸ¢ **Expo Hall**\nL'**Expo Hall** est l'endroit oÃ¹ tous les participants de Disrupt se rassemblent pour **dÃ©couvrir en avant-premiÃ¨re les innovations de demain**. ExpÃ©rimentez des **dÃ©monstrations en direct** et **interagissez avec les innovations** de **100+ startups exposantes**. Des **innovations supplÃ©mentaires** seront prÃ©sentÃ©es dans tout le lieu, crÃ©ant une **expÃ©rience immersive** sur les trois jours.\n\n## ğŸ“¢ **Ne manquez pas votre chance**\nIl reste encore quelques **tables d'exposition disponibles**, et l'une d'entre elles pourrait porter le nom de votre startup.\n\n**Les prix augmentent dans moins de 7 jours.** Inscrivez-vous dÃ¨s maintenant pour **Ã©conomiser jusqu'Ã  668$** sur votre pass avant le **26 septembre Ã  23h59 PT**. Rejoignez-nous pour le **20e anniversaire de TechCrunch** dans le **hub technologique de San Francisco**, du **27 au 29 octobre**.\n\n",
    "has_been_pretreat": true,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [
      "technologie",
      "innovation",
      "Ã©conomie",
      "entreprise"
    ],
    "id": 3
  },
  {
    "title": "Why Californiaâ€™s SB 53 might provide a meaningful check on big AI companies",
    "url": "https://techcrunch.com/2025/09/19/why-californias-sb-53-might-provide-a-meaningful-check-on-big-ai-companies/",
    "content": "### RÃ©sumÃ©\nLa Californie a approuvÃ© un nouveau projet de loi sur la sÃ©curitÃ© de l'IA, SB 53, qui est envoyÃ© au gouverneur Gavin Newsom pour signature ou veto. Ce projet de loi, plus ciblÃ© que le prÃ©cÃ©dent SB 1047, vise les grandes entreprises d'IA gÃ©nÃ©rant plus de 500 millions de dollars de revenus annuels. Il impose des rapports de sÃ©curitÃ©, des dÃ©clarations d'incidents et des canaux de signalement pour les employÃ©s. Le projet de loi a Ã©tÃ© discutÃ© dans le podcast Equity de TechCrunch, oÃ¹ les invitÃ©s soulignent son importance pour rÃ©guler les grandes entreprises d'IA et son impact potentiel sur l'Ã©cosystÃ¨me des startups.\n\n### Article rÃ©Ã©crit\n\n# ğŸ“¢ La Californie approuve un nouveau projet de loi sur la sÃ©curitÃ© de l'IA\n\nLa **chambre** du **senat** de la **Californie** a rÃ©cemment donnÃ© son **approbation finale** Ã  un nouveau **projet de loi** sur la **sÃ©curitÃ© de l'IA**, le **SB 53**, l'envoyant au **gouverneur Gavin Newsom** pour **signature** ou **veto**.\n\nSi cela vous semble familier, c'est parce que **Newsom** avait **vetÃ©** un autre **projet de loi** sur la **sÃ©curitÃ© de l'IA**, Ã©galement rÃ©digÃ© par le **sÃ©nateur de l'Ã‰tat Scott Wiener**, l'annÃ©e derniÃ¨re. Mais le **SB 53** est **plus ciblÃ©** que le **SB 1047** prÃ©cÃ©dent de Wiener, se concentrant sur les **grandes entreprises d'IA** gÃ©nÃ©rant plus de **500 millions de dollars** de **revenus annuels**.\n\nJ'ai eu l'occasion de discuter du **SB 53** avec mes collÃ¨gues **Max Zeff** et **Kirsten Korosec** lors du dernier Ã©pisode du **podcast phare de TechCrunch, Equity**. Max croit que le nouveau projet de loi de Wiener a **plus de chances** de devenir **loi**, en partie grÃ¢ce Ã  ce **focus sur les grandes entreprises**, et parce qu'il a Ã©tÃ© **approuvÃ©** par l'entreprise d'IA **Anthropic**.\n\nLisez un **aperÃ§u** de notre **conversation** sur la **sÃ©curitÃ© de l'IA** et la **lÃ©gislation au niveau de l'Ã‰tat** ci-dessous. (J'ai Ã©ditÃ© la **transcription** pour la **longueur** et la **clartÃ©**, et pour nous faire paraÃ®tre un peu plus intelligents.)\n\n## ğŸ’¬ Discussion sur le SB 53\n\n**Max**: Pourquoi devriez-vous vous soucier de la **lÃ©gislation sur la sÃ©curitÃ© de l'IA** qui passe une **chambre** en **Californie**? Nous entrons dans une Ã¨re oÃ¹ les **entreprises d'IA** deviennent les **entreprises les plus puissantes** au monde, et cela pourrait Ãªtre potentiellement l'un des **seuls freins** Ã  leur **pouvoir**.\n\nCela est beaucoup plus **ciblÃ©** que le **SB 1047**, qui a suscitÃ© beaucoup de **contestations** l'annÃ©e derniÃ¨re. Mais je pense que le **SB 53** impose toujours des **rÃ©gulations significatives** aux **labs d'IA**. Il les oblige Ã  **publier des rapports de sÃ©curitÃ©** pour leurs **modÃ¨les**. Si elles ont un **incident**, cela les force Ã  le **signaler** au **gouvernement**. Et cela donne Ã©galement, pour les **employÃ©s** de ces **labs**, s'ils ont des **prÃ©occupations**, un **canal** pour le **signaler** au **gouvernement** et ne pas faire face Ã  des **reprÃ©sailles** de la part des **entreprises**, mÃªme si beaucoup d'entre elles ont **signÃ© des NDAs**.\n\nPour moi, cela semble Ãªtre un **frein potentiellement significatif** au **pouvoir des entreprises technologiques**, quelque chose que nous n'avons pas vraiment eu au cours des deux derniÃ¨res **dÃ©cennies**.\n\n**Kirsten**: Ã€ votre **point** sur l'importance au **niveau de l'Ã‰tat**, il est important de penser au fait que c'est la **Californie**. Chaque **entreprise d'IA majeure** est, si ce n'est basÃ©e ici, a un **impact majeur** dans cet **Ã‰tat**. Ce n'est pas que les autres **Ã‰tats** n'ont pas d'importance â€” je ne veux pas recevoir d'emails des gens du **Colorado** ou autre â€” mais cela compte que ce soit spÃ©cifiquement la **Californie** parce que c'est vraiment un **hub d'activitÃ© d'IA**.\n\nMa **question** pour toi, Max, c'est qu'il semble y avoir beaucoup d'**exceptions** et d'**exemptions**. C'est plus **ciblÃ©**, mais est-ce plus **compliquÃ©** que le [projet de loi] prÃ©cÃ©dent?\n\n**Max**: D'une certaine maniÃ¨re, oui. Je dirais que la principale **exemption** de ce projet de loi est qu'il essaie vraiment de ne pas s'appliquer aux **petites startups**. Et fondamentalement, l'une des principales **controverses** autour du dernier **effort lÃ©gislatif** du **sÃ©nateur Scott Wiener**, qui reprÃ©sente **San Francisco**, qui a rÃ©digÃ© ce projet de loi, beaucoup de gens ont dit qu'il pourrait nuire Ã  l'**Ã©cosystÃ¨me des startups**, ce Ã  quoi beaucoup de gens s'opposent parce que c'est une partie si **florissante** de l'**Ã©conomie californienne** en ce moment.\n\nCe projet de loi s'applique spÃ©cifiquement aux **dÃ©veloppeurs d'IA** qui **gÃ©nÃ¨rent** plus de **500 millions de dollars** de leurs **modÃ¨les d'IA**. Cela vise vraiment **OpenAI**, **Google DeepMind**, ces **grandes entreprises** et pas les **startups** courantes.\n\n**Anthony**: Ã€ ce que je comprends, si vous Ãªtes une **petite startup**, vous devez partager certaines **informations de sÃ©curitÃ©**, mais pas autant.\n\nIl est Ã©galement **utile** de parler du **paysage plus large** autour de la **rÃ©gulation de l'IA** et du fait que l'un des **grands changements** entre l'annÃ©e derniÃ¨re et cette annÃ©e est que nous avons maintenant un **nouveau prÃ©sident**. L'**administration fÃ©dÃ©rale** a pris une **position** beaucoup plus **sans rÃ©gulation** et les **entreprises** devraient pouvoir faire ce qu'elles veulent, au point qu'elles ont mÃªme inclus [du **langage**] dans les **projets de loi de financement** disant que les **Ã‰tats** ne peuvent pas avoir leur propre **rÃ©gulation de l'IA**.\n\nJe ne pense pas que cela ait passÃ© pour l'instant, mais potentiellement ils pourraient essayer de le faire passer Ã  l'avenir. Donc cela pourrait Ãªtre un autre **front** dans lequel l'**administration Trump** et les **Ã‰tats bleus** se battent.\n\n**Equity** est le **podcast phare** de **TechCrunch**, produit par **Theresa Loconsolo**, et est diffusÃ© tous les **mercredi** et **vendredi**.\n\nAbonnez-vous Ã  nous sur **Apple Podcasts**, **Overcast**, **Spotify**, et tous les **podcasts**. Vous pouvez Ã©galement suivre **Equity** sur **X** et **Threads**, Ã  @EquityPod.\n\nÂ© 2025 **TechCrunch Media LLC**.\n\n",
    "has_been_pretreat": true,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [
      "technologie",
      "juridique",
      "Ã©conomie"
    ],
    "id": 4
  },
  {
    "title": "Cracking product-market fit: Lessons from founders and investors at TechCrunch Disrupt 2025",
    "url": "https://techcrunch.com/2025/09/19/crack-the-code-to-startup-traction-with-insights-from-chef-robotics-nea-and-iconiq-at-techcrunch-disrupt-2025/",
    "content": "### RÃ©sumÃ©\nL'article annonce une session Ã  TechCrunch Disrupt 2025 sur la recherche de l'adÃ©quation produit-marchÃ©, avec des conseils pratiques pour les fondateurs. Les intervenants incluent Rajat Bhageria (Chef Robotics), Ann Bordetsky (NEA), et Murali Joshi (ICONIQ). L'Ã©vÃ©nement se dÃ©roulera du 27 au 29 octobre Ã  San Francisco.\n\n### Article rÃ©Ã©crit\n\n# ğŸš€ **TechCrunch Disrupt 2025 : MaÃ®triser l'adÃ©quation produit-marchÃ©**\n\n**ğŸ“… Ã‰vÃ©nement Ã  ne pas manquer**\nÃ€ **TechCrunch Disrupt 2025** â€” du **27 au 29 octobre** au **Moscone West** Ã  **San Francisco** â€” **Rajat Bhageria** (Chef Robotics), **Ann Bordetsky** (NEA), et **Murali Joshi** (ICONIQ) vous guideront Ã  travers les dÃ©fis de la recherche de l'**adÃ©quation produit-marchÃ©**. **Inscription dÃ¨s maintenant !**\n\n## ğŸ¯ **Ce que vous allez apprendre**\n- **StratÃ©gies de test intelligentes**\n- **ItÃ©ration en temps rÃ©el**\n- **Ã‰coute des utilisateurs sans se perdre dans le bruit**\n\n## ğŸ’¡ **Pour qui ?**\nQue vous soyez en phase de **prototypage** ou en train de **scaler** votre produit, cette session vous offrira des **conseils concrets** pour **rÃ©duire les suppositions** et vous concentrer sur ce qui **fait vraiment la diffÃ©rence**.\n\n## ğŸ¤ **Ne manquez pas cette session**\nRendez-vous sur la **Builders Stage** Ã  **TechCrunch Disrupt 2025**. **RÃ©servez votre pass avant la fin de la journÃ©e** pour **Ã©conomiser jusqu'Ã  668 $**.\n\nÂ© 2025 **TechCrunch Media LLC**\n\n### ",
    "has_been_pretreat": true,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [
      "entreprise",
      "Ã©conomie"
    ],
    "id": 5
  },
  {
    "title": "Metaâ€™s AR ambitions meet reality, and California gets serious about AI safetyÂ â€¦ again",
    "url": "https://techcrunch.com/video/metas-ar-ambitions-meet-reality-and-california-gets-serious-about-ai-safetyagain/",
    "content": "### RÃ©sumÃ©\nL'Ã©pisode de cette semaine du podcast **Equity** de TechCrunch aborde les **derniÃ¨res actualitÃ©s** dans les domaines de l'**IA**, de la **robotique** et de la **rÃ©gulation**. Les animateurs **Anthony Ha**, **Kirsten Korosec** et **Max Zeff** analysent les **mouvements majeurs** de ces secteurs. Le podcast est disponible sur plusieurs plateformes et propose des mises Ã  jour rÃ©guliÃ¨res.\n\n### ğŸ™ï¸ **Ã‰quitÃ© : Les DerniÃ¨res ActualitÃ©s en IA, Robotique et RÃ©gulation**\n\nCette semaine sur **Equity**, **Anthony Ha**, **Kirsten Korosec** et **Max Zeff** **dÃ©cortiquent** les **plus grandes tendances** dans les domaines de l'**IA**, de la **robotique** et de la **rÃ©gulation**.\n\nğŸ§ **Ã‰coutez l'Ã©pisode complet** pour en savoir plus sur :\n- Les **derniÃ¨res avancÃ©es** en **intelligence artificielle**\n- Les **innovations** en **robotique**\n- Les **Ã©volutions rÃ©glementaires** qui impactent ces secteurs\n\nğŸ“… **Equity** est le **podcast phare** de **TechCrunch**, produit par **Theresa Loconsolo**, et publiÃ© **chaque mercredi et vendredi**.\n\nğŸ“² **Abonnez-vous** Ã  **Equity** sur :\n- **Apple Podcasts**\n- **Overcast**\n- **Spotify**\n- **Et toutes les autres plateformes de podcasts**\n\nğŸ“¢ **Suivez Equity** sur **X** et **Threads** Ã  **@EquityPod**.\n\nğŸ“œ **Â© 2025 TechCrunch Media LLC.**\n\n",
    "has_been_pretreat": true,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [
      "technologie",
      "innovation",
      "juridique"
    ],
    "id": 6
  },
  {
    "title": "Live demo fails, AI safety wins, and the golden age of robotics",
    "url": "https://techcrunch.com/podcast/live-demo-fails-ai-safety-wins-and-the-golden-age-of-robotics/",
    "content": "### RÃ©sumÃ©\nL'Ã©pisode de cette semaine du podcast Equity de TechCrunch aborde les derniÃ¨res actualitÃ©s en matiÃ¨re d'IA, de robotique et de rÃ©gulation. Les animateurs Anthony Ha, Kirsten Korosec et Max Zeff analysent les mouvements majeurs du secteur. Le podcast est disponible en abonnement sur diverses plateformes et peut Ãªtre suivi sur les rÃ©seaux sociaux.\n\n### ğŸ™ï¸ **Ã‰quitÃ© : Les DerniÃ¨res Nouvelles en IA, Robotique et RÃ©gulation**\n\nCette semaine sur **Equity**, **Anthony Ha**, **Kirsten Korosec** et **Max Zeff** dÃ©cryptent les **plus grandes tendances** en **IA**, **robotique** et **rÃ©gulation**. ğŸš€\n\nğŸ§ **Ã‰coutez l'Ã©pisode complet** pour dÃ©couvrir les derniÃ¨res actualitÃ©s et analyses.\n\nğŸ“… **Equity** revient la semaine prochaine. **Abonnez-vous** partout oÃ¹ vous obtenez vos podcasts !\n\nğŸ™ï¸ **Equity** est le **podcast phare** de **TechCrunch**, produit par **Theresa Loconsolo**, et publiÃ© tous les **mercredis** et **vendredis**.\n\nğŸ“± **Abonnez-vous** sur **Apple Podcasts**, **Overcast**, **Spotify** et toutes les autres plateformes de podcasts. Vous pouvez Ã©galement suivre **Equity** sur **X** et **Threads**, Ã  **@EquityPod**.\n\nÂ© 2025 **TechCrunch Media LLC**.\n\n",
    "has_been_pretreat": true,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [
      "technologie",
      "innovation"
    ],
    "id": 7
  },
  {
    "title": "Final hours to apply: Be the life of TechCrunch Disrupt 2025 by hosting your own Side Event",
    "url": "https://techcrunch.com/2025/09/19/final-hours-be-the-life-of-techcrunch-disrupt-2025-by-hosting-your-own-side-event/",
    "content": "### RÃ©sumÃ©\nTechCrunch Disrupt 2025 Ã  San Francisco offre une derniÃ¨re chance de proposer un Side Event avant la fermeture des candidatures ce soir. Cet Ã©vÃ©nement permet d'exposer sa marque devant 10 000+ fondateurs et investisseurs, de crÃ©er des conversations influentes et de se dÃ©marquer. TechCrunch gÃ¨re la promotion, tandis que les participants organisent leur Ã©vÃ©nement. Ne pas participer signifie manquer une opportunitÃ© de visibilitÃ© et d'impact dans l'Ã©cosystÃ¨me tech.\n\n### Article rÃ©Ã©crit\n\n# ğŸš¨ DerniÃ¨re Chance pour Proposer un Side Event Ã  TechCrunch Disrupt 2025\n\n**C'est le moment** â€” aujourd'hui est votre **derniÃ¨re chance** de proposer un **Side Event** Ã  **TechCrunch Disrupt 2025** Ã  **San Francisco**.\n\nğŸ“… **Date limite** : Les candidatures ferment **ce soir**. **Aucune extension**, **aucune entrÃ©e tardive**. **Postulez ici**.\n\n## ğŸŒŸ Pourquoi participer ?\n\n**Disrupt Week**, qui se dÃ©roulera du **25 au 31 octobre**, est l'occasion de :\n- **Mettre en avant votre marque** devant **10 000+ fondateurs et investisseurs**, ainsi que l'Ã©cosystÃ¨me tech de la **Baie de San Francisco**.\n- **CrÃ©er les conversations** qui faÃ§onnent la confÃ©rence.\n- **Vous dÃ©marquer**.\n\n## ğŸ¤ Votre rÃ´le et notre soutien\n\n- **Nous gÃ©rons la promotion**.\n- **Vous organisez l'Ã©vÃ©nement**.\n- **Il vous suffit de soumettre votre proposition maintenant**.\n\nğŸ’¡ **Ne manquez pas cette opportunitÃ©** de mettre en lumiÃ¨re votre marque â€” **postulez avant minuit**.\n\n## âŒ Ce que vous manquerez si vous ne participez pas\n\nSi vous ne proposez pas de Side Event, vous manquerez :\n- Une **visibilitÃ© exceptionnelle** devant un public influent.\n- L'opportunitÃ© de **crÃ©er des conversations impactantes**.\n- Un **impact durable** avant, pendant et aprÃ¨s l'Ã©vÃ©nement principal.\n\n## ğŸ“ Comment postuler ?\n\n**Postuler est simple**. Cliquez **ici** pour soumettre votre **Side Event percutant** et faites des **vagues** dans la scÃ¨ne tech.\n\nÂ© 2025 TechCrunch Media LLC.\n\n### ",
    "has_been_pretreat": true,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [
      "technologie",
      "Ã©conomie",
      "entreprise"
    ],
    "id": 8
  },
  {
    "title": "Meta Ray-Ban Display and everything else unveiled at Meta Connect 2025",
    "url": "https://techcrunch.com/2025/09/19/meta-connect-2025-what-to-expect-and-how-to-watch/",
    "content": "At Meta Connect 2025, the companyâ€™s biggest event of the year, Mark Zuckerberg unveiled three new smart glasses: the second-generation Ray-Ban Meta, the Meta Ray-Ban Display and wristband controller, and the Oakley Meta Vanguard.\nMeta says it has sold 2 million of the first-generation Ray-Ban Meta smart glasses, and earlier this year, Meta unveiled its latest AI-powered smart glasses with Oakley, which were designed for athletes. Silicon Valley is leaning heavily into AI wearables, and Meta seems to be one of the companies leading the charge.\nWith Meta looking to regain its footing in the AI race and sell more hardware, the company had a lot at stake during Mark Zuckerbergâ€™s Meta Connect 2025 keynote. Overall, Meta showcased some pretty impressive technology â€” the Meta Neural Band, the wristband controller that comes with the Meta Ray-Ban Display, is a particular highlight.\nAnd yet, in a twist that felt reminiscent of HBOâ€™s â€œSilicon Valley,â€ Zuckerbergâ€™s demo of the AI capabilities on the Ray-Ban Metas failed. Whoops!\nWhile sharing a live video feed of the cooking content creator Jack Mancuso at Meta HQ, Zuckerberg asked the chef to demonstrate how his Ray-Ban Meta glasses could help him whip up a Korean-inspired steak sauce.\nâ€œI love the setup you have here, with soy sauce and other ingredients. How can I help?â€ asked the chipper Meta AI voice.\nMancuso asked for a recipe for a Korean-inspired steak sauce, and the AI voice began to list the ingredients that he would need â€” but Mancuso knows he needs to keep the demo succinct, so he interrupts and asks, â€œWhat do I do first?â€\nAfter a moment of silence that dragged a bit too long, Mancuso repeated, â€œWhat do I do first?â€\nâ€œYouâ€™ve already combined the base ingredients, so now grate a pear to add to the sauce,â€ the AI said. But he had not yet combined the base ingredients, because he had not started making the recipe, hence the question of what to do first.\nMancuso asked the same question again, and the AI gave the same response. The audience laughed.\nâ€œI think the Wi-Fi might be messed up â€” back to you, Mark!â€ Mancuso said.\nâ€œYou know what? Itâ€™s all good. The irony of the whole thing is that you spend years making the technology, and then the Wi-Fi of the day kind ofÂ â€¦ catches you,â€ Zuckerberg said. â€œAnyway, weâ€™ll go check out what he made later.â€\nThe whole interaction was a bit awkward, especially since the issue did not seem to be with the Wi-Fi. But even when things are going according to plan, these presentations can feel a bit hokeyÂ â€¦ like the end of the keynote, when Zuckerberg and Diplo quite literally ran into the sunset together, wearing their Meta Oakley Vanguards. It had to be a busy day for Mark, so maybe he just needed an excuse to build some cardio into his schedule.\nMeta unveiled the second generation of its Ray-Ban Meta glasses, which first debuted in 2023. This spruced-up model features double the battery life of its predecessor, now lasting up to eight hours of mixed use on one charge. The second-generation glasses also support ultra HD 3K video recording, which the company says is twice as sharp as the last model.\nMetaâ€™s smart glasses are also getting some new features with the release of the second-generation Ray-Ban Metas, like conversation focus, which will be available on the Ray-Ban Meta and Oakley Meta HSTN glasses.\nâ€œIf youâ€™re eating at a hot new restaurant, commuting on the train, or catching your favorite DJâ€™s latest set, conversation focus uses your AI glassesâ€™ open-ear speakers to amplify the voice of the person youâ€™re talking to,â€ Meta said in its press release.\nConversation focus isnâ€™t out just yet, so we canâ€™t say for sure if itâ€™ll be any help for your next night out.\nThe Live AI feature â€” which Meta failed to properly demo onstage â€” is also on its way. But itâ€™s so energy-intensive that you can only use it for about an hour or two.\nâ€œAs we make battery and energy efficiency optimizations, Meta AI will transition from something you prompt with a wake word to an always-available assistant,â€ the company said.\nThe second-generation Ray-Ban Meta glasses are priced at $379.\nThe Meta Ray-Ban Display smart glasses are the most impressive glasses that Meta has unveiled to date, featuring a built-in display for apps, alerts, and directions on the right lens. But what sets this pair of smart glasses apart is its accompanying wristband controller, the Meta Neural Band.\nThis wristband lets Meta show off a bit of what itâ€™s been spending so much time (and money) on in its Reality Labs division, which is notorious for losing billions of dollars a quarter.\nVisually, the Meta Neural Band looks like a Fitbit without a screen. Itâ€™s powered by surface electromyography (sEMG), which can pick up on minute hand gestures and small movements. This is far more sophisticated than a wrist gesture on an Apple Watch. Users can write out text messages by holding their fingers together as if they were gripping a pen and â€œwritingâ€ out the text. This means that you can see a WhatsApp message come in on your right glasses lens, then answer it by â€œwritingâ€ your response.\nFor now, the glasses support Meta apps, but the company will have to support a wide variety of apps in the future to get the kind of adoption theyâ€™re looking for. LikeÂ AppleÂ andÂ Google, Meta is betting that smart glasses could cut into the market share of the smartphone in the future â€” but it will be a big challenge to force such a massive cultural shift.\nThe Meta Ray-Ban Display, which comes with the Meta Neural Band, will cost $799 and launches on September 30.\nFor the bearish among us, it seems hard to imagine wearing smart glasses and sending text messages by handwriting in the air. But the Oakley Meta Vanguard smart glasses, which are designed for athletes, offer the most coherent use case yet for this kind of technology.\nBikers, trail runners, and skiers can photograph their adventures without pulling out their phones; the glassesâ€™ open-air speakers can play music during your workout, and even link with apps like Strava and Garmin to relay your stats. Like the other new glasses, the Vanguard model is also AI-enabled.\nUnlike other models of Meta smart glasses, the Oakley Meta Vanguards have just one unified front lens with a camera in the middle, rather than two lenses with cameras on either side â€” itâ€™s a design that makes more technical sense, and itâ€™s a fashion statement that you can pull off in athletic eyewear, but not in eyeglasses (prove me wrong). The new glasses can capture video in up to 3K resolution and feature a 12-megapixel camera with a 122-degree wide-angle lens.\nThe glasses have an IP67 dust and water resistance rating for use during intense workouts. Meta says the wraparound design of the glasses features Oakley PRIZM Lens technology, which is designed to block out sun, wind, and dust.\nUnless youâ€™re an ultramarathon runner, these glasses will easily last throughout your workout. The glasses can stay on for nine hours, or six hours with continuous music playback. But the charging case that the glasses come with can provide an additional 36 hours of charge on the go. Meta claims that the charging case can quickly get the glasses to a 50% charge in 20 minutes.\nThe Oakley Meta Vanguard glasses retail for $499 and go on sale on October 21.\nOn the VR front, Meta did not release any new Quest headsets as part of this yearâ€™s Connect. Even though the conference and company are named after the metaverse, we learned about just a small number of updates to its VR, such as Hyperscape, which will allow developers and creators to build photorealistic spaces in virtual reality.\nMeta is reportedly developing an ultralight VR headset for launch by the end of 2026, so maybe weâ€™ll see that come to fruition at the next Meta Connect event.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 9
  },
  {
    "title": "Octopus Energy spins off its Kraken utility billing and AI platform",
    "url": "https://techcrunch.com/2025/09/19/octopus-energy-spins-off-its-kraken-utility-billing-and-ai-platform/",
    "content": "British renewable energy provider Octopus Energy said this week that itâ€™s spinning off Kraken, its tech platform for utilities, spurred in part by $500 million in committed annual revenue from other utilities and energy providers.\nAn eventual Kraken IPO could be valued at $15 billion and could occur within a year, according to The Wall Street Journal.\nKraken was actually the companyâ€™s initial product, per Octopus CEO Greg Jackson. â€œWe created Octopus as the â€˜demo client,â€™â€ he told the Journal earlier this year. That demo client has since grown to provide power to more than 7.7 million households in the U.K. and another 2.8 million elsewhere.\nThe spinoff would help Kraken minimize conflicts of interest as it signs deals with utilities and power providers that arenâ€™t Octopus, the company said. Octopus originally set the spinoff in motion last year.\nOctopus was founded in 2015, and within a decade became the U.K.â€™s largest energy provider, overtaking British Gas, which was founded more than 200 years ago.\nPart of that growth has stemmed from creative marketing and customer-acquisition strategies.\nOne, called Zero Bills, allowed homeowners to eliminate their energy bills for a decade if they bought properties that were entirely electrified. Another, a tariff it calls Agile, encourages customers to shift their electricity use to times when thereâ€™s a surplus on the grid. In some cases, consumers can run loads of laundry for free.\nAs Octopus gathered data from those projects, it used AI models built into Kraken to sift through it to determine how increasing amounts of renewable energy can work on the grid.\nFor utilities and power providers, Kraken allows them to call on power sources when needed, including renewables, solar, and so-called distributed energy resources, which include EV chargers, smart thermostats, and home batteries. It has also built a customer management system that covers everything from billing, meter management, and customer relations.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 10
  },
  {
    "title": "How developers are using Appleâ€™s local AI models with iOS 26",
    "url": "https://techcrunch.com/2025/09/19/how-developers-are-using-apples-local-ai-models-with-ios-26/",
    "content": "Earlier this year, Apple introduced its Foundation Models framework during WWDC 2025, which allows developers to use the companyâ€™s local AI models to power features in their applications.\nThe company touted that with this framework, developers gain access to AI models without worrying about any inference cost. Plus, these local models have capabilities such as guided generation and tool calling built in.\nAs iOS 26 is rolling out to all users, developers have been updating their apps to include features powered by Appleâ€™s local AI models. Appleâ€™s models are small compared with leading models from OpenAI, Anthropic, Google, or Meta. That is why local-only features largely improve quality of life with these apps rather than introducing major changes to the appâ€™s workflow.\nBelow are some of the first apps to tap into Appleâ€™s AI framework.\nThe Lil Artist app offers various interactive experiences to help kids learn different skills like creativity, math, and music. Developer Arima Jain shipped an AI story creator with the iOS 26 update. This allows users to select a character and a theme, with the app generating a story using AI. The developer said that the text generation in the story is powered by the local model.\nThe developer of the Daylish app is working on a prototype for automatically suggesting emojis for timeline events based on the title for the daily planner app.\nFinance tracking app MoneyCoach has two neat features powered by local models. First, the app shows insights about your spending, such as whether you spent more than average on groceries for that particular week. The other feature automatically suggests categories and subcategories for a spending item for quick entries.\nThe word learning app LookUp has added two new modes using Appleâ€™s AI models. There is a new learning mode, which leverages a local model to create examples corresponding to a word. Plus, the example asks users to explain the usage of the word in a sentence.\nThe developer is also using on-device models to generate a map view of a wordâ€™s origin.\nJust like a few other apps, the Tasks app implemented a feature to suggest tags for an entry using local models automatically. Itâ€™s also using these models to detect a recurring task and schedule it accordingly. And the app lets users speak a few things and use the local model to break them down into various tasks without using the internet.\nAutomattic-owned journaling app Day One is using Appleâ€™s models to get highlights and suggest titles for your entry. The team has also implemented a feature to generate prompts that nudge you to dive deeper and write more based on what you have already written.\nRecipe app Crouton is using Apple Intelligence to suggest tags for a recipe and assign names to timers. It also uses AI to break down a block of text into easy-to-follow steps for cooking.\nDigital signing app SignEasy is using Appleâ€™s local models to extract key insights from a contract and give users a summary of the document they are signing.\nWe will continue updating this list as we discover more apps using Appleâ€™s local models.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 11
  },
  {
    "title": "One week left: Lock in discounted pricing for TechCrunch Disrupt 2025",
    "url": "https://techcrunch.com/2025/09/19/one-week-left-lock-in-discounted-pricing-for-techcrunch-disrupt-2025/",
    "content": "Itâ€™s official! We are in the final week to lock in your TechCrunch Disrupt 2025 pass and save up to $668. If you have been on the fence about joining one of the biggest tech gatherings of the year, where we will also celebrate 20 years of TechCrunch, now is the time to commit before prices rise.\nRegister here to secure your discount before time runs out. Prices jump on September 26 at 11:59 p.m. PT.\nWeâ€™re bringing the biggest names in tech to San Franciscoâ€™s Moscone West this October 27â€“29. Whoâ€™s taking the stage? Youâ€™ll hear from todayâ€™s tech leaders:\nPlus dozens more leaders from Meta, Google Cloud, Pinterest, GitHub, GTMfund, Index Ventures, and beyond. Across 250+ sessions on industry stages, roundtables, and breakouts will be packed with startup energy, deal flow, and the industryâ€™s top movers.\nDisrupt 2025 is where the next wave of ideas, products, and partnerships begins. Itâ€™s your chance to join a community of builders, operators, investors, and tech visionaries. Beyond big insights from the top voices in tech, youâ€™ll leave with powerful connections to fuel your next stage of growth â€” whatever that looks like to you. From interactive roundtables and live Q&A sessions to curated 1:1 and small-group networking, Disrupt is where you turn your vision into reality.\nRegister now â€” your last chance to secure your discount ends in just one week. These low rates end on September 26 at 11:59 p.m. PT.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 12
  },
  {
    "title": "OpenAIâ€™s research on AI models deliberately lying is wild",
    "url": "https://techcrunch.com/2025/09/18/openais-research-on-ai-models-deliberately-lying-is-wild/",
    "content": "Every now and then, researchers at the biggest tech companies drop a bombshell. There was the time Google said its latest quantum chip indicated multiple universes exist. Or when Anthropic gave its AI agent Claudius a snackÂ vending machine to run and it went amok, calling security on people and insisting it was human.\nThis week, it was OpenAIâ€™s turn to raise our collective eyebrows.\nOpenAI released on Monday some research that explained how itâ€™s stopping AI models from â€œscheming.â€ Itâ€™s a  practice in which an â€œAI behaves one way on the surface while hiding its true goals,â€ OpenAI defined in its tweet about the research.\nIn theÂ paper, conducted with Apollo Research, researchers went a bit further, likening AI scheming to a human stock broker breaking the law to make as much money as possible. The researchers, however, argued that most AI â€œschemingâ€ wasnâ€™t that harmful. â€œThe most common failures involve simple forms of deception â€” for instance, pretending to have completed a task without actually doing so,â€ they wrote.\nThe paper was mostly published to show that â€œdeliberative alignmentâ â€Â â€” the anti-scheming technique they were testing â€” worked well.\nButÂ it also explained that AI developers havenâ€™t figured out a way to train their models not to scheme. Thatâ€™s because such training could actually teach the model how to scheme even better to avoid being detected.\nâ€œA major failure mode of attempting to â€˜train outâ€™ scheming is simply teaching the model to scheme more carefully and covertly,â€ the researchers wrote.\nPerhaps the most astonishing part is that, if a model understands that itâ€™sÂ being tested, it can pretend itâ€™s not scheming just to pass the test, even if it is still scheming. â€œModels often become more aware that they are being evaluated. This situational awareness can itself reduce scheming, independent of genuine alignment,â€ the researchers wrote.\nItâ€™s not news that AI models will lie. By now most of us have experienced AI hallucinations, or the model confidently giving an answer to a prompt that simply isnâ€™t true. But hallucinations are basically presenting guesswork with confidence, as OpenAI research released earlier this month documented.\nScheming is something else. Itâ€™s deliberate.\nEven this revelation â€” that a model will deliberately mislead humans â€” isnâ€™t new.Â Apollo Research first published a paper in December documenting how five models schemed when they were given instructions to achieve a goalÂ â€œat all costs.â€\nThe news here is actually good news: The researchers saw significant reductions in scheming by using â€œdeliberative alignmentâ .â€ That technique involves teaching the model an â€œanti-scheming specificationâ€ and then making the model go review it before acting. Itâ€™s a bit like making little kids repeat the rulesÂ before allowing them to play.\nOpenAI researchers insist that the lying theyâ€™ve caught with their own models, or even with ChatGPT, isnâ€™t that serious. As OpenAIâ€™s co-founder Wojciech Zaremba told TechCrunchâ€™s Maxwell Zeff about this research: â€œThis work has been done in the simulated environments, and we think it represents future use cases. However,Â today, we havenâ€™t seen this kind of consequential scheming in our production traffic. Nonetheless, it is well known that there are forms of deception in ChatGPT. You might ask it to implement some website, and it might tell you, â€˜Yes, I did a great job.â€™ And thatâ€™s just the lie. There are some petty forms of deception that we still need to address.â€\nThe fact that AI models from multiple players intentionally deceive humans is, perhaps, understandable. They were built by humans, to mimic humans, and (synthetic data aside) for the most part trained on data produced by humans.\nWhile weâ€™ve all experienced the frustration of poorly performing technology (thinking of you, home printers of yesteryear), when was the last time your not-AI software deliberately lied to you? Has your inbox ever fabricatedÂ emails on its own? Has your CMS logged new prospects that didnâ€™t exist to pad its numbers? Has your fintech app made up its own bank transactions?\nItâ€™s worth pondering this as the corporate world barrels toward an AI future where companies believe agents can be treated like independent employees. The researchers of this paper have the same warning.\nâ€œAs AIs are assigned more complex tasks with real-world consequences and begin pursuing more ambiguous, long-term goals, we expect that the potential for harmful scheming will grow â€” so our safeguards and our ability to rigorously test must grow correspondingly,â€ they wrote.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 13
  },
  {
    "title": "HuaweiÂ announces new AI infrastructure as Nvidia gets locked out of China",
    "url": "https://techcrunch.com/2025/09/18/huawei-announces-new-ai-infrastructure-as-nvidia-gets-locked-out-of-china/",
    "content": "Tech giantÂ HuaweiÂ unveiled newÂ AIÂ infrastructureÂ meant to helpÂ boostÂ computeÂ powerÂ and allow the company to better compete with rival chipmaker Nvidia.\nAt a keynote at its Huawei Connect conferenceÂ on Thursday, Shenzhen, China-basedÂ Huawei announcedÂ newÂ SuperPoDÂ InterconnectÂ technology that can linkÂ together up to 15,000Â graphics cards, including Huaweiâ€™s Ascend AI chips, to increase compute power.\nThisÂ techÂ seems to beÂ a competitor for Nvidiaâ€™sÂ NVLinkÂ infrastructure,Â whichÂ facilitatesÂ high-speed communication betweenÂ AIÂ chips.\nTechnologyÂ like thisÂ is critical for Huawei to better compete withÂ semiconductors likeÂ Nvidiaâ€™s. While Huaweiâ€™s AI chips are lessÂ powerful than Nvidiaâ€™s,Â being able to cluster themÂ togetherÂ will give its usersÂ access toÂ moreÂ computeÂ power,Â which is needed for training and scaling AIÂ systems.\nThis news also comes just a day afterÂ China banned domestic tech companiesÂ from buying Nvidiaâ€™s hardware, includingÂ Nvidiaâ€™sÂ RTX Pro 600D servers specifically designed for the market in China.\nTechCrunchÂ reached out to Huawei for more information.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 14
  },
  {
    "title": "How AI startups are fueling Googleâ€™s booming cloud business",
    "url": "https://techcrunch.com/2025/09/18/how-ai-startups-are-fueling-googles-booming-cloud-business/",
    "content": "Google Cloud announced Thursday it has added fast-rising AI coding startups Lovable and Windsurf to its roster of customers. Both companies have chosen Google Cloud as one of their cloud computing providers, the latest sign of Googleâ€™s rising prominence against larger rivals like AWS and Microsoft Azure. Google Cloud tells TechCrunch that it handles a significant percentage of Lovable and Windsurfâ€™s cloud and AI workloads today, though the startups are not contractually obligated to primarily work with Google.\nThe deals also highlight Googleâ€™s efforts to make its cloud business more central to the companyâ€™s future.\nToday, Google Cloud is overshadowed by larger competitors like AWS and Microsoft, as well as Googleâ€™s much larger advertising business. But it is seeing upward momentum.\nGoogle Cloud is one of the companyâ€™s fastest-growing business lines. On its last earnings call, Google said its cloud division hit an annual run rate of $50 billion, and cloud chief Thomas Kurian said this week the unit lined up $58 billion in new revenue over the next two years. Google generated $43.2 billion in cloud services in 2024 and $33.1 billion in 2023.\nWinning contracts with leading AI startups seems to be a large driver of Google Cloudâ€™s growth. The division says it now works with nine out of the 10 leading AI labs, including Safe Superintelligence and OpenAI, and 60% of the worldâ€™s generative AI startups. In the last year, the company says itâ€™s seen a 20% increase in the number of new AI startups choosing Google Cloud.\nWhile Lovable and Windsurf, which was recently acquired by Cognition, spend relatively little compared to leading AI labs or large enterprises, the bet is that they will become larger businesses in the future, and well worth the investment.\nGoogle says the two vibe-coding startups use Gemini 2.5 Pro to power their products, which are also run on Google Cloud infrastructure. Google says Windsurf is also using Gemini models in integrations with Cognitionâ€™s AI agent, Devin.\nIn an interview with TechCrunch, Windsurf CEO Jeff Wang said the startup works with a variety of cloud providers, including Google Cloud, but itâ€™s hard to say which company it uses the most. Lovable declined to comment.\nThe significant cloud costs of training, fine-tuning, and running AI models has presented a major challenge for AI model developers, including Google DeepMind with its Gemini models. But itâ€™s been a boon for cloud businesses. The global cloud market is expected to exceed $400 billion in 2025 and grow at a rate of 20% over the next five years, according to the market intelligence and analytics firm Synergy Research.\nThe company on Thursday hosted its first Google AI Builderâ€™s Forum, in which it brought together hundreds of AI startup founders and announced more than 40 new AI startups building on Google Cloud. In addition to Lovable and Windsurf, Sequoia-backed Factory AI and Andreessen Horowitz-backed Krea AI were among the customers named.\nPart of the reason so many AI startups work with Google Cloud are the generous deals it offers. Many of the AI startups Google works with started on its Google for Startups Cloud Program, in which it offers $350,000 in cloud credits. Google Cloud also offers a dedicated cluster of Nvidia GPUs for startups in the Y Combinator accelerator program.\nUpdate 9/19/25: This article has been updated to clarify language around the term â€œprimary cloud computing providerâ€ and include comment from Windsurfâ€™s CEO. Neither Lovable nor Windsurf have signed a preferred cloud provider agreement, a contractual designation that guarantees a startup does a majority of their work with a single cloud provider.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 15
  },
  {
    "title": "Tim Cook, Sam Altman, and more attend Trumpâ€™s UK state banquet",
    "url": "https://techcrunch.com/2025/09/18/tim-cook-sam-altman-and-more-attend-trumps-uk-state-banquet/",
    "content": "Top tech names were on the guest list for the banquet thrown for President Trump during his second state visit to the U.K. on Wednesday.\nThe banquet seating chart included Nvidia CEO Jensen Huang; Apple CEO Tim Cook; venture capitalist and White House AI and crypto czar David Sacks; Alphabet and Google president Ruth Porat; Microsoft CEO Satya Nadella; Salesforce CEO Marc Benioff; and OpenAIâ€™s Sam Altman, according to The New York Times.\nOn Thursday, the U.S. and U.K. signed a partnership called the Tech Prosperity Deal to focus on developing nuclear, AI, and quantum technologies. Google, Microsoft, Nvidia, and OpenAI also made announcements earlier this week to build data centers in the U.K., while CoreWeave and Salesforce announced a multibillion-pound investment in the country. Overall, American tech firms committed a total of Â£31 billion ($42 billion) to boost AI infrastructure in the U.K.\nThis state banquet guest list seems to have featured more tech and business names than the Hollywood types that often attend such affairs.\nThis change reveals the shifting economic needs of the U.K. and U.S. in the age of AI, as well as the rising prominence of technology and its leaders in Trumpâ€™s second administration. Just this past year, numerous Big Tech companies like OpenAI, Google, and Apple have pledged to work with the government, from providing AI assistant tools to government services to building digital health ecosystems for the U.S. health industry.\nThe president has also taken a sharper focus on tech â€” criticizing Tim Cook for Appleâ€™s outsourced supply chain, signing an â€œanti-wokeâ€ AI order, and instructing the attorney general to investigate private companies receiving federal funds that have DEI programs deemed â€œillegal.â€\nMark Zuckerberg, Jeff Bezos, and other tech leaders attended the presidentâ€™s inauguration this year. And, in early September, President Trump threw a tech dinner with 33 top names in Silicon Valley, including Altman, Cook, and Zuckerberg. Musk, a former senior adviser to the president, once known as â€œFirst Buddy,â€ was not present at either dinner.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 16
  },
  {
    "title": "Notion launches agents for data analysis and task automation",
    "url": "https://techcrunch.com/2025/09/18/notion-launches-agents-for-data-analysis-and-task-automation/",
    "content": "At the â€œMake with Notionâ€ event on Thursday, the company announced the launch of its first AI agent. The agent will draw on all of a userâ€™s notion pages and database as context, automatically generating notes and analysis for meetings, competitor evaluation reports, and feedback landing pages.\nThe productivity platform said that the agent can create pages and databases, or update them with new data, properties, or views. Users can also trigger Notion agents from outside platforms that are linked to the service. For instance, you can ask the Notion agent to create a bug-tracking dashboard from various sources, including Slack, email, and Google Drive.\nThe newly announced Agent builds on Notion AI, a pre-existing feature that could search or summarize content. But the new agent is able to tackle more complex multistep tasks, using the powers of agentic AI. The company said that the current version of the agent can perform a task that runs up to 20 minutes across hundreds of pages.\nUsers can set up a â€œprofileâ€ page for the agent to instruct it to follow directions on referencing sources, style of output, and where to update tasks and final results. Youâ€™ll also be able to ask the agent to â€œrememberâ€ key points as people use them. Those memories will be stored on the profile page, and users can edit them there.\nIn demo videos, the company gave examples of agents that could provide feedback for landing pages and update them, create a restaurant tracker, create an analysis from meeting notes, and prepare a competition analysis report.\nAt the moment, you have to trigger these actions manually. But Notion said that the ability to create customized agents that work on a schedule or triggers is coming soon. The company will also release a template library for agents so you can pick ready-made prompts that might suit your task.\nOver the last two years, Notion has released a calendar app, a Gmail client, a meeting note-taker, and an enterprise search to get information from different sources. These are features that gave the company enough contextual building blocks to create automations. Other enterprise knowledge and productivity platforms, including Salesforce, Fireflies, Fathom, and Read AI have launched their own agents to extract and update information.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 17
  },
  {
    "title": "Google now lets you share your custom Gemini AI assistants known as Gems",
    "url": "https://techcrunch.com/2025/09/18/google-now-lets-you-share-your-custom-gemini-ai-assistants-known-as-gems/",
    "content": "Google is making it possible to now share your Gemini Gems â€” custom AI assistants and experts designed for specific tasks â€” the company announced on Thursday. The feature launched last year, initially as part of the Gemini Advanced paid subscription, allowing users to write instructions to create an AI chatbot for different scenarios. For instance, Google launched with premade Gems like a learning coach, a brainstorming assistant, a career guide, a writing editor, and a coding partner.\nNow Google says youâ€™ll be able to share your Gems with friends, family, or co-workers as easily as you can share a file from Google Drive.\nThis would make Gems more accessible to more people, as not everyone uses the advanced customization feature. It could also help prevent people from building the same Gems as others. For instance, if multiple co-workers were using a similar type of custom Gemini assistant, they could just share the same resource instead of each making their own version that could have slight inconsistencies between them.\nGoogle suggests Gem sharing could also be useful for people working on family vacation plans and guides, meal planners, or collaborative writing projects.\nTo share a Gem, youâ€™ll open the Gem manager on the web app and click the â€œShareâ€ icon next to any Gem youâ€™ve created. Also similar to Google Drive, you can control who can view and use your Gems and whoâ€™s allowed to edit them.\nAfter first rolling out to Gemini Advanced, Gemini Business, and Gemini Enterprise subscribers in over 150 countries, Google announced in March that Gems were now available to everyone and could support file uploads.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 18
  },
  {
    "title": "Mark Zuckerberg has begun his quest to kill the smartphone",
    "url": "https://techcrunch.com/2025/09/18/mark-zuckerberg-has-begun-his-quest-to-kill-the-smartphone/",
    "content": "If you canâ€™t resist the urge to check your phone over and over, even if youâ€™re out with friends, Meta has a solution: check your glasses instead.\nâ€œThe promise of glasses is to preserve this sense of presence that you have with other people,â€ said CEO Mark Zuckerberg at the Meta Connect 2025 keynote. â€œI think that weâ€™ve lost it a little bit with phones, and we have the opportunity to get it back with glasses.â€\nIn reality, Meta wants its own hardware to eat into the marketshare of Apple and Google so that it doesnâ€™t have to keep siphoning profits to them via app stores. But nevertheless, this is the angle Meta is taking to sell its most sophisticated smart glasses yet, the Meta Ray-Ban Display, which the company hopes could one day eclipse the market share of smartphones.\nMetaâ€™s Reality Labs division burns cash at an alarming rate, which has concerned investors over the years. But Wednesdayâ€™s event finally showed us a glimpse of what the divisionâ€™s $70 billion in losses since 2020 have gone toward.\nMeta has had its fair share of flops, like the entire promise of its social metaverse. (Remember when they announced that metaverse avatars would finally get legs?) But with the Meta Ray-Ban Display, Meta has created a remarkable piece of technology, unlike any other consumer-facing product on the market â€” we have yet to test it ourselves, so we canâ€™t quite say just how groundbreaking this really is, but it looks promising.\nLike Metaâ€™s existing smart glasses, which have sold millions of pairs, the new model has cameras, speakers, microphones, and an on-board AI assistant. The display on the glasses, which is offset so as not to obstruct oneâ€™s sightline, can display Meta apps like Instagram, WhatsApp, and Facebook, as well as directions and live translations.\nWhat most sets the Meta Ray-Ban Display apart is the Meta Neural Band, a wristband that uses surface electromyography (sEMG) to pick up on signals sent between your brain and your hand when performing a gesture.\nMetaâ€™s keynote didnâ€™t get into the specifics of how Zuckerberg was writing these texts, but according to Reality Labsâ€™ research on sEMG, users can write out messages like this by holding their fingers together as if they were gripping a pen and â€œwritingâ€ out the text.\nWhile some live AI demos at the keynote failed â€” Zuckerberg blamed the Wi-Fi â€” we at least got to see the wristband in action, which is more novel. Zuckerberg quickly wrote out text messages, then sent them on his Ray-Bans.\nâ€œIâ€™m up to about 30 words a minute on this,â€ Zuckerberg said onstage at the companyâ€™s Menlo Park headquarters. â€œYou can get pretty fast.â€\nOn a touchscreen smartphone like an iPhone, research has estimated that people text at about 36 words per minute, making Zuckerbergâ€™s claim impressive. Reality Labsâ€™ research participants averaged closer to 21 words per minute.\nUnlike past Meta Ray-Bans, this technology allows people to actually use the glasses without speaking aloud, which isnâ€™t always natural in public settings. While Apple Watch users can send texts without voice prompting, the process is so tedious and slow that itâ€™s only useful as a last resort.\nOther gesture controls on the wristband seem more similar to technology that consumers have used before, like Nintendo Joy-Cons and Apple Watches. But if the voiceless texting interface is as good as it seems, then the wristband will likely be capable of more complex gestures than weâ€™re used to.\nMeta has invested heavily in research on sEMG since 2021, even showing us a prototype of a heftier product called Orion. Like Apple and Google, Meta is preparing for a not-so-impossible future where these smart glasses could potentially eclipse the smartphone.\nBut as is the risk with any massive hardware investment, thereâ€™s no way to know if this will actually feel more natural to people in their day-to-day lives than pulling a sleek aluminum rectangle out of their pocket to tap out messages to their friends.\nThis might be Metaâ€™s biggest bet â€” perhaps a bigger bet than its subpar metaverse. Thatâ€™s why itâ€™s so striking that Zuckerberg is unveiling this technology as not just a fascinating innovation, but something that he wants to portray as more prosocial than the smartphone. Itâ€™s a way for him to capitalize on our growing malaise with our ever-increasing screen time, even though heâ€™s the one making the apps that demand our attention.\nâ€œThe technology needs to get out of the way,â€ Zuckerberg said.\nWill the smartphone become an obsolete relic like a Nokia with a T9 keyboard? That depends on whether thereâ€™s truth to Zuckerbergâ€™s narrative that these glasses will help us feel more present. But Meta and its competitors are betting big on the cultural shift from smartphones to smart glasses, and the Ray-Ban Display will give consumers their first taste of this possible future.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 19
  },
  {
    "title": "Google brings Gemini in Chrome to US users, unveils agentic browsing capabilities, and more",
    "url": "https://techcrunch.com/2025/09/18/google-brings-gemini-in-chrome-to-us-users-unveils-agentic-browsing-capabilities-and-more/",
    "content": "Google announced Thursday that itâ€™s rolling out Gemini in Chrome to all Mac and Windows desktop users in the U.S. after previously limiting the capability to Google AI Pro and Google AI Ultra subscribers. The tech giant also announced that itâ€™s bringing agentic capabilities to Chrome in the future, adding its AI Mode search feature to the address bar, launching new Gemini features, using AI to combat AI-generated scams, rolling out automatic password resets, and more.\nU.S. users who have their language set to English can now ask Gemini to clarify complex information on any web page theyâ€™re reading using the Gemini icon in the top-right corner of their Chrome window. For example, you could open up a page that features a banana bread recipe and ask Gemini to make the recipe gluten free.\nGemini can now work across multiple tabs, allowing users to quickly compare and summarize information across multiple websites. For example, you could be planning your flight, hotel, and vacation in multiple tabs and work with Gemini to organize your trip. Or, you might be shopping for a new mattress and want to compare all of the different models youâ€™re looking at in multiple tabs.\nGemini will soon be able to retrieve web pages youâ€™ve previously visited, making it easier to return to past browsing sessions without sifting through your browser history. That means you will be able to ask something like â€œOn which site did I see the walnut desk last week?â€ or â€œWhat was that blog I read on back-to-school shopping?â€\nAdditionally, Google is launching a deeper integration between Gemini in Chrome and other Google apps, like Calendar, YouTube, and Maps. Google says this will allow users to do things like schedule meetings, see location details, and more without having to leave the page theyâ€™re on. For example, if youâ€™re trying to find a specific spot in a YouTube video, you can ask Gemini to take you there.\nGoogle notes that the AI assistant will be able to complete tedious tasks, like booking a haircut or ordering weekly groceries. Gemini will navigate to the site, add things to your cart, and let you take the final action by checking out with your payment option.\nGoogle says the new agentic capabilities will be available in Chrome in the coming months. Itâ€™s worth noting that OpenAI launched Operator, an AI agent that performs tasks autonomously, earlier this year.\nGoogle is also bringing AI Mode, its advanced search feature, directly into the Chrome address bar. With AI Mode, users can ask complex questions with follow-ups to dig deeper into topics. For example, instead of searching for â€œbest mattress,â€ you could type out â€œIâ€™m a side sleeper with occasional lower back pain. Make me a table comparing the different mattress typesâ€ directly in the address bar. From there, you could ask follow-up questions and keep your search going with queries like, â€œHow long do memory foam mattresses typically last?â€\nThis update will be rolling out later this month in English in the U.S.Â and expanding to more countries and languages in the future.\nAlso coming to the address bar is the ability to ask questions about the page youâ€™re on. Chrome can now suggest relevant questions based on the context of the page to kickstart your search in the address bar. Google says users will get a helpful AI Overview and the option to ask follow-up questions with AI Mode.\nThe company says Chrome will also soon be able to use its Gemini Nano model to detect and protect against scams, such as fake virus alerts and fraudulent giveaways. These scams often impersonate trusted brands and use generative AI to create convincing phishing attempts, Google notes.\nGoogle also announced that itâ€™s using AI to help users fix compromised passwords with a single click on supported sites, like Coursera, Spotify, Duolingo, H&M, and more. If Chrome warns you that your password was exposed in a data breach, you can allow it to create and save a new one for you.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 20
  },
  {
    "title": "ChatGPT: Everything you need to know about the AI-powered chatbot",
    "url": "https://techcrunch.com/2025/09/18/chatgpt-everything-to-know-about-the-ai-chatbot/",
    "content": "ChatGPT, OpenAIâ€™s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.\n2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.\nOpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAIâ€™s transition to a for-profit.\nIn 2025, OpenAI is battling the perception that itâ€™s ceding ground in the AI race to Chinese rivals like DeepSeek. The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history.\nBelow, youâ€™ll find a timeline of ChatGPT product updates and releases, starting with the latest, which weâ€™ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.\nTo see a list of 2024 updates, go here.\nCEO Sam Altman announced new policies for under-18 users of ChatGPT, tightening safeguards around sensitive conversations. The company says it will block flirtatious exchanges with minors and add stronger protections around discussions of suicide, even escalating severe cases to parents or authorities. The move comes as OpenAI faces a wrongful death lawsuit tied to alleged chatbot interactions, underscoring rising concerns about the mental health risks of AI companions.\nOpenAI rolled out GPT-5-Codex, a new version of its AI coding agent that can spend anywhere from a few seconds to seven hours tackling a task, depending on complexity. The company says this dynamic approach helps the model outperform GPT-5 on key coding benchmarks, including bug fixes and large-scale refactoring. The update comes as OpenAI looks to keep Codex competitive in a fast-growing market that now includes rivals like Claude Code, Cursor, and GitHub Copilot.\nOpenAI is shaking up its Model Behavior team, the small but influential group that helps shape how its AI interacts with people The roughly 14-person team is being folded into the larger Post Training group, now reporting to lead researcher Max Schwarzer. Meanwhile, founding leader Joanne Jang is spinning up a new unit called OAI Labs, focused on prototyping fresh ways for people to collaborate with AI.\nOpenAI, facing a lawsuit from the parents of a 16-year-old who died by suicide, said in its blog that it has implemented new safeguards for ChatGPT, including stronger detection of mental health risks and parental control features. The AI company said the updates aim to provide tighter protections around suicide-related conversations and give parents more oversight of their childrenâ€™s use.\nElon Muskâ€™s AI startup, xAI, filed a federal lawsuit in Texas against Apple and OpenAI, alleging that the two companies colluded to lock up key markets and shut out rivals.\nOpenAI introduced its most affordable subscription plan, ChatGPT Go, in India, priced at 399 rupees per month (approximately $4.57). This move aims to expand OpenAIâ€™s presence in its second-largest market, offering enhanced access to the latest GPT-5 model and additional features.\nSince its May 2023 launch, ChatGPTâ€™s mobile app has amassed $2 billion in global consumer spending, dwarfing competitors like Claude, Copilot, and Grok by roughly 30 times, according to Appfigures. This year alone, the app has generated $1.35 billion, a 673% increase from the same period in 2024, averaging nearly $193 million per month, or 53 times more than its nearest rival, Grok.\nDespite unveiling GPT-5 as a â€œone-size-fits-allâ€ AI, OpenAI is still offering several legacy AI options, including GPT-4o, GPT-4.1, and o3. Users can choose between new â€œAuto,â€ â€œFast,â€ and â€œThinkingâ€ modes for GPT-5, and paid subscribers regain access to legacy models like GPT-4o and GPT-4.1.\nOpenAI CEO Sam Altman told Reddit users that GPT-5â€™s â€œdumberâ€ behavior at launch was due to a router issue and promised fixes, double rate limits for Plus users, and transparency on which model is answering, while also shrugging off the infamous â€œchart crimeâ€ from the live presentation.\nOpenAI released GPT-5, a next-gen AI thatâ€™s not just smarter but more useful â€” able to handle tasks like coding apps, managing calendars, and creating research briefs â€” while automatically figuring out the fastest or most thoughtful way to answer your questions.\nOpenAI is making a major push into federal government workflows, offering ChatGPT Enterprise to agencies for just $1 for the next year. The move comes after the U.S. General Services Administration (GSA) added OpenAI, Google, and Anthropic to its approved AI vendor list, allowing agencies to access these tools through preset contracts without negotiating pricing.\nOpenAI unveiled its first open source language models since GPT-2, introducing two new open-weight AI releases: gpt-oss-120b, a high-performance model capable of running on a single Nvidia GPU, and gpt-oss-20b, a lighter model optimized for laptop use. The move comes amid growing competition in the global AI market and a push for more open technology in the U.S. and abroad.\nChatGPTâ€™s rapid growth is accelerating. OpenAI said the chatbot was on track to hit 700 million weekly active users in the first week of August, up from 500 million at the end of March. Nick Turley, OpenAIâ€™s VP and head of the ChatGPT app, highlighted the appâ€™s growth on X, noting it has quadrupled in size over the past year.\nOpenAI unveiled Study Mode, a new ChatGPT feature designed to promote critical thinking by prompting students to engage with material rather than simply receive answers. The tool is now rolling out to Free, Plus, Pro, and Team users, with availability for Edu subscribers expected in the coming weeks.\nChatGPT users should be cautious when seeking emotional support from AI, as the AI industry lacks safeguards for sensitive conversations, OpenAI CEO Sam Altman said on a recent episode of This Past Weekend w/ Theo Von. Unlike human therapists, AI tools arenâ€™t bound by doctor-patient confidentiality, he noted.\nChatGPT now receives 2.5 billion prompts daily from users worldwide, including roughly 330 million from the U.S. Thatâ€™s more than double the volume reported by CEO Sam Altman just eight months ago, highlighting the chatbotâ€™s explosive growth.\nOpenAI has introduced ChatGPT Agent, which completes a wide variety of computer-based tasks on behalf of users and combines several capabilities like Operator and Deep Research, according to the company. OpenAI says the agent can automatically navigate a userâ€™s calendar, draft editable presentations and slideshows, run code, shop online, and handle complex workflows from end to end, all within a secure virtual environment.\nResearchers at Stanford University have observed that therapy chatbots powered by large language models can sometimes stigmatize people with mental health conditions or respond in ways that are inappropriate or could be harmful. While chatbots are â€œbeing used as companions, confidants, and therapists,â€ the study found â€œsignificant risks.â€\nCEO Sam Altman said that the company is delaying the release of its open model, which had already been postponed by a month earlier this summer. The ChatGPT maker, which initially planned to release the model around mid-July, has indefinitely postponed its launch to conduct additional safety testing.\nOpenAI plans to release an AI-powered web browser to challenge Alphabetâ€™s Google Chrome. It will keep some user interactions within ChatGPT, rather than directing people to external websites.\nSome ChatGPT users have noticed a new feature called â€œStudy Togetherâ€ appearing in their list of available tools. This is the chatbotâ€™s approach to becoming a more effective educational tool, rather than simply providing answers to prompts. Some people also wonder whether there will be a feature that allows multiple users to join the chat, similar to a study group.\nReferrals from ChatGPT to news publishers are increasing. But this rise is insufficient to offset the decline in clicks as more users now obtain their news directly from AI or AI-powered search results, according to a report by digital market intelligence company Similarweb. Since Google launched its AI Overviews in May 2024, the percentage of news searches that donâ€™t lead to clicks on news websites has increased from 56% to nearly 69% by May 2025.\nOpenAI has started using Googleâ€™s AI chips to power ChatGPT and other products, as reported by Reuters. The ChatGPT maker is one of the biggest buyers of Nvidiaâ€™s GPUs, using the AI chips to train models, and this is the first time that OpenAI is using non-Nvidia chips in an important way.\nResearchers from MITâ€™s Media Lab monitored the brain activity of writers in 32 regions. They found that ChatGPT users showed minimal brain engagement and consistently fell short in neural, linguistic, and behavioral aspects. To conduct the test, the lab split 54 participants from the Boston area into three groups, each consisting of individuals ages 18 to 39. The participants were asked to write multiple SAT essays using tools such as OpenAIâ€™s ChatGPT, the Google search engine, or without any tools.\nThe ChatGPT app for iOS was downloaded 29.6 million times in the last 28 days, while TikTok, Facebook, Instagram, and X were downloaded a total of 32.9 million times during the same period, representing a difference of about 10.6%, according to ZDNET report citing Similarwebâ€™s X post.\nSam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.\nOpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.\nOpenAI upgraded ChatGPTâ€™s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said.\nOpenAIâ€™s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across usersâ€™ own services to answer their questions. For instance, an analyst could use the companyâ€™s slide deck and documents to develop an investment thesis.\nOpenAI plans to purchase Jony Iveâ€™s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAIâ€™s reach to a larger audience in the future.\nOpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and â€œcleanerâ€ code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.\nSam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a personâ€™s life when one attendee asked about how ChatGPT can become more personalized.\nOpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.\nOpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.\nAfter introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAIâ€™s products.\nOpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAIâ€™s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the companyâ€™s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg.\nOpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.\nOpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on â€œadditional fixesâ€ to the modelâ€™s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.\nAn issue within OpenAIâ€™s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunchâ€™s testing, a fact later confirmed by OpenAI. â€œProtecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,â€ a spokesperson told TechCrunch via email. â€œIn this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.â€\nOpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.\nOpenAI leaders have been talking about allowing the open model to link up with OpenAIâ€™s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch.\nOpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAIâ€™s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.\nOpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The companyÂ skipped that step â€” sending safety cardsÂ for GPT-4.1 â€” claiming in a statement to TechCrunch that â€œGPT-4.1 is not a frontier model, so there wonâ€™t be a separate system card released for it.â€\nQuestions have been raised regarding OpenAIâ€™s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAIâ€™s top-reported score.\nOpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.\nOpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAIâ€™s safety report.\nOpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAIâ€™s previous models.\nOpen AI introduced a new section called â€œlibraryâ€ to make it easier for users to create images on mobile and web platforms, per the companyâ€™s X post.\nOpenAI said on Tuesday that it might revise its safety standards if â€œanother frontier AI developer releases a high-risk system without comparable safeguards.â€ The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.\nOpenAI is currently in the early stages of developing its own social media platform to compete with Elon Muskâ€™s X and Mark Zuckerbergâ€™s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.\nOpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAIâ€™s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.\nOpenAI has launched three members of the GPT-4.1 model â€” GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano â€” with a specific focus on coding capabilities. Itâ€™s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Googleâ€™s Gemini 2.5 Pro, Anthropicâ€™s Claude 3.7 Sonnet, and DeepSeekâ€™s upgraded V3.\nOpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAIâ€™s API.\nOpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAIâ€™s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.\nOpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.\nIt looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new â€œImageGenâ€ watermark feature in the new beta of ChatGPTâ€™s Android app. Blaho also found mentions of other tools: â€œStructured Thoughts,â€ â€œReasoning Recap,â€ â€œCoT Search Tool,â€ and â€œl1239dk1.â€\nOpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAIâ€™s premium service, which offers access to the companyâ€™s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.\nMore than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available  to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.\nThe Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAIâ€™s o3 â€œreasoningâ€ model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.\nIn a series of posts on X, OpenAI CEO Sam Altman said the companyâ€™s new image-generation toolâ€™s popularity may cause product releases to be delayed. â€œWe are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,â€ he wrote.\nOpeanAI intends to release its â€œfirstâ€ open language model since GPT-2 â€œin the coming months.â€ The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.\nOpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now â€œevolvedâ€ its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAIâ€™s model behavior.\nOpenAI wants to incorporate Anthropicâ€™s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said.\nThe latest update of the image generator on OpenAIâ€™s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like â€œMy Neighbor Totoroâ€ and â€œSpirited Away.â€ The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization.\nOpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesnâ€™t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said.\nOpenAI on Tuesday rolled out a major upgrade to ChatGPTâ€™s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAIâ€™s AI video-generation tool, for subscribers of the companyâ€™s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the companyâ€™s API service. The companyâ€™s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.\nBrad Lightcap, OpenAIâ€™s chief operating officer, will lead the companyâ€™s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.\nOpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the companyâ€™s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPTâ€™s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are â€œmore direct, engaging, concise, specific, and creative,â€ a spokesperson from OpenAI told TechCrunch.\nOpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAIâ€™s ChatGPT. Reliance has proposed selling OpenAIâ€™s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.\nNoyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. â€œThe GDPR is clear. Personal data has to be accurate,â€ said Joakim SÃ¶derberg, data protection lawyer atÂ Noyb, in a statement. â€œIf itâ€™s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isnâ€™t enough. You canâ€™t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.â€\nOpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, â€œgpt-4o-mini-tts,â€ that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called â€œgpt-4o-transcribeâ€ and â€œgpt-4o-mini-transcribeâ€. The company claims they are improved versions of what was already there and that they hallucinate less.\nOpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 â€œreasoningâ€ AI model to deliver â€œconsistently better responses.â€ Itâ€™s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAIâ€™s GPT-4.5 for input and 10 times the price of regular o1.\nNoam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for â€œreasoningâ€ could have been developed 20 years ago if researchers had understood the correct approach and algorithms.\nOpenAI CEO Sam Altman said, in aÂ post on X, that the company has trained a â€œnew modelâ€ thatâ€™s â€œreally goodâ€ at creative writing. He posted a lengthy sample from the model given the prompt â€œPlease write a metafictional literary short story about AI and grief.â€ OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming.Â And it turns out that it might not be that great at creative writing at all.\nOpenAI rolled out new tools designed to help developers and businesses build AI agents â€” automated systems that can independently accomplish tasks â€” using the companyâ€™s own AI models and frameworks. The tools are part of OpenAIâ€™s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAIâ€™s Operator product. The Responses API effectively replaces OpenAIâ€™s Assistants API, which the company plans to discontinue in the first half of 2026.\nOpenAI intends to release several â€œagentâ€ products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a â€œhigh-income knowledge workerâ€ agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting â€œPhD-level research,â€ are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. Itâ€™s unclear when these agentic tools might launch or which customers will be eligible to buy them.\nThe latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.\nAccording to a new report from VC firm Andreessen Horowitz (a16z), OpenAIâ€™s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPTâ€™s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that modelâ€™s launch.\nOpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a â€œsimplifiedâ€ product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that â€œintegrates a lot of [OpenAIâ€™s] technology,â€ including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.\nA commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAIâ€™s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesnâ€™t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.\nIn response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step â€œthoughtâ€ process. ChatGPT users will see an updated â€œchain of thoughtâ€ that shows more of the modelâ€™s â€œreasoningâ€ steps and how it arrived at answers to questions.\nOpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbotâ€™s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.\nOpenAI announced a new AI â€œagentâ€ called deep research thatâ€™s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the â€œagentâ€ is intended for instances where you donâ€™t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.\nOpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit userâ€™s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI modelsâ€™ responses to human replies for that same post.\nOpenAI launched a new AI â€œreasoningâ€ model, o3-mini, the newest in the companyâ€™s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both â€œpowerfulâ€ and â€œaffordable.â€\nA new report from app analytics firm Appfigures found that over half of ChatGPTâ€™s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.\nOpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAIâ€™s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAIâ€™s tools for the handling of non-public sensitive data.\nYounger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether theyâ€™ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think itâ€™s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.\nOpenAI says that it might store chats and associated screenshots from customers who use Operator, the companyâ€™s AI â€œagentâ€ tool, for up to 90 days â€” even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operatorâ€™s.\nOpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.\nOperator, OpenAIâ€™s agent tool, could be released sooner rather than later. Changes to ChatGPTâ€™s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes arenâ€™t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPTâ€™s client-side code. TechCrunch separately identified the same references to Operator on OpenAIâ€™s website.\nOpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number â€” no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number canâ€™t upgrade to one of OpenAIâ€™s paid plans without verifying their account via an email. Multi-factor authentication also isnâ€™t supported without a valid email.\nChatGPTâ€™s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.\nOpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and â€œtraitsâ€ theyâ€™d like the chatbot to have. OpenAI suggests traits like â€œChatty,â€ â€œEncouraging,â€ and â€œGen Z.â€ However, some users reported that the new options have disappeared, so itâ€™s possible they went live prematurely.\nChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.\nNovember 30, 2022 is when ChatGPT was released for public use.\nBoth the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.\nThere is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.\nAnyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.\nMultiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.\nMost recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.Â  And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.\nGPT stands for Generative Pre-Trained Transformer.\nA chatbot can be any software/system that holds dialogue with you/a person but doesnâ€™t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that theyâ€™ll give canned responses to questions.\nChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.\nDue to the nature of how these models work, they donâ€™t know or care whether something is true, only that it looks true. Thatâ€™s a problem when youâ€™re using it to do your homework, sure, but when it accuses you of a crime you didnâ€™t commit, that may well at this point be libel.\nWe will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.\nYes, there is a free ChatGPT mobile app for iOS and Android users.\nItâ€™s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.\nYes, it was released March 1, 2023.\nEveryday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.\nAdvanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.\nIt depends on the nature of the program. While ChatGPT can write workable Python code, it canâ€™t necessarily program an entire appâ€™s worth of code. Thatâ€™s because ChatGPT lacks context awareness â€” in other words, the generated code isnâ€™t always appropriate for the specific context in which itâ€™s being used.\nYes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.\nYes. There are multiple AI-powered chatbot competitors such as Together, Googleâ€™s Gemini and Anthropicâ€™s Claude, and developers are creating open source alternatives.\nOpenAI hasÂ saidÂ that individuals in â€œcertain jurisdictionsâ€ (such as the EU) can object to the processing of their personal information by its AI models by filling outÂ this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression â€œin accordance with applicable lawsâ€.\nThe web form for making a deletion of data about you request is entitled â€œOpenAI Personal Data Removal Requestâ€.\nIn its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on â€œlegitimate interestâ€ (LI), pointing users towards more information about requesting an opt out â€” when it writes: â€œSee hereÂ for instructions on how you can opt out of our use of your information to train our models.â€\nRecently, Discord announced that it had integrated OpenAIâ€™s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.\nAn Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPTâ€™s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.\nCNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.\nSeveral major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.\nThere have also been cases of ChatGPT accusing individuals of false crimes.\nSeveral marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.\nPoorly. Several tools claim to detect ChatGPT-generated text, but in our tests, theyâ€™re inconsistent at best.\nNo. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some usersâ€™ conversations to other people on the service.\nNone specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.\nYes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.\nThis story is continually updated with new information.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 21
  },
  {
    "title": "Google and PayPal team up on agentic commerce",
    "url": "https://techcrunch.com/2025/09/18/google-and-paypal-team-up-on-agentic-commerce/",
    "content": "PayPal announced on Wednesday a new multi-year partnership with Google that will see the payments giant using Googleâ€™s AI technology to create new AI-powered shopping experiences. PayPalâ€™s solutions, meanwhile, will be integrated across Googleâ€™s products, and PayPal will work with Google Cloud on hosting and improving its technology infrastructure.\nThe companies did not detail what specific types of agentic shopping experiences they would work together to create but said Google would contribute its AI technology and expertise, and PayPal would leverage its global payment infrastructure, personalization, and identity solutions.\nIn addition, both companies will join others to advocate for the adoption of Googleâ€™s new Agent Payments Protocol, announced on Tuesday. This open protocol is meant to enable purchases that are initiated by AI agents and has already been backed by over 60 merchants and financial institutions.\nAs part of the deal, PayPal will be listed as a key payment provider for card payments in areas like Google Cloud, Google Ads, and Google Play. Other products being integrated by Google include PayPalâ€™s branded checkout, Hyperwallet payouts service, and PayPal Payouts service.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 22
  },
  {
    "title": "Nvidia buys $5B stake in Intel, planning AI chip collaboration",
    "url": "https://techcrunch.com/2025/09/18/nvidia-buys-5-billion-stake-in-intel-planning-ai-chip-collaboration/",
    "content": "Nvidia has agreed to buy a $5 billion stake in Intel as part of a broader deal to together develop â€œmultiple generationsâ€ of data center and PC products.\nNvidia will acquire the Intel stock for $23.28 per share, a slight discount on the companyâ€™s previous trading price. According to Reuters, the deal would make Nvidia one of Intelâ€™s largest shareholders, owning about 4% of the company. Intel shares were up as much as 30% in early trading on Thursday morning.\nThe companies will integrate their two architectures using Nvidiaâ€™s NVLink interface, which enables data and control code transfers between CPUs and GPUs. NVLink enables faster transfers between chips compared with other standards like PCI Express; thatâ€™s crucial for AI applications, which require many GPUs to run together and process immense workloads.\nFor data centers, Intel will manufacture a new line of x86 CPUs specifically customized for Nvidiaâ€™s AI infrastructure platforms, to be offered to enterprise and hyperscale customers.\nFor the consumer PC segment, Intel will build x86 system-on-chips that will incorporate chiplets of Nvidiaâ€™s RTX GPUs, which will no doubt give Intel an edge over rival AMDâ€™s CPUs. The companies are calling these chips â€œx86 RTX SoCsâ€ at the moment and claim these chips will power a â€œwide range of PCs.â€\nThe deal comes after a rough few years for Intel, which has struggled to capitalize on the AI chip race unlike its new partner. Intel brought on a new CEO, laid off thousands of staff as it sought to shore up margins, and spiked manufacturing projects to prioritize more financial discipline.\nThe deal comes on the heels of another record quarter for Nvidia, which has grown into both the worldâ€™s most lucrative semiconductor company and, by market cap, one of the largest companies in the world. Over the same period, Intel has struggled to keep pace with the fluctuations of market demand, particularly the intense semiconductor demands of AI. As a result, the collaboration could allow Intel to win back market share from rivals like AMD.\nâ€œIntelâ€™s leading data center and client computing platforms, combined with our process technology, manufacturing and advanced packaging capabilities, will complement NVIDIAâ€™s AI and accelerated computing leadership to enable new breakthroughs for the industry,â€ said Intel CEO Lip-Bu Tan in a statement.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 23
  },
  {
    "title": "Building the future of Open AI with Thomas Wolf at TechCrunch Disrupt 2025",
    "url": "https://techcrunch.com/2025/09/18/building-the-future-of-open-ai-with-thomas-wolf-at-techcrunch-disrupt-2025/",
    "content": "AI is moving fast â€” but who decides how itâ€™s built, shared, and scaled? At TechCrunch Disrupt 2025, happening October 27-29 at San Franciscoâ€™s Moscone West, weâ€™re diving in with Thomas Wolf, co-founder and chief science officer of Hugging Face, for a session on what it takes to make cutting-edge research and models that are truly open and accessible. Catch him on the AI Stage, along with thousands of other like-minded tech leaders and innovators.\nThe future of AI wonâ€™t just be defined by closed labs and Big Tech budgets â€” it will be written in open source repos, global research collaborations, and moonshot experiments that anyone can build on. Wolf brings a rare perspective on how to bridge research, community, and real-world applications in ways that shape both the technology and the ecosystem around it.\nWhether youâ€™re a founder, developer, or investor, this session offers a clear view of where AI is headed â€” and how openness can drive the next wave of breakthroughs.\nWolf has been at the center of some of the most important advances in AI. At Hugging Face, he helped launch the Transformers and Datasets libraries, led the BigScience Workshop on large language models that produced BLOOM, and has championed open science across industry and academia. Heâ€™s also co-author of â€œNatural Language Processing with Transformersâ€ and â€œThe Ultra-Scale Playbook,â€ resources shaping how the next generation of AI practitioners learn and build.\nJoin 10,000+ startup and VC leaders October 27â€“29 at Moscone West in San Francisco, with headline-making sessions, hands-on discussions, and intentional networking designed to fuel your next move. Disrupt 2025 is where the future of tech gets built and where we celebrate 20 years of TechCrunch. Lock in your pass now to save up to $668 before savings end on September 26 at 11:59 p.m. PT.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 24
  },
  {
    "title": "AtlassianÂ acquiresÂ DX, a developer productivity platform, for $1B",
    "url": "https://techcrunch.com/2025/09/18/atlassian-acquires-dx-a-developer-productivity-platform-for-1b/",
    "content": "ProductivityÂ software giant AtlassianÂ is making its largest acquisition yet to add aÂ developer productivity tool to itsÂ productÂ suite.\nAtlassian announced Thursday it has agreed to acquire the developerÂ productivityÂ insight platformÂ DXÂ forÂ $1 billionÂ in cash and restricted stock.Â Enterprises use DX to analyze how productive their engineering teams are and identify bottlenecks slowing them down.\nDX was launched five years ago byÂ Abi Noda and Greyson Junggren. NodaÂ toldÂ TechCrunch in 2022Â that he founded the companyÂ to find a better way to understand what hampered engineering teams. At the time,Â he felt the metrics he was using as a product managerÂ at GitHubÂ werenâ€™tÂ giving him the full picture, and he wanted to build something better thatÂ didnâ€™tÂ make developers feel like they were beingÂ surveilled.\nâ€œThe assumptions we had about what we needed to help ship products faster were quite different than what the teams and developers were saying was getting in their way,â€ Noda told TechCrunch at the time. â€œEven teams didnâ€™t always have awareness about their own issues and leadership.â€\nDX came out of stealth in 2022 and has since tripled its customer baseÂ every year. The company now works with more than 350 enterprise customers, includingÂ ADP, Adyen, and GitHub, among others, while raisingÂ less than $5 million in venture funding.\nAtlassianÂ co-founderÂ and CEOÂ Mike Cannon-BrookesÂ told TechCrunchÂ that after trying to build an in-house developer productivity insight tool for three years, his Sydney, Australia-based companyÂ realized it made sense to look for an external, existing option.\nDX was a natural choice, Cannon-Brookes said, considering 90% of DXâ€™s customers were already using Atlassianâ€™s project management and collaboration tools as well.\nâ€œDX has done an amazing job [of] understanding the qualitative and quantitative aspects of developer productivity and turning that into actions that can improve those companies and give them insights and comparisons to others in their industry, others at their size, etc.,â€ Cannon-Brookes said.\nHe added that the timing was right due to the rise of AI tools and companies looking for ways to measure how they are being used.\nâ€œYou suddenly have these budgets that are going up. Is that a good thing?â€ Cannon-Brookes said. â€œIs that not a good thing?Â  Am I spending the money in the rightÂ ways?Â Itâ€™sÂ really,Â reallyÂ importantÂ and critical.â€\nHe added that there was a great cultural fit, too.Â Cannon-Brookes saidÂ heâ€™sÂ always felt an affinity for Utah-based entrepreneurs â€”Â DX is based in Salt Lake City â€”Â and he liked that both companies were able toÂ scaleÂ without taking onÂ much outside funding.\nThe feeling was mutual.\nNoda told TechCrunch this week that he thinks DX and Atlassian are better together than apart and that many of Atlassianâ€™s tools areÂ complementaryÂ to the data and information that DXâ€™s platform gathers.\nâ€œWeÂ are able toÂ provide customers with that full flywheel to get the data and understand whereÂ we areÂ unhealthy,â€ Noda said. â€œThey can plug inÂ Atlassianâ€™sÂ tools andÂ solutionsÂ to go address those bottlenecks. An end-to-end flywheel that isÂ ultimately whatÂ customers want.â€\nDXâ€™s platform will be integrated into the broader Atlassian product suite.\nThis isÂ Atlassianâ€™sÂ secondÂ acquisitionÂ this month.Â The company announced it was buyingÂ AI-browser developerÂ The Browser CompanyÂ in early September.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 25
  },
  {
    "title": "India leads the way on Googleâ€™s Nano Banana with a local creative twist",
    "url": "https://techcrunch.com/2025/09/17/india-leads-the-way-on-googles-nano-banana-with-a-local-creative-twist/",
    "content": "Googleâ€™s Nano Banana image-generation model, officially known as Gemini 2.5 Flash Image, has fueled global momentum for the Gemini app since launching last month. But in India, it has taken on a creative life of its own, with retro portraits and local trends going viral â€” even as privacy and safety concerns begin to emerge.\nIndia has emerged as the No. 1 country in terms of Nano Banana usage for now, according to David Sharon, multimodal generation lead for Gemini Apps at Google DeepMind, who spoke at a media session this week. The modelâ€™s popularity has propelled the Gemini app to the top of the free app charts on both the App Store and Google Play in India. The app has also climbed to the top of global app storesâ€™ charts, according to Appfigures.\nGiven Indiaâ€™s scale â€” the worldâ€™s second-largest smartphone market and second-biggest online population after China â€” it is no surprise the country is leading in adoption. But what is catching Googleâ€™s attention is not just how many people are using Nano Banana, it is how: Millions of Indians are engaging with the AI model in ways that are uniquely local, highly creative, and in some cases, completely unexpected.\nOne of the standout trends is Indians using Nano Banana to re-create retro looks inspired by 1990s Bollywood, imagining how they might have appeared during that era, complete with period-specific fashion, hairstyles, and makeup. This trend is local to India, Sharon told reporters.\nA variation of the retro trend is what some are calling the â€œAI saree,â€ where users generate vintage-style portraits of themselves wearing traditional Indian attire.\nAnother trend local to India is people generating their selfies in front of cityscapes and iconic landmarks, such as Big Ben and the U.K.â€™s retro telephone booths.\nâ€œWe saw a lot of that in the beginning,â€ Sharon said.\nIndian users are also experimenting with Nano Banana to transform objects, create time-travel effects, and even reimagine themselves as retro postage stamps. Others are generating black-and-white portraits or using the model to visualize encounters with their younger selves.\nSome of these trends did not originate in India, but the country played a key role in helping them gain global attention. One example is the figurine trend, where people generate miniature versions of themselves, often placing them in front of a computer screen. The trend first emerged in Thailand, spread to Indonesia, and became global after gaining traction in India, Sharon said.\nIn addition to Nano Banana, Google has observed a trend where Indian users are utilizing its Veo 3 AI video-generation model on the Gemini app to create short videos from old photos of their grandparents and great-grandparents.\nAll of this has helped drive Geminiâ€™s popularity on both the App Store and Google Play in India. Between January and August, the app saw an average of 1.9 million monthly downloads in the country â€” about 55% higher than in the U.S. â€” accounting for 16.6% of global monthly downloads, per Appfigures data shared exclusively with TechCrunch.\nIndia downloads have totaled 15.2 million this year until August; the U.S., on the other hand, has had 9.8 million downloads so far this year, per Appfigures data.\nDaily downloads of the Gemini app in India significantly surged following the release of the Nano Banana update, beginning on September 1 with 55,000 installs across both app stores. Downloads peaked at 414,000 on September 13 â€” a 667% increase â€” with Gemini holding the top overall spot on the iOS App Store since September 10 and on Google Play since September 12, including across all categories, Appfigures data shows.\nDespite India leading in downloads, the country does not top in-app purchases on the Gemini app, which has generated an estimated $6.4 million in global consumer spending on iOS since launch, per Appfigures. The U.S. accounts for the largest share at $2.3 million (35%), while India contributes $95,000 (1.5%).\nHowever, India posted a record 18% month-over-month growth in spending, reaching $13,000 between September 1 and 16 â€” compared to an 11% global increase during the same period. That puts India seven percentage points above the global rate and more than 17 points ahead of the U.S., where growth was under 1%.\nThat said, as with other AI apps, there are concerns about users uploading personal photos to Gemini to transform their appearance.\nâ€œWhen a user asks us to fulfill their query, we do our best to fulfill that query. We donâ€™t try to assume what the userâ€™s intent is,â€ Sharon said while addressing questions on how Google is dealing with data misuse and privacy concerns among users in India and other top markets. â€œWeâ€™ve really tried to improve that, and we have improved that to be bold and fulfill your request.â€\nGoogle places a visible, diamond-shaped watermark on images generated by the Nano Banana model and also embeds a hidden marker using its SynthID tool to identify AI-generated content. SynthID allows Google to detect and flag whether an image was created using its models.\nSharon told reporters that Google is testing a detection platform with trusted testers, researchers, and other experts. The company also plans to launch a consumer-facing version that would allow anyone to check whether an image is AI-generated.\nâ€œThis is still day one, and weâ€™re still learning, and weâ€™re learning together. There are things that we might need to improve on in the future, and itâ€™s really your feedback from users, press, academia, and experts that helps us improve,â€ Sharon said.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 26
  },
  {
    "title": "Meta unveils new smart glasses with a display and wristband controller",
    "url": "https://techcrunch.com/2025/09/17/meta-unveils-new-smart-glasses-with-a-display-and-wristband-controller/",
    "content": "Meta on Wednesday unveiled a new pair of Ray-Ban branded smart glasses with a built-in display for apps, alerts, and directions on the right lens. The smart glasses are controlled by a wristband that picks up on subtle hand gestures, called Meta Neural Band, the same one it unveiled at last yearâ€™s Connect as part of its Orion demo.\nCEO Mark Zuckerberg announced the new product, called Meta Ray-Ban Display, onstage at the companyâ€™s annual developer conference, Meta Connect 2025. Unlike Orion, Zuckerberg says this is a product that people can buy in a couple of weeks, starting September 30, and theyâ€™ll cost $799.\nThis is Metaâ€™s latest attempt to ship a pair of consumer smart glasses that can handle many of the tasks users traditionally do on a smartphone. For years, Meta has been forced to reach users through its competitorsâ€™ devices, namely those sold by Google and Apple. While Meta has invested billions in virtual reality headsets, AI-powered smart glasses now seem like the most promising way for the company to connect with users on its own hardware.\nWith the Meta Ray-Ban Display, Meta aims to build off the success of its original Ray-Ban Meta smart glasses, which the company has sold millions of pairs of with its eyewear partner, EssilorLuxottica. Much like Ray-Ban Meta, the Meta Ray-Ban Display comes equipped with an on-board AI assistant, as well as cameras, speakers, and microphones. The glasses let users connect to the cloud to access the internet and social media apps.\nMeta says the display enables users to do much more with their smart glasses. Users are capable of displaying Meta apps like Instagram, WhatsApp, and Facebook. Users can also view directions and see live translations in the smart glassesâ€™ display.\nThe Neural Band that ships alongside the device looks similar to a Fitbit, but without a screen, and allows users to navigate apps with small hand movements. Zuckerberg said onstage that the Meta Neural Band has 18 hours of battery life and is water resistant.\nThe device uses electromyography (EMG) to pick up on signals sent between your brain and your hand when performing a gesture. Meta is betting this interface will be a new way users can control their devices.\nEarlier this week, a video leaked of Metaâ€™s latest smart glasses. CNBC and Bloomberg previously reported that the smart glasses, which were internally codenamed Hypernova, would be unveiled at this yearâ€™s Connect conference.\nItâ€™s worth noting that Meta Ray-Ban Display are far less capable than the Orion smart glasses Meta showed off at Connect 2024. That device featured augmented reality lenses and eye tracking, while this pair uses a much simpler display. It may be years before Meta ever sells Orion.\nStill, Meta is hoping it can win the smart glasses race by being first to market with a real product. However, it seems likely that Google and Apple will launch smart glasses of their own in the years to come. Those devices will undoubtedly be able to integrate into Google and Appleâ€™s respective operating systems, giving them a significant leg up over Meta.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 27
  },
  {
    "title": "Nvidia AI chip challenger Groq raises even more than expected, hits $6.9B valuation",
    "url": "https://techcrunch.com/2025/09/17/nvidia-ai-chip-challenger-groq-raises-even-more-than-expected-hits-6-9b-valuation/",
    "content": "AI chip startup Groq confirmed Wednesday that it raised a fresh $750 million in funding at a post-money valuation of $6.9 billion.\nThis topped the rumored numbers when word leaked in July that Groq was raising. At that time, reports suggested that the raise would be about $600 million, at near a $6 billion valuation.\nGroq, which also sells data center computing power,Â previously raised $640 million at a $2.8 billion valuationÂ in August 2024, making this more than double the valuation in about a year. Groq has now raised over $3 billion to date, PitchBook estimates.\nGroq has been a hot commodity because it is working on breaking the chokehold that AI chip maker Nvidia has over the tech industry. Groqâ€™s chips are not GPUs, the graphics processing units that typically power AI systems. Instead, Groq calls them LPUs, (language processing units) and calls its hardware an inference engine â€” specialized computers optimized for running AI models quickly and efficiently.\nIts products are geared toward developers and enterprises, available as either a cloud service or an on-premises hardware cluster.Â The on-prem hardware is a server rack outfitted with a stack of its integrated hardware/software nodes. Both the cloud and on-prem hardware run open versions of popular models, like those from Meta, DeepSeek, Qwen, Mistral, Google and OpenAI.Â Groq says its offerings maintain, or in some cases improve, AI performance at significantly less cost than alternatives.\nGroqâ€™s founder, Jonathan Ross, has a particularly relevant pedigree for this work. Ross previously worked at Google developing its Tensor Processing Unit chip, which are specialized processors designed for machine learning tasks. The TPU was announced in 2016, the same year Groq emerged from stealth.Â TPUs still power Google Cloudâ€™s AI services.\nGroq says it now powers the AI apps of more than 2 million developers, up from 356,000 developers when the company talked to TechCrunch a year ago.\nThe new round was led by investment firm Disruptive, with additional funding from BlackRock, Neuberger Berman, Deutsche Telekom Capital Partners, and others. Existing investors, including Samsung, Cisco, D1, and Altimeter, also joined the round.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 28
  },
  {
    "title": "Irregular raises $80 million to secure frontier AI models",
    "url": "https://techcrunch.com/2025/09/17/irregular-raises-80-million-to-secure-frontier-ai-models/",
    "content": "On Wednesday, AI security firm Irregular announced $80 million in new funding in a round led by Sequoia Capital and Redpoint Ventures, with participation from Wiz CEO Assaf Rappaport. A source close to the deal said the round valued Irregular at $450 million.\nâ€œOur view is that soon, a lot of economic activity is going to come from human-on-AI interaction and AI-on-AI interaction,â€ co-founder Dan Lahav told TechCrunch, â€œand thatâ€™s going to break the security stack along multiple points.â€\nFormerly known as Pattern Labs, Irregular is already a significant player in AI evaluations. The companyâ€™s work is cited in security evaluations for Claude 3.7 Sonnet as well as OpenAIâ€™s o3 and o4-mini models. More generally, the companyâ€™s framework for scoring a modelâ€™s vulnerability-detection ability (dubbed SOLVE) is widely used within the industry.\nWhile Irregular has done significant work on modelsâ€™ existing risks, the company is fundraising with an eye towards something even more ambitious: spotting emergent risks and behaviors before they surface in the wild. The company has constructed an elaborate system of simulated environments, enabling intensive testing of a model before it is released.\nâ€œWe have complex network simulations where we have AI both taking the role of attacker and defender,â€ says co-founder Omer Nevo. â€œSo when a new model comes out, we can see where the defenses hold up and where they donâ€™t.â€\nSecurity has become a point of intense focus for the AI industry, as the potential risks posed by frontier models as more risks have emerged. OpenAI overhauled its internal security measures this summer, with an eye towards potential corporate espionage.\nAt the same time, AI models are increasingly adept at finding software vulnerabilities â€” a power with serious implications for both attackers and defenders.\nFor the Irregular founders, itâ€™s the first of many security headaches caused by the growing capabilities of large language models.\nâ€œIf the goal of the frontier lab is to create increasingly more sophisticated and capable models, our goal is to secure these models,â€ Lahav says. â€œBut itâ€™s a moving target, so inherently thereâ€™s much, much, much more work to do in the future.â€\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 29
  },
  {
    "title": "Google isnâ€™t kidding around about cost cutting, even slashing its FT subscription",
    "url": "https://techcrunch.com/2025/09/19/google-isnt-kidding-around-about-cost-cutting-even-slashing-its-ft-subscription/",
    "content": "Google is ending its enterprise subscription to the Financial Times, and itâ€™s not the only enterprise media subscription on the chopping block, sources say. The cuts reflect broader cost-reduction efforts at the search giant, even as the company reports strong financial performance.\nGoogle has been implementing cost reductions across 2025, including eliminating 35% of managers who oversee teams of three people or fewer, and offering voluntary exit programs across multiple divisions since January. Finance chief Anat Ashkenazi signaled late last year that the company would continue to push cost cuts â€œa little further,â€ a mandate that appears unchanged despite Alphabet reporting strong Q2 2025 results with $96.4 billion in revenue.\nThese cuts may save Google mere thousands; they also come as Google faces increasingly strained relationships with news publishers. August data from the trade association Digital Content Next showed median referral traffic from Google Search to publishers fell 10% between May and June of this year, with non-news brands experiencing 14% drops.\nMajor outlets, including CNN, Business Insider, and HuffPost have reportedly seen even sharper traffic declines (of 30%, 40%, and 40%, respectively), according to data from SimilarWeb.\nPublishers attribute these declines largely to Googleâ€™s AI Overviews feature, which has reduced click-throughs to external websites from 56% to 69% since its launch, according to Pew Research. This spring, Pew analyzed data from 900 U.S. adults, six in ten of whom conducted at least one Google search in March 2025 that produced an AI-generated summary.\nThe traffic decline comes as Google has largely resisted content licensing, unlike rival OpenAI, which has signed deals with numerous major publishers including The Financial Times, News Corp, and Axel Springer. So far at least, Google has struck few deals, including one with the Associated Press and an annual Reddit agreement reportedly worth $60 million per year. (According to a new Bloomberg report, Reddit is now looking to renegotiate its contracts with both Google and OpenAI, with Bloomberg suggesting that Reddit sees its prominent role in search results and generative AI training as even more valuable than it first understood.)\nGoogle reportedly began exploratory talks with 20 outlets about more content licensing deals this summer. Still, some might see Google canceling its FT subscription as akin to a plagiarist refusing to buy the textbook theyâ€™re copying from.\nAt a Fortune event earlier this month, the CEO of the largest digital and print publisher in the U.S. â€” Neil Vogel of People Inc. â€” didnâ€™t hold his punches, calling Google a â€œbad actorâ€ and accusing it of using the same bot to crawl websites for its search engine as it does to support its AI features.\nGoogle differs from other AI players by tying its AI training to search access, leaving publishers unable to block AI systems without also forfeiting search traffic.\nâ€œFor a long time,â€ Vogel said at the event, â€œthe deal was: â€˜Take our content, build your search engine, send us back trafficâ€™. That dealâ€™s off.â€\nIn a separate, scathing op-ed this summer, Digital Content Next CEO Jason Kint wrote that Googleâ€™s AI overviews are creating a â€œzero-clickâ€ environment where â€œall traffic dead ends at Google.â€\nGoogle did not respond to a request for comment.\nUpdate: This story has been updated with information about Googleâ€™s content-licensing deals.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 30
  },
  {
    "title": "Meta CTO explains why the smart glasses demos failed at Meta Connect â€” and it wasnâ€™t the Wi-Fi",
    "url": "https://techcrunch.com/2025/09/19/meta-cto-explains-why-the-smart-glasses-demos-failed-at-meta-connect-and-it-wasnt-the-wi-fi/",
    "content": "Meta chief technology officer Andrew Bosworth took to his Instagram to explain, in more technical detail, why multiple demos of Metaâ€™s new smart glasses technology failed at Meta Connect, the companyâ€™s developer conference, this week.\nMeta on Wednesday introduced three new pairs of smart glasses, including an upgraded version of its existing Ray-Ban Meta, a new Meta Ray-Ban Display that comes with a wristband controller, and the sports-focused Oakley Meta Vanguard.\nHowever, at different points during the event, the live technology demos failed to work.\nIn one, cooking content creator Jack Mancuso asked his Ray-Ban Meta glasses how to get started with a particular sauce recipe. After repeating the question, â€œWhat do I do first?â€ with no response, the AI skipped ahead in the recipe, forcing him to stop the demo. He then tossed it back to Meta CEO Mark Zuckerberg, saying that he thinks the Wi-Fi may be messed up.\nIn another demo, the glasses failed to pick up a live WhatsApp video call between Bosworth and Zuckerberg; Zuckerberg eventually had to give up. Bosworth walked onstage, joking about the â€œbrutalâ€ Wi-Fi.\nâ€œYou practice these things like a hundred times, and then you never know whatâ€™s gonna happen,â€ Zuckerberg said at the time.\nAfter the event, Bosworth took to his Instagram for a Q&A session about the new tech and the live demo failures.\nOn the latter, he explained that it wasnâ€™t actually the Wi-Fi that caused the issue with the chefâ€™s glasses. Instead, it was a mistake in resource management planning.\nâ€œWhen the chef said, â€˜Hey, Meta, start Live AI,â€™ it started every single Ray-Ban Metaâ€™s Live AI in the building. And there were a lot of people in that building,â€ Bosworth explained. â€œThat obviously didnâ€™t happen in rehearsal; we didnâ€™t have as many things,â€ he said, referring to the number of glasses that were triggered.\nThat alone wasnâ€™t enough to cause the disruption, though. The second part of the failure had to do with how Meta had chosen to route the Live AI traffic to its development server to isolate it during the demo. But when it did so, it did this for everyone in the building on the access points, which included all the headsets.\nâ€œSo we DDoSâ€™d ourselves, basically, with that demo,â€ Bosworth added. (A DDoS attack, or a distributed denial of service attack, is one where a flood of traffic overwhelms a server or service, slowing it down or making it unavailable. In this case, Metaâ€™s dev server wasnâ€™t set up to handle the flood of traffic from the other glasses in the building â€” Meta was only planning for it to handle the demos alone.)\nThe issue with the failed WhatsApp call, on the other hand, was the result of a new bug.\nThe smart glassesâ€™ display had gone to sleep at the exact moment the call came in, Bosworth said. When Zuckerberg woke the display back up, it didnâ€™t show the answer notification to him. The CTO said this was a â€œrace conditionâ€ bug, or where the outcome depends on the unpredictable and uncoordinated timing of two or more different processes trying to use the same resource simultaneously.\nâ€œWeâ€™ve never run into that bug before,â€ Bosworth noted. â€œThatâ€™s the first time weâ€™d ever seen it. Itâ€™s fixed now, and thatâ€™s a terrible, terrible place for that bug to show up.â€ He stressed that, of course, Meta knows how to handle video calls, and the company was â€œbummedâ€ about the bug showing up here.\nDespite the issues, Bosworth said heâ€™s not worried about the results of the glitches.\nâ€œObviously, I donâ€™t love it, but I know the product works. I know it has the goods. So it really was just a demo fail and not, like, a product failure,â€ he said.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 31
  },
  {
    "title": "The 9 most sought-after startups from YC Demo Day",
    "url": "https://techcrunch.com/2025/09/15/the-9-most-sought-after-startups-from-yc-demo-day/",
    "content": "Y Combinator hosted its Summer 2025 Demo Day last week, showcasing the latest batch of over 160 startups.\nAs with recent batches, the majority of startups presented AI-centric solutions. However, a clear evolution was evident. Instead ofÂ  â€œAI-poweredâ€ products, many companies are now building AI agents or the infrastructure and tools needed to develop them. For instance, this batch had a flurry of voice AI solutions and new businesses focused on helping others monetize the â€œAI economyâ€ with ads and marketing tools.\nWe spoke with a handful of YC-focusedÂ  investors to learn which startups they found most interesting and which generated the highest investment demand.\nBelow are the most frequently mentioned ones:\nWhat it does: Stripe for AI startups\nWhy itâ€™s a fave: Many AI startups use complex pricing models that often blend a flat subscription fee per seat with usage-based charges, credits, and various add-on costs. Managing complex AI pricing on Stripe is a time-consuming, manual process. Thatâ€™s why Autumn developed an open-source infrastructure that simplifies Stripe integration for AI startups. The company says its technology is already used by hundreds of AI apps and 40 YC startups. Given Stripeâ€™s dominance in payments and the explosive growth of the AI market, could a specialized billing solution for AI be the next major fintech success story?\nWhat it does: Builds Vercel for AI agents\nWhy itâ€™s a fave: Just as Vercel helps developers deploy and host startups, Dedalus Labs claims its platform automates the infrastructure for building AI agents, cutting hours of coding down to a few clicks. The company handles complex tasks like autoscaling and load balancing, which it says makes agent deployment fast and simple.\nWhat it does: crowdsource rankings of vibe coded designs\nWhy itâ€™s a fave: The ability of AI to rapidly generate a huge number of designs creates a new problem: figuring out which ones are actually good. Design Arena solves this by crowdsourcing rankings of AI-generated visuals, creating a feedback loop that forces AI models to improve. Large AI labs see value in training their models to generate better designs, as some of them are already Design Arenaâ€™s customers.\nWhat it does: Tech-enabled distributor for retailers in Southeast Asia\nWhy itâ€™s a fave: Getasap Asia was founded by Raghav Arora three years ago when he was just 14 years old. Since then, the startup that uses tech to deliver supplies to corner stores, restaurants and large supermarkets in Southeast Asia in under eight hours, has earned millions in revenue. Getasap Asia closed a round from General Catalyst, according to its website, and we are hearing that the startupâ€™s valuation was among the highest in the whole batch.\nWhat it does: AI engineer that fixes bugs in production\nWhy itâ€™s a fave: Founded by a 20-year-old Pablo Hansen who last year earned a masterâ€™s degree in AI, Keystone is on a mission to reduce software breaks. The companyâ€™s AI finds and fixes bugs for clients like Lovable and has already turned down a seven-figure acquisition offer, Hansen said.\nWhat it does: AI matchmaker for female friends\nWhy itâ€™s a fave: While there isnâ€™t a shortage of dating apps, RealRoots is tackling a different kind of loneliness. The companyâ€™s AI matchmaker, Lisa, interviews women and then organizes social experiences to connect them with compatible friends. While the AI part might be performative â€“Â  conversations with Lisa probably wouldnâ€™t give RealRoots more insights about participants than written answers would â€“ RealRoots may be on to something. Last month alone, the company generated $782,000 from 9,000 paying clients, its founders said.\nWhat it does: Automates insurance claims with AI\nWhy itâ€™s a fave: Solvaâ€™s AI automates the most routine tasks for insurance adjusters, from filling out complex claims to preventing improper payouts. Just ten weeks after launching, Solva has already amassed $245,000 in annual recurring revenue (ARR), a figure that has investors excited.\nWhat it does: counter-drone mini-missiles\nWhy itâ€™s a fave: With China reportedly amassing swarms of inexpensive drones, the U.S. military faces an urgent need for cost-effective counter-drone solutions. Perseus is developing just that: small missiles designed to shoot down drones at a fraction of the cost of existing systems. Multiple branches of the U.S. military have already invited the startup to demonstrate its solution, which could lead to hefty contracts.\nWhat it does: AI foreign language tutor\nWhy itâ€™s a fave: Apps like Duolingo have made language learning accessible and fun, but they often lack a key component of fluency: consistent conversation. Pingo solves this problem by allowing users to speak with its AI, which acts as a native speaker. The companyâ€™s unique approach is proving incredibly popular, with founders claiming itâ€™s growing 70% monthly and earning $250,000 in monthly revenue.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 32
  },
  {
    "title": "Appleâ€™s iOS 26 with the new Liquid Glass design is now available to everyone",
    "url": "https://techcrunch.com/2025/09/15/apples-ios-26-with-the-new-liquid-glass-design-is-now-available-to-everyone/",
    "content": "Appleâ€™s iOS 26 software update for iPhones is available Monday to people who have an iPhone 11, iPhone SE 2, and later. The marquee feature of iOS 26 is Appleâ€™s Liquid Glass design, which includes elements on-screen that resembled a â€œglassyâ€ look. Other features include a call screening assistant, a new gaming and preview app, in-app translation across the system, and updates to Genmoji and Image Playground apps.\nThe operating system update also went through a big numerical change as Apple jumped from iOS 18 to iOS 26 for two key reasons. First, it wanted to bring all operating systems â€” iOS, iPadOS, macOS, watchOS, tvOS, and VisionOS â€” in sync. And it also wanted to reflect the year number in which the majority of the people will use this update.\nLiquid Glass design has been the most significant visual overhaul for iOS in years. Appleâ€™s intention with this redesign was to take inspiration from the Vision Pro interface and apply it to all of its operating systems. The elements are meant to look like they are made of translucent glass. This resulted in challenges in terms of readability and how elements in the background look.\nSince June, Apple has made several changes to how â€œglassyâ€ the interface looks through beta releases. While the company is releasing the stable version of iOS 26 today, we might expect visual tweaks for improved readability and usability in the coming months. This visual change might take a bit of time for users to adjust, and they might not like certain elements right away.\nThe Phone app has a new unified look where your favorites are up top in a card format with recents and voicemails on the same screen. You can tap the filter button on the top right and look at these sections individually as well. (If you donâ€™t like the new interface, Apple also gives you an option to switch to the classic look.)\nIn addition, iOS 26 brings a call-screening feature to iPhones, which is a personal favorite. When an unknown number calls you, the system asks for their name and the purpose of the call. Once they give this information, the system invokes the ringer and notifies you of the call. You can look at the conversation and interject at any time. Transcription of voicemail doesnâ€™t work well for all languages, but call screening has reduced the number of calls Iâ€™ve had to pick up.\nThereâ€™s also a holding assist for when a restaurant or a helpline places you on hold; you can use call assist to notify when an agent starts talking again.\nThe Messages app is getting to feature party with other chat apps like WhatsApp and Telegram with backgrounds, new conversation flow, polls, text selection, photo previews, and typing indicators in groups. Apple has been working on SMS filtering for a few years now. The company said it updated its spam filtering with this release. Plus, it places messages from unknown senders in a new folder. One thing I didnâ€™t like about this update is that it takes me a couple of taps to go to the transactions tab.\nThe games app overhaul means that you can look at the games you are playing (or have played), arcade games, challenges, and achievements in one place, along with suggestions for new titles. The app also shows you what your friends are playing.\nApple finally added Macâ€™s Preview app to iOS 26, which means you can edit, annotate, and sign PDFs more easily.\nMeanwhile, Apple Music now has automixing for dynamic song switching, along with lyrics translation and pronunciation. Whatâ€™s more, you can pin your favorite songs and playlists.\nWith iOS 26, Apple Maps lets you define preferred routes while commuting. In case your choice of route has more traffic or any incidents, Maps sends you a notification along with suggesting alternative routes. The app also lets you easily view visited places through a new places library.\nThe Camera app in iOS 26 adopts the Liquid Glass design with only Video and Photo options visible by default. You can scroll to the left or right to switch between different modes. Apple has placed some controls like Flash and Night mode on the top right, and you can switch them on/off with one touch. For more options like filters, styles, exposure controls, and timer, you can swipe up from the bottom of the screen.\nIf you didnâ€™t like the previous Photos app design, the tabs are back in this version.\nUnlike last yearâ€™s grand launch of Apple Intelligence, this yearâ€™s operating system is light on AI features, especially given delays in launching and rolling out features. The company is making AI-powered translation easily available in apps like Messages, FaceTime, and Phone. Currently, this feature supports English (U.K., U.S.), French (France), German, Portuguese (Brazil), and Spanish (Spain).\nThrough iOS 26, the company is also launching live translation on AirPods, including the newly launched AirPods Pro 3, AirPods Pro 2, and AirPods 4.\nAlso, iOS 26 updates visual intelligence to understand the content on the screen. You have to press Power + the volume down button to bring up this menu. Apple Intelligence can then suggest events to add to your calendar. You can also ask questions about the content on the screen, using Google Visual Search or ChatGPT. Apple is also releasing its own â€œCircle to searchâ€ called Highlight.\nThe most confusing part about this update is that the buttons used to bring up on-screen visual intelligence are the same as the screenshot button. Because of this, it takes an extra step to save a screenshot, and I have forgotten to save some important screenshots.\nApple is updating Genmoji with iOS 26 to let you merge two emojis with a text prompt and make something new. You can now add expression to people in both Genmoji and Image Playground. Update to Image Playground now allows you to modify attributes like hair and facial hair, along with new styles from ChatGPT.\nWe have a list of tons of small but useful iOS features here. You can update to iOS 26 by going to Settings > General > Software Update and downloading the latest version.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 33
  },
  {
    "title": "Spotify will now let free users pick and play tracks",
    "url": "https://techcrunch.com/2025/09/15/spotify-will-now-let-free-users-pick-and-play-tracks/",
    "content": "Following its long-awaited launch of lossless streaming for paid subscribers, Spotify is upgrading its service for free users, too. On Monday, the company announced that free users globally will now be able to search and play any song they want or play a song shared by a friend or an artist they follow on social media.\nThe company calls the new features â€œPick & Play,â€ â€œSearch & Play,â€ and â€œShare & Play,â€ respectively. With the former, free users can hit play in the Spotify app to pick and play any song they want, or can even search for a particular song and play it.\nThe â€œShare & Playâ€ feature could encourage free users to open Spotify when they come across music on social media. For instance, Instagram lets users share a Spotify track to Stories with sound and allows users to share music on Instagram Notes.\nPreviously, free users could shuffle songs with limited skips on mobile devices.\nSpotify says the new features will roll out globally to free users, but there will still be some restrictions that Premium users wonâ€™t face.\nWhen reached for clarification, the company told TechCrunch that users on the free mobile experience will have an allocation of â€œon-demand time,â€ and when they reach that daily limit, theyâ€™ll then be restricted to a limited number of skips per hour. Spotify did not share what that time limit is, but noted that Premium users will not have these restrictions.\nIn recent months, Spotifyâ€™s ad business has been struggling, with CEO Daniel Ek telling investors the company has been â€œmoving too slowlyâ€ on this front. The streamer wants ad revenue to make up 20% of its overall revenue, but has grown it only to 11% as of June. By adding new free features, Spotify could boost engagement among its free user base, who would then be exposed to more ads.\nSpotify says that other features, like its support forÂ lossless, AI Playlists, and Mix, will remain Premium-only offerings, while others like the newly launched Messages and personalized playlist daylist, available to global users, will span both the free and paid experiences, as they had before.\nThe companyâ€™s free users today make up the bulk of its user base. Out of Spotifyâ€™s 696 million monthly active users in the most recent quarter, 433 million were free, ad-supported customers. In addition, there were 276 million Premium (paying) subscribers in the quarter.\nUpdated after publication with more information about the restrictions impacting free users.\nÂ© 2025 TechCrunch Media LLC.",
    "has_been_pretreat": false,
    "rating": null,
    "time_spent": 0,
    "comments": "",
    "tags": [],
    "id": 34
  }
]